{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "464dd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "idx = pd.IndexSlice\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import copy\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "code_dir = '/cluster/home/kheuto01/code/zero-inflated-gp/'\n",
    "sys.path.append(code_dir)\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from onoffgpf import OnOffSVGP, OnOffLikelihood\n",
    "\n",
    "import pickle\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import gpflow\n",
    "\n",
    "\n",
    "code_dir = '/cluster/home/kheuto01/code/zero-inflated-gp/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/perturbations/'\n",
    "sys.path.append(code_dir)\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/diff_bpr'\n",
    "sys.path.append(code_dir)\n",
    "from top_k import top_k_idx\n",
    "#from make_datasets import make_data\n",
    "from bpr_model import PerturbedBPRLinearModel, PerturbedBPRMLPModel\n",
    "from make_datasets import make_data\n",
    "\n",
    "\n",
    "from onoffgpf import OnOffSVGP, OnOffSVGPPoiMC, OnOffLikelihood\n",
    "gpflow.config.default_float()\n",
    "\n",
    "\n",
    "from zinf_gp.metrics import normcdf, fixed_top_X\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68c36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_template = '{time}_{loc}_{model}_{start_year}_{cov}_{num_inducing}_{lr}'\n",
    "#/annual_group_normal_2000_-auto_200_0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e139210",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 'annual'\n",
    "loc = 'tract'\n",
    "model = 'normal'\n",
    "start_year = '2010'\n",
    "cov = '-auto'\n",
    "num_inducing = '400'\n",
    "test_years=2\n",
    "data_dir='/cluster/tufts/hugheslab/datasets/NSF_OD/results_20220606_update/'\n",
    "\n",
    "log_dir='/cluster/tufts/hugheslab/kheuto01/opioid/logs/new_big_run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab23fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "town_map = pd.read_csv(os.path.join(data_dir, 'town_tract_map.csv'), dtype=str)\n",
    "group_map = gpd.read_file(os.path.join(data_dir, 'tract_group_map'), dtype=str)\n",
    "\n",
    "# test y always comes from quarterly tract\n",
    "y_timesteps_per_year = 1\n",
    "file_name = f'clean_annual_tract'\n",
    "data_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "\n",
    "timestep_col = 'timestep'\n",
    "geography_col = 'geoid'\n",
    "outcome_col = 'deaths'\n",
    "\n",
    "x_idx_cols = [geography_col, 'lat', 'lon', timestep_col,\n",
    "              'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "              'svi_pctile',\n",
    "              'neighbor_t', 'self_t-1']\n",
    "y_idx_cols = [geography_col, timestep_col, outcome_col]\n",
    "features_only = ['lat', 'lon', timestep_col,\n",
    "                 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "                 'svi_pctile',\n",
    "                 'neighbor_t', 'self_t-1']\n",
    "\n",
    "data_gdf = gpd.read_file(data_path)\n",
    "\n",
    "last_train_year = 2018\n",
    "\n",
    "test_y = data_gdf[(data_gdf['year'] > last_train_year) &\n",
    "                  (data_gdf['year'] <= last_train_year + test_years)][y_idx_cols]\n",
    "starting_y_timestep = int(test_y[timestep_col].min())\n",
    "\n",
    "sorted_y_timesteps = test_y[timestep_col].unique()\n",
    "sorted_y_timesteps.sort()\n",
    "\n",
    "x_timesteps_per_year = {'quarter': 4, 'semi': 2, 'annual': 1}[time]\n",
    "\n",
    "file_name = f'clean_{time}_{loc}'\n",
    "data_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "#data_gdf = gpd.read_file(data_path)\n",
    "\n",
    "test_x = data_gdf[(data_gdf['year'] > last_train_year) &\n",
    "                  (data_gdf['year'] <= last_train_year + test_years)][x_idx_cols]\n",
    "\n",
    "starting_x_timestep = int(test_x[timestep_col].min())\n",
    "\n",
    "test_timesteps_per_year = max(y_timesteps_per_year, x_timesteps_per_year)\n",
    "test_timesteps = test_timesteps_per_year * test_years\n",
    "\n",
    "x_repeats = int(test_timesteps_per_year / x_timesteps_per_year)\n",
    "y_repeats = int(test_timesteps_per_year / y_timesteps_per_year)\n",
    "\n",
    "sorted_x_timesteps = test_x[timestep_col].unique()\n",
    "sorted_x_timesteps.sort()\n",
    "\n",
    "x_timesteps = [timestep for timestep in sorted_x_timesteps for _ in range(x_repeats)]\n",
    "\n",
    "y_timesteps = [timestep for timestep in sorted_y_timesteps for _ in range(y_repeats)]\n",
    "\n",
    "\n",
    "best_model = 'n0.3_samp50_lr0.01_hs50_10_lb5'\n",
    "noise = 0.3\n",
    "perturbation_samples = 50\n",
    "hidden_sizes = [50, 10]\n",
    "lookback_years=5\n",
    "learning_rate=0.01\n",
    "add_spacetime=True\n",
    "add_svi=True\n",
    "epochs = 3000\n",
    "seed = 360\n",
    "time_window = lookback_years\n",
    "timesteps_per_year = 1\n",
    "first_train_eval_year = 2013\n",
    "last_train_eval_year = 2017\n",
    "batch_dim_size = (last_train_eval_year - first_train_eval_year + 1)*timesteps_per_year\n",
    "validation_year = 2018\n",
    "first_test_year = 2019\n",
    "last_test_year = 2020\n",
    "\n",
    "\n",
    "multiindexed_gdf = data_gdf.set_index(['geoid', 'timestep'])\n",
    "multiindexed_gdf['timestep'] = multiindexed_gdf.index.get_level_values('timestep')\n",
    "num_geoids = len(data_gdf['geoid'].unique())\n",
    "\n",
    "train_shape = (num_geoids, time_window, len(features_only))\n",
    "\n",
    "train_x_BSF_flat, train_y_BS = make_data(multiindexed_gdf, first_train_eval_year, last_train_eval_year,\n",
    "                                                  time_window, features_only, train_shape, pred_lag=timesteps_per_year)\n",
    "\n",
    "valid_x_BSF_flat, valid_y_BS = make_data(multiindexed_gdf, validation_year, validation_year,\n",
    "                                         time_window, features_only, train_shape, pred_lag=timesteps_per_year)\n",
    "\n",
    "test_x_BSF_flat, test_y_BS = make_data(multiindexed_gdf, first_test_year, last_test_year,\n",
    "                                       time_window, features_only, train_shape, pred_lag=timesteps_per_year)\n",
    "\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "norm_layer.adapt(train_x_BSF_flat)\n",
    "train_x_BSF_flat = norm_layer(train_x_BSF_flat)\n",
    "valid_x_BSF_flat = norm_layer(valid_x_BSF_flat)\n",
    "test_x_BSF_flat = norm_layer(test_x_BSF_flat)\n",
    "\n",
    "top_100_idx_func = partial(top_k_idx, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73984aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 06:41:47.048612: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-06 06:41:47.048667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: s1cmp008.pax.tufts.edu\n",
      "2023-07-06 06:41:47.048677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: s1cmp008.pax.tufts.edu\n",
      "2023-07-06 06:41:47.048843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 515.65.1\n",
      "2023-07-06 06:41:47.048879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 515.65.1\n",
      "2023-07-06 06:41:47.048886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 515.65.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual_tract_normal_2000_-auto_200_0.01\n",
      "annual_tract_normal_2000_-auto_400_0.01\n",
      "annual_tract_normal_2010_-auto_200_0.01\n",
      "annual_tract_normal_2010_-auto_400_0.01\n",
      "annual_tract_poisson_2000_-auto_200_0.01\n",
      "annual_tract_poisson_2000_-auto_400_0.01\n",
      "annual_tract_poisson_2010_-auto_200_0.01\n",
      "annual_tract_poisson_2010_-auto_400_0.01\n"
     ]
    }
   ],
   "source": [
    "best_elbo = -np.inf\n",
    "for lr in ['0.01','0.001']:\n",
    "    for model in ['normal', 'poisson']:\n",
    "        for start_year in ['2000','2010']:\n",
    "            for cov in ['-auto','all']:\n",
    "                for num_inducing in ['200','400']:\n",
    "\n",
    "                    this_run = run_template.format(time=time, loc=loc,\n",
    "                                                   model=model, start_year=start_year,\n",
    "                                                   cov=cov,\n",
    "                                                   num_inducing=num_inducing, lr=lr)\n",
    "                    try:\n",
    "                        with open(os.path.join(log_dir, this_run, 'model.mod'), 'rb') as f:\n",
    "                            predictor = pickle.load(f)\n",
    "                        with open(os.path.join(log_dir, this_run, 'stats.csv'), 'rb') as f:\n",
    "                            stats = pd.read_csv(f)\n",
    "                            elbo = stats.iloc[-1, :][['elbo']].values[0]\n",
    "                    except(FileNotFoundError):\n",
    "                        print(os.path.join(log_dir,this_run))\n",
    "                        continue\n",
    "\n",
    "                    if elbo > best_elbo:\n",
    "                        best_elbo = elbo\n",
    "                        print(this_run)\n",
    "                        best_predictor = copy.deepcopy(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c487e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     sampled_test \u001b[38;5;241m=\u001b[39m test_y_time\u001b[38;5;241m.\u001b[39mset_index(geography_col)\u001b[38;5;241m.\u001b[39mloc[sampled_index, outcome_col]\n\u001b[1;32m     21\u001b[0m     sampled_pred \u001b[38;5;241m=\u001b[39m pred_df\u001b[38;5;241m.\u001b[39mloc[sampled_index]\n\u001b[0;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfixed_top_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     23\u001b[0m     sampled_xtops\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     25\u001b[0m xtop_ptiles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(sampled_xtops, [\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m97.5\u001b[39m])\n",
      "File \u001b[0;32m~/code/opioid-overdose-models/zinf_gp/metrics.py:42\u001b[0m, in \u001b[0;36mfixed_top_X\u001b[0;34m(true_qtr_val, pred_qtr_val, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m bootstrapped_tied_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(tied_top_predicted\u001b[38;5;241m.\u001b[39mindex, (\u001b[38;5;241m1000\u001b[39m, num_tied_spots))\n\u001b[1;32m     39\u001b[0m bootstrapped_all_indices \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mIndex\u001b[38;5;241m.\u001b[39munion(undisputed_top_predicted\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m     40\u001b[0m                                            bootstrap_index) \u001b[38;5;28;01mfor\u001b[39;00m bootstrap_index \u001b[38;5;129;01min\u001b[39;00m bootstrapped_tied_indices]\n\u001b[0;32m---> 42\u001b[0m bootstrapped_absolute \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([np\u001b[38;5;241m.\u001b[39mabs(top_X_true\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m-\u001b[39m true_qtr_val[indices]\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     43\u001b[0m                                  \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m bootstrapped_all_indices])\n\u001b[1;32m     44\u001b[0m bootstrapped_ratio \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([np\u001b[38;5;241m.\u001b[39mabs(true_qtr_val[indices])\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(top_X_true)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     45\u001b[0m                               \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m bootstrapped_all_indices])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_possible_absolute, best_possible_ratio, bootstrapped_absolute, bootstrapped_ratio\n",
      "File \u001b[0;32m~/code/opioid-overdose-models/zinf_gp/metrics.py:42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m bootstrapped_tied_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(tied_top_predicted\u001b[38;5;241m.\u001b[39mindex, (\u001b[38;5;241m1000\u001b[39m, num_tied_spots))\n\u001b[1;32m     39\u001b[0m bootstrapped_all_indices \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mIndex\u001b[38;5;241m.\u001b[39munion(undisputed_top_predicted\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m     40\u001b[0m                                            bootstrap_index) \u001b[38;5;28;01mfor\u001b[39;00m bootstrap_index \u001b[38;5;129;01min\u001b[39;00m bootstrapped_tied_indices]\n\u001b[0;32m---> 42\u001b[0m bootstrapped_absolute \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([np\u001b[38;5;241m.\u001b[39mabs(top_X_true\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m-\u001b[39m \u001b[43mtrue_qtr_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m                                  \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m bootstrapped_all_indices])\n\u001b[1;32m     44\u001b[0m bootstrapped_ratio \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([np\u001b[38;5;241m.\u001b[39mabs(true_qtr_val[indices])\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(top_X_true)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     45\u001b[0m                               \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m bootstrapped_all_indices])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_possible_absolute, best_possible_ratio, bootstrapped_absolute, bootstrapped_ratio\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/pandas/core/generic.py:11512\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.sum\u001b[0;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11493\u001b[0m \u001b[38;5;129m@doc\u001b[39m(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m  11494\u001b[0m     _num_doc,\n\u001b[1;32m  11495\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the sum of the values over the requested axis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11510\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11511\u001b[0m ):\n\u001b[0;32m> 11512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/pandas/core/generic.py:11280\u001b[0m, in \u001b[0;36mNDFrame.sum\u001b[0;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\n\u001b[1;32m  11273\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11274\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11278\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11279\u001b[0m ):\n\u001b[0;32m> 11280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_count_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnansum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/pandas/core/generic.py:11263\u001b[0m, in \u001b[0;36mNDFrame._min_count_stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m  11261\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_axis_number\n\u001b[0;32m> 11263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  11265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  11266\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  11267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  11268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  11269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  11270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/pandas/core/series.py:4666\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4662\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4664\u001b[0m     )\n\u001b[1;32m   4665\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4666\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/pandas/core/nanops.py:86\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f: F) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m F:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     88\u001b[0m         obj_iter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain(args, kwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck(obj) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m obj_iter):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xtops = []\n",
    "for year in range(test_years):\n",
    "    xtop_year = []\n",
    "    max_timesteps = max(x_timesteps_per_year, y_timesteps_per_year)\n",
    "    for x_time, y_time in zip(x_timesteps[year * max_timesteps:(year + 1) * max_timesteps],\n",
    "                              y_timesteps[year * max_timesteps:(year + 1) * max_timesteps]):\n",
    "        test_x_time = test_x[test_x[timestep_col] == x_time]\n",
    "        test_y_time = test_y[test_y[timestep_col] == y_time]\n",
    "        _, _, _, fmean, fvar, gmean, gvar, _, _ = best_predictor.build_predict(test_x_time.loc[:, features_only].values)\n",
    "        g_cond = tf.math.softplus(fmean * normcdf(gmean)).numpy()\n",
    "        pred_df = pd.Series(g_cond.squeeze(), index=test_x_time[geography_col])\n",
    "\n",
    "\n",
    "        y_index = test_y_time[geography_col]\n",
    "        sampled_size = int(0.95*len(y_index))\n",
    "        assert(sampled_size==1539)\n",
    "        sampled_xtops = []\n",
    "        for _ in range(100):\n",
    "            sampled_index = np.random.choice(y_index, sampled_size,replace=False)\n",
    "            sampled_test = test_y_time.set_index(geography_col).loc[sampled_index, outcome_col]\n",
    "            sampled_pred = pred_df.loc[sampled_index]\n",
    "            result = fixed_top_X(sampled_test, sampled_pred, 100)[-1]\n",
    "            sampled_xtops.append(result)\n",
    "\n",
    "        xtop_ptiles = np.percentile(sampled_xtops, [2.5, 50, 97.5])\n",
    "        xtop_year.append(xtop_ptiles)\n",
    "    annual_avg = np.array(xtop_year).mean(axis=0)\n",
    "    xtops.append(annual_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a0a9fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b263b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.44046947, 0.45405563, 0.47257506]),\n",
       " array([0.43850162, 0.45537507, 0.48084863])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24474f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtops = []\n",
    "maes = []\n",
    "rmses = []\n",
    "preds = []\n",
    "for year in range(test_years):\n",
    "    xtop_year = []\n",
    "    max_timesteps = max(x_timesteps_per_year, y_timesteps_per_year)\n",
    "    for x_time, y_time in zip(x_timesteps[year * max_timesteps:(year + 1) * max_timesteps],\n",
    "                              y_timesteps[year * max_timesteps:(year + 1) * max_timesteps]):\n",
    "        test_x_time = test_x[test_x[timestep_col] == x_time]\n",
    "        test_y_time = test_y[test_y[timestep_col] == y_time]\n",
    "        _, _, _, fmean, fvar, gmean, gvar, _, _ = best_predictor.build_predict(test_x_time.loc[:, features_only].values)\n",
    "        g_cond = tf.math.softplus(fmean * normcdf(gmean)).numpy()\n",
    "        pred_df = pd.Series(g_cond.squeeze(), index=test_x_time[geography_col])\n",
    "        preds.append(pred_df)\n",
    "\n",
    "        result = fixed_top_X(test_y_time.set_index(geography_col).loc[:, outcome_col], pred_df, 100)[-1]\n",
    "        \n",
    "        rmses.append(sqrt(mean_squared_error(test_y_time.set_index(geography_col).loc[:, outcome_col], pred_df)))\n",
    "        \n",
    "        maes.append(mean_absolute_error(test_y_time.set_index(geography_col).loc[:, outcome_col], pred_df))\n",
    "\n",
    "        xtop_year.append(result)\n",
    "    annual_avg = np.array(xtop_year).mean(axis=0)\n",
    "    xtops.append(annual_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ee2ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "this_2019 = multiindexed_gdf.loc[idx[:,19],:].drop(columns='timestep').reset_index().set_index('geoid')['deaths']\n",
    "this_2020 = multiindexed_gdf.loc[idx[:,20],:].drop(columns='timestep').reset_index().set_index('geoid')['deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77364b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 s, sys: 176 ms, total: 1min\n",
      "Wall time: 59.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bprs_2019=[]\n",
    "bprs_2020=[]\n",
    "rng = np.random.default_rng(seed=360)\n",
    "removed_tracts = 250\n",
    "num_tracts = test_x_BSF_flat.shape[1]\n",
    "num_sampled = num_tracts - removed_tracts\n",
    "K=100\n",
    "\n",
    "for _ in range(100):\n",
    "    sampled_indicies = rng.choice(range(num_tracts), size=num_sampled, replace=False)\n",
    "    \n",
    "    bprs_2019.append(fixed_top_X_new(this_2019[sampled_indicies],\n",
    "                            preds[0][sampled_indicies],\n",
    "                            X=K)[-1])\n",
    "    bprs_2020.append(fixed_top_X_new(this_2020[sampled_indicies],\n",
    "                            preds[1][sampled_indicies],\n",
    "                            X=K)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c05148ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43938636480679005, 0.46125555906681526, 0.4868839017524691)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bprs = (np.array(bprs_2019)+np.array(bprs_2020))/2\n",
    "np.percentile(avg_bprs,2.5), np.mean(avg_bprs), np.percentile(avg_bprs, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d5fe622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4444444444444446, 0.45290581162324633]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2791d9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44867512803384546"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xtops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56eb675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4444444444444446, 0.45290581162324633]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ead7ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44867512803384546"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xtops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4efd9c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1334389263152322"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1301558e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4415631203967694"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c282a322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[geoid\n",
       " 25001010100    0.755169\n",
       " 25001010206    0.755858\n",
       " 25001010208    0.754911\n",
       " 25001010304    0.755814\n",
       " 25001010306    0.756159\n",
       "                  ...   \n",
       " 25027761100    0.755977\n",
       " 25027761200    0.756139\n",
       " 25027761300    0.756042\n",
       " 25027761401    0.755985\n",
       " 25027761402    0.756044\n",
       " Length: 1620, dtype: float64,\n",
       " geoid\n",
       " 25001010100    0.796505\n",
       " 25001010206    0.797219\n",
       " 25001010208    0.796238\n",
       " 25001010304    0.797173\n",
       " 25001010306    0.797530\n",
       "                  ...   \n",
       " 25027761100    0.797342\n",
       " 25027761200    0.797510\n",
       " 25027761300    0.797410\n",
       " 25027761401    0.797350\n",
       " 25027761402    0.797412\n",
       " Length: 1620, dtype: float64]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97707fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_top_X_new(true_qtr_val, pred_qtr_val, X=10):\n",
    "    top_X_predicted = pred_qtr_val.sort_values(ascending=False).iloc[:X]\n",
    "    top_X_true = true_qtr_val.sort_values(ascending=False).iloc[:X]\n",
    "\n",
    "    undisputed_top_predicted = top_X_predicted[top_X_predicted > top_X_predicted.min()]\n",
    "    num_tied_spots = X - len(undisputed_top_predicted)\n",
    "    undisputed_top_true = top_X_true[top_X_true > top_X_true.min()]\n",
    "    num_true_ties = X - len(undisputed_top_true)\n",
    "\n",
    "    tied_top_predicted = pred_qtr_val[pred_qtr_val == top_X_predicted.min()]\n",
    "    tied_top_true = true_qtr_val[true_qtr_val == top_X_true.min()]\n",
    "\n",
    "    error_in_top_true_ties = np.abs(tied_top_true - pred_qtr_val[tied_top_true.index]).sort_values(ascending=True)\n",
    "    error_in_top_pred_ties = np.abs(true_qtr_val[tied_top_predicted.index] - tied_top_predicted).sort_values(\n",
    "        ascending=True)\n",
    "    top_true_tied_geoids = error_in_top_true_ties.iloc[:num_true_ties].index\n",
    "    top_pred_tied_geoids = error_in_top_pred_ties.iloc[:num_tied_spots].index\n",
    "\n",
    "    best_possible_top_true_geoids = pd.Index.union(undisputed_top_true.index, top_true_tied_geoids)\n",
    "    best_possible_top_pred_geoids = pd.Index.union(undisputed_top_predicted.index, top_pred_tied_geoids)\n",
    "\n",
    "    # True values of GEOIDS with highest actual deaths. If ties, finds tied locations that match preds best\n",
    "    best_possible_true = true_qtr_val[best_possible_top_true_geoids]\n",
    "    best_possible_pred = true_qtr_val[best_possible_top_pred_geoids]\n",
    "    assert (len(best_possible_true) == X)\n",
    "    assert (len(best_possible_pred) == X)\n",
    "\n",
    "    best_possible_absolute = np.abs(best_possible_true.sum() - best_possible_pred.sum())\n",
    "    best_possible_ratio = np.abs(best_possible_pred).sum() / np.abs(best_possible_true).sum()\n",
    "\n",
    "    bootstrapped_tied_indices = np.random.choice(tied_top_predicted.index, (1000, num_tied_spots))\n",
    "    this_idx = undisputed_top_predicted.index.values\n",
    "    bootstrapped_all_indices = [np.concatenate((this_idx,bootstrap_index)) for bootstrap_index in bootstrapped_tied_indices]\n",
    "    #bootstrapped_all_indices = [pd.Index.union(undisputed_top_predicted.index,\n",
    "    #                                           bootstrap_index) for bootstrap_index in bootstrapped_tied_indices]\n",
    "    \n",
    "    denominator =  top_X_true.sum()\n",
    "    numerators = [true_qtr_val[indicies].sum() for indicies in bootstrapped_all_indices] \n",
    "\n",
    "    bootstrapped_absolute = np.mean([np.abs(denominator - numerator)\n",
    "                                     for numerator in numerators])\n",
    "    bootstrapped_ratio = np.mean([numerator / denominator\n",
    "                                  for numerator in numerators])\n",
    "\n",
    "    return best_possible_absolute, best_possible_ratio, bootstrapped_absolute, bootstrapped_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2b4cdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geoid\n",
       "25001010100    0.755169\n",
       "25001010206    0.755858\n",
       "25001010208    0.754911\n",
       "25001010304    0.755814\n",
       "25001010306    0.756159\n",
       "                 ...   \n",
       "25027761100    0.755977\n",
       "25027761200    0.756139\n",
       "25027761300    0.756042\n",
       "25027761401    0.755985\n",
       "25027761402    0.756044\n",
       "Length: 1620, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06afbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
