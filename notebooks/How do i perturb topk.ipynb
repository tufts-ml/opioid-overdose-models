{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c69b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b842233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2023 The Google Research Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Introduces differentiation via perturbations.\n",
    "\n",
    "Example of usage:\n",
    "\n",
    "  @perturbed\n",
    "  def sign_or(x, axis=-1):\n",
    "    s = tf.cast((tf.sign(x) + 1)  / 2.0, dtype=tf.bool)\n",
    "    result = tf.math.reduce_any(s, axis=axis)\n",
    "    return tf.cast(result, dtype=x.dtype) * 2.0 - 1.0\n",
    "\n",
    "http://localhost:8765/notebooks/opioid-overdose-models/notebooks/How%20do%20i%20perturb%20topk.ipynb#\n",
    "Then sign_or is differentiable (unlike what it seems).\n",
    "\n",
    "It is possible to specify the parameters of the perturbations using:\n",
    "  @perturbed(num_samples=1000, sigma=0.1, noise='gumbel')\n",
    "  ...\n",
    "\n",
    "The decorator can also be used directly as a function, for example:\n",
    "  soft_argsort = perturbed(tf.argsort, num_samples=200, sigma=0.01)\n",
    "\"\"\"\n",
    "\n",
    "import functools\n",
    "from typing import Tuple\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "_GUMBEL = 'gumbel'\n",
    "_NORMAL = 'normal'\n",
    "SUPPORTED_NOISES = (_GUMBEL, _NORMAL)\n",
    "\n",
    "\n",
    "def sample_noise_with_gradients(\n",
    "    noise, shape):\n",
    "  \"\"\"Samples a noise tensor according to a distribution with its gradient.\n",
    "\n",
    "  Args:\n",
    "   noise: (str) a type of supported noise distribution.\n",
    "   shape: tf.Tensor<int>, the shape of the tensor to sample.\n",
    "\n",
    "  Returns:\n",
    "   A tuple Tensor<float>[shape], Tensor<float>[shape] that corresponds to the\n",
    "   sampled noise and the gradient of log the underlying probability\n",
    "   distribution function. For instance, for a gaussian noise (normal), the\n",
    "   gradient is equal to the noise itself.\n",
    "\n",
    "  Raises:\n",
    "   ValueError in case the requested noise distribution is not supported.\n",
    "   See perturbations.SUPPORTED_NOISES for the list of supported distributions.\n",
    "  \"\"\"\n",
    "  if noise not in SUPPORTED_NOISES:\n",
    "    raise ValueError('{} noise is not supported. Use one of [{}]'.format(\n",
    "        noise, SUPPORTED_NOISES))\n",
    "\n",
    "  if noise == _GUMBEL:\n",
    "    sampler = tfp.distributions.Gumbel(0.0, 1.0)\n",
    "    samples = sampler.sample(shape)\n",
    "    gradients = 1 - tf.math.exp(-samples)\n",
    "  elif noise == _NORMAL:\n",
    "    sampler = tfp.distributions.Normal(0.0, 1.0)\n",
    "    samples = sampler.sample(shape)\n",
    "    gradients = samples\n",
    "\n",
    "  return samples, gradients\n",
    "\n",
    "\n",
    "def perturbed(func=None,\n",
    "              num_samples = 1000,\n",
    "              sigma = 0.05,\n",
    "              noise = _NORMAL,\n",
    "              batched = True):\n",
    "  \"\"\"Turns a function into a differentiable one via perturbations.\n",
    "\n",
    "  The input function has to be the solution to a linear program for the trick\n",
    "  to work. For instance the maximum function, the logical operators or the ranks\n",
    "  can be expressed as solutions to some linear programs on some polytopes.\n",
    "  If this condition is violated though, the result would not hold and there is\n",
    "  no guarantee on the validity of the obtained gradients.\n",
    "\n",
    "  This function can be used directly or as a decorator.\n",
    "\n",
    "  Args:\n",
    "   func: the function to be turned into a perturbed and differentiable one.\n",
    "    Four I/O signatures for func are currently supported:\n",
    "     If batched is True,\n",
    "      (1) input [B, D1, ..., Dk], output [B, D1, ..., Dk], k >= 1\n",
    "      (2) input [B, D1, ..., Dk], output [B], k >= 1\n",
    "     If batched is False,\n",
    "      (3) input [D1, ..., Dk], output [D1, ..., Dk], k >= 1\n",
    "      (4) input [D1, ..., Dk], output [], k >= 1.\n",
    "   num_samples: the number of samples to use for the expectation computation.\n",
    "   sigma: the scale of the perturbation.\n",
    "   noise: a string representing the noise distribution to be used to sample\n",
    "    perturbations.\n",
    "   batched: whether inputs to the perturbed function will have a leading batch\n",
    "    dimension (True) or consist of a single example (False). Defaults to True.\n",
    "\n",
    "  Returns:\n",
    "   a function has the same signature as func but that can be back propagated.\n",
    "  \"\"\"\n",
    "  # This is a trick to have the decorator work both with and without arguments.\n",
    "  if func is None:\n",
    "    return functools.partial(\n",
    "        perturbed, num_samples=num_samples, sigma=sigma, noise=noise,\n",
    "        batched=batched)\n",
    "\n",
    "  @functools.wraps(func)\n",
    "  def wrapper(input_tensor, *args, **kwargs):\n",
    "    @tf.custom_gradient\n",
    "    def forward(input_tensor, *args, **kwargs):\n",
    "      \"\"\"The differentiation by perturbation core routine.\"\"\"\n",
    "      original_input_shape = tf.shape(input_tensor)\n",
    "      if batched:\n",
    "        tf.debugging.assert_rank_at_least(\n",
    "            input_tensor, 2, 'Batched inputs must have at least rank two')\n",
    "      else:  # Adds dummy batch dimension internally.\n",
    "        input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "      input_shape = tf.shape(input_tensor)  # [B, D1, ... Dk], k >= 1\n",
    "      perturbed_input_shape = tf.concat([[num_samples], input_shape], axis=0)\n",
    "\n",
    "      noises = sample_noise_with_gradients(noise, perturbed_input_shape)\n",
    "      additive_noise, noise_gradient = tuple(\n",
    "          [tf.cast(noise, dtype=input_tensor.dtype) for noise in noises])\n",
    "      perturbed_input = tf.expand_dims(input_tensor, 0) + sigma * additive_noise\n",
    "\n",
    "      # [N, B, D1, ..., Dk] -> [NB, D1, ..., Dk].\n",
    "      flat_batch_dim_shape = tf.concat([[-1], input_shape[1:]], axis=0)\n",
    "      perturbed_input = tf.reshape(perturbed_input, flat_batch_dim_shape)\n",
    "      # Calls user-defined function in a perturbation agnostic manner.\n",
    "      perturbed_output = func(perturbed_input, *args, **kwargs)\n",
    "      # [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\n",
    "      perturbed_input = tf.reshape(perturbed_input, perturbed_input_shape)\n",
    "      # Either\n",
    "      #   (Default case): [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk]\n",
    "      # or\n",
    "      #   (Full-reduce case) [NB] -> [N, B]\n",
    "        \n",
    "      perturbed_output_shape = tf.concat(\n",
    "          [[num_samples], [-1], tf.shape(perturbed_output)[1:]], axis=0)\n",
    "      perturbed_output = tf.reshape(perturbed_output, perturbed_output_shape)\n",
    "\n",
    "      forward_output = tf.reduce_mean(perturbed_output, axis=0)\n",
    "      if not batched:  # Removes dummy batch dimension.\n",
    "        forward_output = forward_output[0]\n",
    "\n",
    "      def grad(dy):\n",
    "        \"\"\"Compute the gradient of the expectation via integration by parts.\"\"\"\n",
    "        output, noise_grad = perturbed_output, noise_gradient\n",
    "        # Adds dummy feature/channel dimension internally.\n",
    "        if perturbed_input.shape.rank > output.shape.rank:\n",
    "          dy = tf.expand_dims(dy, axis=-1)\n",
    "          output = tf.expand_dims(output, axis=-1)\n",
    "        # Adds dummy batch dimension internally.\n",
    "        if not batched:\n",
    "          dy = tf.expand_dims(dy, axis=0)\n",
    "        # Flattens [D1, ..., Dk] to a single feat dim [D].\n",
    "        flatten = lambda t: tf.reshape(t, (tf.shape(t)[0], tf.shape(t)[1], -1))\n",
    "        dy = tf.reshape(dy, (tf.shape(dy)[0], -1))  # (B, D)\n",
    "        output = flatten(output)  # (N, B, D)\n",
    "        noise_grad = flatten(noise_grad)  # (N, B, D)\n",
    "\n",
    "        g = tf.einsum('nbd,nb->bd', noise_grad,\n",
    "                      tf.einsum('nbd,bd->nb', output, dy))\n",
    "        g /= sigma * num_samples\n",
    "        return tf.reshape(g, original_input_shape)\n",
    "\n",
    "      return forward_output, grad\n",
    "\n",
    "    return forward(input_tensor, *args, **kwargs)\n",
    "\n",
    "  return wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.random.normal((5, 1620), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "73033389",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=500\n",
    "sigma=0.05\n",
    "batched=True\n",
    "noise='normal'\n",
    "\n",
    "func = top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bd321125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_idx(input_BD, **kwargs):\n",
    "    \n",
    "    _, idx_BD = tf.math.top_k(input_BD, **kwargs)\n",
    "    input_depth = input_BD.shape[-1]\n",
    "    one_hot_idx_BKD = tf.one_hot(idx_BD, input_depth)\n",
    "    #Sum over k dimension so we dont have to worry about sorting\n",
    "    k_hot_idx_BD = tf.reduce_sum(one_hot_idx_BKD, axis=-2)\n",
    "    \n",
    "    \n",
    "    return k_hot_idx_BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1e5ca558",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_idx = partial(top_k_idx, k=100)\n",
    "perturbed_top_100 = perturbed(top_100_idx,\n",
    "                         num_samples=num_samples,\n",
    "                         sigma=sigma,\n",
    "                         noise=noise,\n",
    "                         batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f34de5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1620), dtype=float32, numpy=\n",
       "array([[0.  , 1.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.23, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , ..., 1.  , 0.  , 0.  ]], dtype=float32)>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pout = perturbed_top_100(rand_input)\n",
    "pout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b4260a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.9999993 , 0.9999994 , 0.9999994 , 0.99999934, 0.9999994 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pout[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8474dd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Pack as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Pack] name: packed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m perturbed_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_input, perturbed_input_shape)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Either\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#   (Default case): [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# or\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#   (Full-reduce case) [NB] -> [N, B]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m perturbed_output_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[0;32m---> 28\u001b[0m     [[num_samples], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_output\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m perturbed_output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_output, perturbed_output_shape)\n\u001b[1;32m     31\u001b[0m forward_output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(perturbed_output, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Pack as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Pack] name: packed"
     ]
    }
   ],
   "source": [
    "      original_input_shape = tf.shape(input_tensor)\n",
    "      if batched:\n",
    "        tf.debugging.assert_rank_at_least(\n",
    "            input_tensor, 2, 'Batched inputs must have at least rank two')\n",
    "      else:  # Adds dummy batch dimension internally.\n",
    "        input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "      input_shape = tf.shape(input_tensor)  # [B, D1, ... Dk], k >= 1\n",
    "      perturbed_input_shape = tf.concat([[num_samples], input_shape], axis=0)\n",
    "\n",
    "      noises = sample_noise_with_gradients(noise, perturbed_input_shape)\n",
    "      additive_noise, noise_gradient = tuple(\n",
    "          [tf.cast(noise, dtype=input_tensor.dtype) for noise in noises])\n",
    "      perturbed_input = tf.expand_dims(input_tensor, 0) + sigma * additive_noise\n",
    "\n",
    "      # [N, B, D1, ..., Dk] -> [NB, D1, ..., Dk].\n",
    "      flat_batch_dim_shape = tf.concat([[-1], input_shape[1:]], axis=0)\n",
    "      perturbed_input = tf.reshape(perturbed_input, flat_batch_dim_shape)\n",
    "      # Calls user-defined function in a perturbation agnostic manner.\n",
    "      perturbed_output = func(perturbed_input,)\n",
    "      # [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\n",
    "      perturbed_input = tf.reshape(perturbed_input, perturbed_input_shape)\n",
    "      # Either\n",
    "      #   (Default case): [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk]\n",
    "      # or\n",
    "      #   (Full-reduce case) [NB] -> [N, B]\n",
    "        \n",
    "      perturbed_output_shape = tf.concat(\n",
    "          [[num_samples], [-1], tf.shape(perturbed_output)[1:]], axis=0)\n",
    "      perturbed_output = tf.reshape(perturbed_output, perturbed_output_shape)\n",
    "\n",
    "      forward_output = tf.reduce_mean(perturbed_output, axis=0)\n",
    "      if not batched:  # Removes dummy batch dimension.\n",
    "        forward_output = forward_output[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3f33c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TopKV2' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperturbed_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TopKV2' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "perturbed_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20de3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.top_k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "175bf435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.nn_ops.top_k(input, k=1, sorted=True, name=None)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v2.nn.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766555a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
