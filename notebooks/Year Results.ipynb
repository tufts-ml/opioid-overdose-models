{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2c7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 16:18:46.869805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 16:18:46.984407: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-08 16:18:46.989612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-08 16:18:46.989626: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-08 16:18:47.019989: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-08 16:18:48.660403: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 16:18:48.660479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 16:18:48.660486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Run a zero-inflated GP on opioid data\"\"\"\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "idx = pd.IndexSlice\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import copy\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "code_dir = '/cluster/home/kheuto01/code/zero-inflated-gp/'\n",
    "sys.path.append(code_dir)\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from onoffgpf import OnOffSVGP, OnOffLikelihood\n",
    "\n",
    "import pickle\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    https://stackoverflow.com/a/4913653/1748679\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "    return c * r\n",
    "\n",
    "\n",
    "def top_X(y_true, y_pred, X=10):\n",
    "    top_X_predicted = y_pred.sort_values(ascending=False)[:X]\n",
    "    top_X_true = y_true.sort_values(ascending=False)[:X]\n",
    "\n",
    "    undisputed_top_predicted = top_X_predicted[top_X_predicted > top_X_predicted.min()]\n",
    "    num_tied_spots = X - len(undisputed_top_predicted)\n",
    "    undisputed_top_true = top_X_true[top_X_true > top_X_true.min()]\n",
    "    num_true_ties = X - len(undisputed_top_true)\n",
    "\n",
    "    tied_top_predicted = top_X_predicted[top_X_predicted == top_X_predicted.min()]\n",
    "    tied_top_true = top_X_true[top_X_true == top_X_true.min()]\n",
    "\n",
    "    error_in_top_true_ties = np.abs(tied_top_true - y_pred[tied_top_true.index]).sort_values(ascending=True)\n",
    "    error_in_top_pred_ties = np.abs(y_true[tied_top_predicted.index] - tied_top_predicted).sort_values(ascending=True)\n",
    "    top_true_tied_geoids = error_in_top_true_ties[:num_true_ties].index\n",
    "    top_pred_tied_geoids = error_in_top_pred_ties[:num_tied_spots].index\n",
    "\n",
    "    best_possible_top_true_geoids = pd.Index.union(undisputed_top_true.index, top_true_tied_geoids)\n",
    "    best_possible_top_pred_geoids = pd.Index.union(undisputed_top_predicted.index, top_pred_tied_geoids)\n",
    "\n",
    "    # True values of GEOIDS with highest actual deaths. If ties, finds tied locations that match preds best\n",
    "    best_possible_true = y_true[best_possible_top_true_geoids]\n",
    "    best_possible_pred = y_true[best_possible_top_pred_geoids]\n",
    "\n",
    "    assert (len(best_possible_true) == X)\n",
    "    assert (len(best_possible_pred) == X)\n",
    "\n",
    "    best_possible_absolute = np.abs(best_possible_true.sum() - best_possible_pred.sum())\n",
    "    best_possible_ratio = np.abs(best_possible_pred).sum() / np.abs(best_possible_true).sum()\n",
    "\n",
    "    bootstrapped_tied_indices = np.random.choice(tied_top_predicted.index, (1000, num_tied_spots))\n",
    "    bootstrapped_all_indices = [pd.Index.union(undisputed_top_predicted.index,\n",
    "                                               bootstrap_index) for bootstrap_index in bootstrapped_tied_indices]\n",
    "\n",
    "    bootstrapped_absolute = np.mean([np.abs(top_X_true.sum() - y_true[indices].sum())\n",
    "                                     for indices in bootstrapped_all_indices])\n",
    "    bootstrapped_ratio = np.mean([np.abs(y_true[indices]).sum() / np.abs(top_X_true).sum()\n",
    "                                  for indices in bootstrapped_all_indices])\n",
    "\n",
    "    return best_possible_absolute, best_possible_ratio, bootstrapped_absolute, bootstrapped_ratio\n",
    "\n",
    "def normcdf(x):\n",
    "    return 0.5 * (1.0 + tf.math.erf(x / np.sqrt(2.0))) * (1. - 2.e-3) + 1.e-3\n",
    "\n",
    "\n",
    "def fixed_top_X(true_qtr_val, pred_qtr_val, X=10):\n",
    "    top_X_predicted = pred_qtr_val.sort_values(ascending=False)[:X]\n",
    "    top_X_true = true_qtr_val.sort_values(ascending=False)[:X]\n",
    "\n",
    "    undisputed_top_predicted = top_X_predicted[top_X_predicted > top_X_predicted.min()]\n",
    "    num_tied_spots = X - len(undisputed_top_predicted)\n",
    "    undisputed_top_true = top_X_true[top_X_true > top_X_true.min()]\n",
    "    num_true_ties = X - len(undisputed_top_true)\n",
    "\n",
    "    tied_top_predicted = pred_qtr_val[pred_qtr_val == top_X_predicted.min()]\n",
    "    tied_top_true = true_qtr_val[true_qtr_val == top_X_true.min()]\n",
    "\n",
    "    error_in_top_true_ties = np.abs(tied_top_true - pred_qtr_val[tied_top_true.index]).sort_values(ascending=True)\n",
    "    error_in_top_pred_ties = np.abs(true_qtr_val[tied_top_predicted.index] - tied_top_predicted).sort_values(\n",
    "        ascending=True)\n",
    "    top_true_tied_geoids = error_in_top_true_ties[:num_true_ties].index\n",
    "    top_pred_tied_geoids = error_in_top_pred_ties[:num_tied_spots].index\n",
    "\n",
    "    best_possible_top_true_geoids = pd.Index.union(undisputed_top_true.index, top_true_tied_geoids)\n",
    "    best_possible_top_pred_geoids = pd.Index.union(undisputed_top_predicted.index, top_pred_tied_geoids)\n",
    "\n",
    "    # True values of GEOIDS with highest actual deaths. If ties, finds tied locations that match preds best\n",
    "    best_possible_true = true_qtr_val[best_possible_top_true_geoids]\n",
    "    best_possible_pred = true_qtr_val[best_possible_top_pred_geoids]\n",
    "\n",
    "    assert (len(best_possible_true) == X)\n",
    "    assert (len(best_possible_pred) == X)\n",
    "\n",
    "    best_possible_absolute = np.abs(best_possible_true.sum() - best_possible_pred.sum())\n",
    "    best_possible_ratio = np.abs(best_possible_pred).sum() / np.abs(best_possible_true).sum()\n",
    "\n",
    "    bootstrapped_tied_indices = np.random.choice(tied_top_predicted.index, (1000, num_tied_spots))\n",
    "    bootstrapped_all_indices = [pd.Index.union(undisputed_top_predicted.index,\n",
    "                                               bootstrap_index) for bootstrap_index in bootstrapped_tied_indices]\n",
    "\n",
    "    bootstrapped_absolute = np.mean([np.abs(top_X_true.sum() - true_qtr_val[indices].sum())\n",
    "                                     for indices in bootstrapped_all_indices])\n",
    "    bootstrapped_ratio = np.mean([np.abs(true_qtr_val[indices]).sum() / np.abs(top_X_true).sum()\n",
    "                                  for indices in bootstrapped_all_indices])\n",
    "\n",
    "    return best_possible_absolute, best_possible_ratio, bootstrapped_absolute, bootstrapped_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954a91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/cluster/tufts/hugheslab/datasets/NSF_OD/'\n",
    "result_dir = os.path.join(data_dir, 'results_20220606_update')\n",
    "mass_shapefile = os.path.join(data_dir,'shapefiles','MA_2021')\n",
    "\n",
    "svi_file = os.path.join(result_dir, 'svi_month')\n",
    "svi_gdf = gpd.read_file(svi_file)\n",
    "# Call it \"grid_squar\" because geopandas only supports len 10 columns\n",
    "svi_gdf = svi_gdf.rename(columns={'INTPTLAT': 'lat', 'INTPTLON': 'lon', 'GEOID': 'grid_squar'})\n",
    "# Make lat and lon floats\n",
    "svi_gdf.loc[:, 'lat'] = svi_gdf.lat.astype(float)\n",
    "svi_gdf.loc[:, 'lon'] = svi_gdf.lon.astype(float)\n",
    "deaths_gdf = svi_gdf\n",
    "\n",
    "\n",
    "# Used when we just need the unique tracts and their locations\n",
    "just_grid = deaths_gdf.loc[\n",
    "    (deaths_gdf['year'] == 2000) & (deaths_gdf['month'] == 1), ['grid_squar', 'geometry', 'lat', 'lon']]\n",
    "\n",
    "# Calculate each squares neighbors\n",
    "neighbors = {}\n",
    "for _, row in just_grid.iterrows():\n",
    "    just_grid.loc[:, 'haversine'] = just_grid.apply(lambda x: haversine(row['lon'], row['lat'],\n",
    "                                                                        x['lon'], x['lat']),\n",
    "                                                    axis=1)\n",
    "    matching_neighbors = just_grid[just_grid['haversine'] < 8]['grid_squar'].values\n",
    "    neighbors[row['grid_squar']] = matching_neighbors\n",
    "\n",
    "tracts = deaths_gdf['grid_squar'].unique()\n",
    "min_year = deaths_gdf.year.min()\n",
    "max_year = deaths_gdf.year.max()\n",
    "deaths_gdf = deaths_gdf.set_index(['grid_squar', 'year', 'month']).sort_index()\n",
    "\n",
    "month_since_2000 = 0\n",
    "season_since_2000 = 0\n",
    "qtr_since_2000 = 0\n",
    "year_since_2000 = 0\n",
    "for year in range(min_year, max_year + 1):\n",
    "    for month in range(1, 12 + 1):\n",
    "\n",
    "        if month in [1, 2, 3, 4, 5, 6]:\n",
    "            season = 'jan-jun'\n",
    "        else:\n",
    "            season = 'jul-dec'\n",
    "\n",
    "        if month <= 3:\n",
    "            qtr = 1\n",
    "        elif month <= 6:\n",
    "            qtr = 2\n",
    "        elif month <= 9:\n",
    "            qtr = 3\n",
    "        else:\n",
    "            qtr = 4\n",
    "\n",
    "        deaths_gdf.loc[idx[:, year, month], 'month_since_2000'] = month_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'season'] = season\n",
    "        deaths_gdf.loc[idx[:, year, month], 'season_since_2000'] = season_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'quarter'] = qtr\n",
    "        deaths_gdf.loc[idx[:, year, month], 'qtr_since_2000'] = qtr_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'year_since_2000'] = year_since_2000\n",
    "\n",
    "        month_since_2000 += 1\n",
    "\n",
    "        if month in [6, 12]:\n",
    "            season_since_2000 += 1\n",
    "\n",
    "        if month in [3, 6, 9, 12]:\n",
    "            qtr_since_2000 += 1\n",
    "\n",
    "        if month == 12:\n",
    "            year_since_2000 += 1\n",
    "\n",
    "deaths_gdf = deaths_gdf.reset_index()\n",
    "\n",
    "\n",
    "timestep_col = 'year_since_2000'\n",
    " \n",
    "deaths_gdf.loc[:, 'timestep'] = deaths_gdf.loc[:, timestep_col]\n",
    "deaths_gdf = deaths_gdf.set_index(['grid_squar', 'year', timestep_col]).sort_index()\n",
    "deaths_gdf.loc[idx[:, :, :], 'self_t-1'] = deaths_gdf.loc[idx[:, :, :], 'deaths'].shift(1, fill_value=0)\n",
    "unduped_gdf = deaths_gdf[~deaths_gdf.index.duplicated(keep='first')]\n",
    "summed_deaths = deaths_gdf.groupby(level=[0,1,2]).sum()[['deaths']]\n",
    "summed_deaths = summed_deaths.merge(unduped_gdf, how='left', left_index=True, right_index=True,suffixes=[None,'_garbage'])\n",
    "summed_deaths = summed_deaths.drop('deaths_garbage',axis=1)\n",
    "deaths_gdf = summed_deaths\n",
    "for tract in tracts:\n",
    "    deaths_gdf.loc[idx[tract, :, :], 'neighbor_t-1'] = \\\n",
    "        deaths_gdf.loc[idx[neighbors[tract], :, :], 'self_t-1'].groupby(level=['year', timestep_col]).mean().shift(1,\n",
    "                                                                                                                fill_value=0).values\n",
    "\n",
    "timestep = 0\n",
    "\n",
    "\n",
    "deaths_gdf_with_autoregressive = deaths_gdf.reset_index()\n",
    "\n",
    "features = ['grid_squar','year','quarter', 'lat', 'lon', timestep_col, 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "         'svi_pctile', 'neighbors_last_timestep', 'last_timestep']\n",
    "features_no_idx = ['lat', 'lon', timestep_col, 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    " 'svi_pctile', 'neighbors_last_timestep', 'last_timestep']\n",
    "\n",
    "train_x_through_2018 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2018][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "train_y_through_2018 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2018][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "train_x_through_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2019][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "train_y_through_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2019][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "\n",
    "x_just_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2019][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "y_just_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2019][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "x_just_2020 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2020][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "y_just_2020 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2020][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "\n",
    "x_just_2019q1 = deaths_gdf_with_autoregressive[\n",
    "    (deaths_gdf_with_autoregressive['year'] == 2019) & (deaths_gdf_with_autoregressive['quarter'] == 1)][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "y_just_2019q1 = deaths_gdf_with_autoregressive[\n",
    "    (deaths_gdf_with_autoregressive['year'] == 2019) & (deaths_gdf_with_autoregressive['quarter'] == 1)][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c11fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_file = os.path.join(result_dir, 'svi_month')\n",
    "svi_gdf = gpd.read_file(svi_file)\n",
    "# Call it \"grid_squar\" because geopandas only supports len 10 columns\n",
    "svi_gdf = svi_gdf.rename(columns={'INTPTLAT': 'lat', 'INTPTLON': 'lon', 'GEOID': 'grid_squar'})\n",
    "# Make lat and lon floats\n",
    "svi_gdf.loc[:, 'lat'] = svi_gdf.lat.astype(float)\n",
    "svi_gdf.loc[:, 'lon'] = svi_gdf.lon.astype(float)\n",
    "deaths_gdf = svi_gdf\n",
    "\n",
    "# Used when we just need the unique tracts and their locations\n",
    "just_grid = deaths_gdf.loc[\n",
    "    (deaths_gdf['year'] == 2000) & (deaths_gdf['month'] == 1), ['grid_squar', 'geometry', 'lat', 'lon']]\n",
    "\n",
    "# Calculate each squares neighbors\n",
    "neighbors = {}\n",
    "for _, row in just_grid.iterrows():\n",
    "    just_grid.loc[:, 'haversine'] = just_grid.apply(lambda x: haversine(row['lon'], row['lat'],\n",
    "                                                                        x['lon'], x['lat']),\n",
    "                                                    axis=1)\n",
    "    matching_neighbors = just_grid[just_grid['haversine'] < 8]['grid_squar'].values\n",
    "    neighbors[row['grid_squar']] = matching_neighbors\n",
    "\n",
    "tracts = deaths_gdf['grid_squar'].unique()\n",
    "min_year = deaths_gdf.year.min()\n",
    "max_year = deaths_gdf.year.max()\n",
    "deaths_gdf = deaths_gdf.set_index(['grid_squar', 'year', 'month']).sort_index()\n",
    "\n",
    "month_since_2000 = 0\n",
    "season_since_2000 = 0\n",
    "qtr_since_2000 = 0\n",
    "year_since_2000 = 0\n",
    "for year in range(min_year, max_year + 1):\n",
    "    for month in range(1, 12 + 1):\n",
    "\n",
    "        if month in [1, 2, 3, 4, 5, 6]:\n",
    "            season = 'jan-jun'\n",
    "        else:\n",
    "            season = 'jul-dec'\n",
    "\n",
    "        if month <= 3:\n",
    "            qtr = 1\n",
    "        elif month <= 6:\n",
    "            qtr = 2\n",
    "        elif month <= 9:\n",
    "            qtr = 3\n",
    "        else:\n",
    "            qtr = 4\n",
    "\n",
    "        deaths_gdf.loc[idx[:, year, month], 'month_since_2000'] = month_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'season'] = season\n",
    "        deaths_gdf.loc[idx[:, year, month], 'season_since_2000'] = season_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'quarter'] = qtr\n",
    "        deaths_gdf.loc[idx[:, year, month], 'qtr_since_2000'] = qtr_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'year_since_2000'] = year_since_2000\n",
    "\n",
    "        month_since_2000 += 1\n",
    "\n",
    "        if month in [6, 12]:\n",
    "            season_since_2000 += 1\n",
    "\n",
    "        if month in [3, 6, 9, 12]:\n",
    "            qtr_since_2000 += 1\n",
    "\n",
    "        if month == 12:\n",
    "            year_since_2000 += 1\n",
    "\n",
    "deaths_gdf = deaths_gdf.reset_index()\n",
    "timestep_col = 'quarter'\n",
    " \n",
    "deaths_gdf = deaths_gdf.set_index(['grid_squar', 'year', 'quarter']).sort_index()\n",
    "deaths_gdf.loc[idx[:, :, :], 'self_t-1'] = deaths_gdf.loc[idx[:, :, :], 'deaths'].shift(1, fill_value=0)\n",
    "unduped_gdf = deaths_gdf[~deaths_gdf.index.duplicated(keep='first')]\n",
    "summed_deaths = deaths_gdf.groupby(level=[0,1,2]).sum()[['deaths']]\n",
    "summed_deaths = summed_deaths.merge(unduped_gdf, how='left', left_index=True, right_index=True,suffixes=[None,'_garbage'])\n",
    "summed_deaths = summed_deaths.drop('deaths_garbage',axis=1)\n",
    "deaths_gdf = summed_deaths\n",
    "for tract in tracts:\n",
    "    deaths_gdf.loc[idx[tract, :, :], 'neighbor_t-1'] = \\\n",
    "        deaths_gdf.loc[idx[neighbors[tract], :, :], 'self_t-1'].groupby(level=['year', 'quarter']).mean().shift(1,\n",
    "                                                                                                                fill_value=0).values\n",
    "\n",
    "timestep = 0\n",
    "\n",
    "for year in range(min_year, max_year + 1):\n",
    "    for quarter in range(1, 5):\n",
    "        deaths_gdf.loc[idx[:, year, quarter], 'timestep'] = timestep\n",
    "        timestep += 1\n",
    "\n",
    "deaths_gdf_with_autoregressive = deaths_gdf.reset_index()\n",
    "\n",
    "features = ['grid_squar','year','quarter', 'lat', 'lon', timestep_col, 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "         'svi_pctile', 'neighbors_last_timestep', 'last_timestep']\n",
    "features_no_idx = ['lat', 'lon', timestep_col, 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    " 'svi_pctile', 'neighbors_last_timestep', 'last_timestep']\n",
    "\n",
    "train_x_through_2018 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2018][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "train_y_through_2018 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2018][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "train_x_through_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2019][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "train_y_through_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2019][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "\n",
    "x_just_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2019][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "y_just_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2019][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "x_just_2020 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2020][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "y_just_2020 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2020][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "\n",
    "spatial_kernel = gpflow.kernels.RBF(2, active_dims=[0, 1])\n",
    "temporal_kernel = gpflow.kernels.RBF(1, active_dims=[2])\n",
    "\n",
    "x_just_2019q2 = deaths_gdf_with_autoregressive[\n",
    "    (deaths_gdf_with_autoregressive['year'] == 2019) & (deaths_gdf_with_autoregressive['quarter'] == 2)][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "y_just_2019q2 = deaths_gdf_with_autoregressive[\n",
    "    (deaths_gdf_with_autoregressive['year'] == 2019) & (deaths_gdf_with_autoregressive['quarter'] == 2)][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "\n",
    "x_just_2019q3 = deaths_gdf_with_autoregressive[\n",
    "    (deaths_gdf_with_autoregressive['year'] == 2019) & (deaths_gdf_with_autoregressive['quarter'] == 3)][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "y_just_2019q3 = deaths_gdf_with_autoregressive[\n",
    "    (deaths_gdf_with_autoregressive['year'] == 2019) & (deaths_gdf_with_autoregressive['quarter'] == 3)][\n",
    "    ['grid_squar', 'timestep', 'deaths']]\n",
    "\n",
    "x_just_2019q4 = deaths_gdf_with_autoregressive[\n",
    "    (deaths_gdf_with_autoregressive['year'] == 2019) & (deaths_gdf_with_autoregressive['quarter'] == 4)][\n",
    "    ['grid_squar', 'lat', 'lon', 'timestep', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',\n",
    "     'neighbor_t-1', 'self_t-1']]\n",
    "y_just_2019q4 = deaths_gdf_with_autoregressive[\n",
    "    (deaths_gdf_with_autoregressive['year'] == 2019) & (deaths_gdf_with_autoregressive['quarter'] == 4)][\n",
    "    ['grid_squar', 'timestep', 'deaths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c567d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "mass_shapefile = os.path.join(data_dir,'shapefiles','MA_2021')\n",
    "town_shapefile = os.path.join(data_dir,'shapefiles','MA_2020_Towns',\n",
    "                              'CENSUS2020TOWNS_POLY.shp')\n",
    "\n",
    "tract_gdf = gpd.read_file(mass_shapefile)\n",
    "tract_gdf.loc[:,'TRACTCE'] = tract_gdf['TRACTCE'].astype(int)\n",
    "\n",
    "town_shapes = gpd.read_file(town_shapefile)\n",
    "towns_lat_lon = town_shapes.to_crs({'init': 'epsg:4269'}) \n",
    "\n",
    "svi_file = os.path.join(result_dir,'svi_month')\n",
    "svi_gdf = gpd.read_file(svi_file)\n",
    "just_tracts = svi_gdf.loc[(svi_gdf['year']==2000)&(svi_gdf['month']==1),['GEOID','geometry', 'INTPTLAT', 'INTPTLON']]\n",
    "just_tracts['points'] = just_tracts.apply(lambda x: Point(np.float(x['INTPTLON']), np.float(x['INTPTLAT'])), axis=1)\n",
    "just_towns = deaths_gdf.reset_index().loc[(deaths_gdf.reset_index()['year']==2000)&(deaths_gdf.reset_index()['month']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ada394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 16:22:27.897440: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-02-08 16:22:27.897484: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: p1cmp078.pax.tufts.edu\n",
      "2023-02-08 16:22:27.897492: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: p1cmp078.pax.tufts.edu\n",
      "2023-02-08 16:22:27.897623: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.47.3\n",
      "2023-02-08 16:22:27.897656: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.47.3\n",
      "2023-02-08 16:22:27.897662: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.47.3\n",
      "2023-02-08 16:22:27.898081: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/cluster/home/kheuto01/try_thing_yr/model.mod','rb') as f:\n",
    "    m_year = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a360b308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40.0, 0.40298507462686567, 40.0, 0.4029850746268656)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_2019 = m_year.predict_onoffgp(x_just_2019q1.loc[:, ['lat','lon','timestep','theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile', 'neighbor_t-1', 'self_t-1']].values)\n",
    "sg_2019 = sg_2019[0]\n",
    "pred_2019_df = pd.Series(sg_2019.numpy().squeeze(), index=x_just_2019q1.grid_squar)\n",
    "fixed_top_X(y_just_2019q1.set_index('grid_squar')['deaths'],pred_2019_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5606de58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.0, 0.2413793103448276, 22.0, 0.2413793103448275)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_2019 = m_year.predict_onoffgp(x_just_2019q1.loc[:, ['lat','lon','timestep','theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile', 'neighbor_t-1', 'self_t-1']].values)\n",
    "sg_2019 = sg_2019[0]\n",
    "pred_2019_df = pd.Series(sg_2019.numpy().squeeze(), index=x_just_2019q2.grid_squar)\n",
    "fixed_top_X(y_just_2019q2.set_index('grid_squar')['deaths'],pred_2019_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60f8faf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.0, 0.2727272727272727, 24.0, 0.2727272727272726)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_2019 = m_year.predict_onoffgp(x_just_2019q1.loc[:, ['lat','lon','timestep','theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile', 'neighbor_t-1', 'self_t-1']].values)\n",
    "sg_2019 = sg_2019[0]\n",
    "pred_2019_df = pd.Series(sg_2019.numpy().squeeze(), index=x_just_2019q3.grid_squar)\n",
    "fixed_top_X(y_just_2019q3.set_index('grid_squar')['deaths'],pred_2019_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6da355b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.0, 0.2, 24.0, 0.20000000000000004)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_2019 = m_year.predict_onoffgp(x_just_2019q1.loc[:, ['lat','lon','timestep','theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile', 'neighbor_t-1', 'self_t-1']].values)\n",
    "sg_2019 = sg_2019[0]\n",
    "pred_2019_df = pd.Series(sg_2019.numpy().squeeze(), index=x_just_2019q4.grid_squar)\n",
    "fixed_top_X(y_just_2019q4.set_index('grid_squar')['deaths'],pred_2019_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4395681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27927291442474145"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.4029850746268656,0.2413793103448275,0.2727272727272726,0.20000000000000004])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28707c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_squar</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>0.019381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25001010206</td>\n",
       "      <td>0.031325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25001010208</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25001010304</td>\n",
       "      <td>0.069675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25001010306</td>\n",
       "      <td>0.069675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>25027761100</td>\n",
       "      <td>0.313183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>25027761200</td>\n",
       "      <td>0.072541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>25027761300</td>\n",
       "      <td>0.340030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>25027761401</td>\n",
       "      <td>0.148008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>0.148008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1620 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grid_squar    deaths\n",
       "0     25001010100  0.019381\n",
       "1     25001010206  0.031325\n",
       "2     25001010208  0.017843\n",
       "3     25001010304  0.069675\n",
       "4     25001010306  0.069675\n",
       "...           ...       ...\n",
       "1615  25027761100  0.313183\n",
       "1616  25027761200  0.072541\n",
       "1617  25027761300  0.340030\n",
       "1618  25027761401  0.148008\n",
       "1619  25027761402  0.148008\n",
       "\n",
       "[1620 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0ef27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grid_squar\n",
       "25001010100    0.224602\n",
       "25001010206    0.218860\n",
       "25001010208    0.189577\n",
       "25001010304    0.283480\n",
       "25001010306    0.257300\n",
       "                 ...   \n",
       "25027761100    0.370158\n",
       "25027761200    0.481235\n",
       "25027761300    0.485591\n",
       "25027761401    0.485148\n",
       "25027761402    0.497723\n",
       "Length: 1620, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2019_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413b66fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_squar</th>\n",
       "      <th>timestep</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>25001010206</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>25001010208</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>25001010304</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>25001010306</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35549</th>\n",
       "      <td>25027761100</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35571</th>\n",
       "      <td>25027761200</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35593</th>\n",
       "      <td>25027761300</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35615</th>\n",
       "      <td>25027761401</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35637</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        grid_squar  timestep  deaths\n",
       "19     25001010100      19.0     1.0\n",
       "41     25001010206      19.0     1.0\n",
       "63     25001010208      19.0     0.0\n",
       "85     25001010304      19.0     1.0\n",
       "107    25001010306      19.0     0.0\n",
       "...            ...       ...     ...\n",
       "35549  25027761100      19.0     0.0\n",
       "35571  25027761200      19.0     1.0\n",
       "35593  25027761300      19.0     1.0\n",
       "35615  25027761401      19.0     0.0\n",
       "35637  25027761402      19.0     0.0\n",
       "\n",
       "[1620 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_just_2019q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf9c1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40.0, 0.40298507462686567, 40.0, 0.4029850746268656)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d684a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grid_squar\n",
       "25001010100    0.224602\n",
       "25001010206    0.218860\n",
       "25001010208    0.189577\n",
       "25001010304    0.283480\n",
       "25001010306    0.257300\n",
       "                 ...   \n",
       "25027761100    0.370158\n",
       "25027761200    0.481235\n",
       "25027761300    0.485591\n",
       "25027761401    0.485148\n",
       "25027761402    0.497723\n",
       "Length: 1620, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2019_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e4531fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_squar</th>\n",
       "      <th>timestep</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [grid_squar, timestep, deaths]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_just_2019q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b758245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
