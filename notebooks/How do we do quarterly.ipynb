{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94c01185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import IndexSlice as idx\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/perturbations/'\n",
    "sys.path.append(code_dir)\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/diff_bpr'\n",
    "sys.path.append(code_dir)\n",
    "from top_k import top_k_idx\n",
    "#from make_datasets import make_data\n",
    "from bpr_model import PerturbedBPRModel\n",
    "\n",
    "\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/'\n",
    "sys.path.append(code_dir)\n",
    "from zinf_gp.metrics import normcdf, fixed_top_X\n",
    "\n",
    "\n",
    "\n",
    "from perturbations import perturbed\n",
    "from bpr import bpr_variable_k_no_ties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e583b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/cluster/tufts/hugheslab/datasets/NSF_OD/results_20220606_update/clean_quarter_tract/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7085d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_quarterly(multiindexed_gdf, first_year, last_year, time_window, feature_cols, train_shape, pred_lag=1):\n",
    "\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for eval_year in range(first_year, last_year + 1):\n",
    "        quarters_in_year = multiindexed_gdf[multiindexed_gdf['year']==eval_year].index.unique(level='timestep')\n",
    "        quarters_in_year.sort_values()\n",
    "        train_x_df = multiindexed_gdf.loc[idx[:, min(quarters_in_year) - time_window:max(quarters_in_year) - pred_lag], feature_cols]\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        for quarter in quarters_in_year:\n",
    "            \n",
    "            train_x_df['pred_timestep'] = quarter\n",
    "            train_x_vals = train_x_df.values.reshape(train_shape)\n",
    "            \n",
    "            train_y_df = multiindexed_gdf.loc[idx[:,quarter], 'deaths']\n",
    "            train_y_vals = train_y_df.values\n",
    "\n",
    "            xs.append(train_x_vals)\n",
    "            ys.append(train_y_vals)\n",
    "\n",
    "    x_BSTD = np.stack(xs, axis=0)\n",
    "    y_BS = np.stack(ys)\n",
    "\n",
    "    x_BSTD = tf.convert_to_tensor(x_BSTD, dtype=tf.float32)\n",
    "    y_BS = tf.convert_to_tensor(y_BS, dtype=tf.float32)\n",
    "\n",
    "    B, S, T, D = x_BSTD.shape\n",
    "\n",
    "    assert (B == len(range(first_year, last_year + 1))*pred_lag)\n",
    "    assert (S == train_shape[0])\n",
    "    assert (T == time_window)\n",
    "    assert (D == len(feature_cols)+1)\n",
    "\n",
    "    # Reshape the training data to flatten the dimensions\n",
    "    x_BSF_flat = tf.reshape(x_BSTD, (B, S, T * D), )\n",
    "\n",
    "\n",
    "    return x_BSF_flat, y_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9ce3af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbedBPRModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, perturbed_top_k_func, k=100):\n",
    "        \"\"\"k should match the k baked into the perturbed top_k func.\n",
    "        we need k for when performing exact top k in evaluation step.\"\"\"\n",
    "        super(PerturbedBPRModel, self).__init__()\n",
    "        self.perturbed_top_k_func = perturbed_top_k_func\n",
    "        self.k = k\n",
    "        self.hidden1 = tf.keras.layers.Dense(100, activation='relu')\n",
    "        self.hidden2 = tf.keras.layers.Dense(50, activation='relu')\n",
    "        self.hidden3 = tf.keras.layers.Dense(10, activation='relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        intermediate = self.hidden1(inputs)\n",
    "        intermediate = self.hidden2(intermediate)\n",
    "        intermediate = self.hidden3(intermediate)\n",
    "        \n",
    "        outputs = self.output_layer(intermediate)\n",
    "        # squeeze away feature dimension\n",
    "        outputs = tf.squeeze(outputs, axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            top_100_indicators = self.perturbed_top_k_func(y_pred)\n",
    "            true_top_100_val, true_top_100_idx = tf.math.top_k(y, k=self.k)\n",
    "\n",
    "            denominator = tf.reduce_sum(true_top_100_val, axis=-1)\n",
    "            numerator = tf.reduce_sum(top_100_indicators * y, axis=-1)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(numerator, denominator, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_pred = self(x, training=False)  # Forward pass\n",
    "        # use discrete topk to simulate making a decision\n",
    "        _, pred_100_idx = tf.math.top_k(y_pred, k=self.k)\n",
    "        true_top_100_val, true_top_100_idx = tf.math.top_k(y, k=self.k)\n",
    "\n",
    "        denominator = tf.reduce_sum(true_top_100_val, axis=-1)\n",
    "        numerator = tf.reduce_sum(tf.gather(y, pred_100_idx, batch_dims=-1), axis=-1)\n",
    "\n",
    "        # Compute the loss value\n",
    "        # (the loss function is configured in `compile()`)\n",
    "        self.compiled_loss(numerator, denominator, regularization_losses=self.losses)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2b2af227",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "seed = 360\n",
    "time_window = 5*4\n",
    "first_train_eval_year = 2014\n",
    "last_train_eval_year = 2018\n",
    "#batch_dim_size = last_train_eval_year - first_train_eval_year + 1\n",
    "first_validation_year = 2019\n",
    "last_validation_year = 2019\n",
    "first_test_year = 2020\n",
    "last_test_year = 2021\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "timestep_col = 'timestep'\n",
    "geography_col = 'geoid'\n",
    "outcome_col = 'deaths'\n",
    "\n",
    "x_idx_cols = [geography_col, 'lat', 'lon', timestep_col,\n",
    "              'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "              'svi_pctile', 'year',\n",
    "              'neighbor_t', 'deaths']\n",
    "y_idx_cols = [geography_col, timestep_col, outcome_col]\n",
    "features_only = ['lat', 'lon', timestep_col,\n",
    "                 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "                 'svi_pctile',\n",
    "                 'neighbor_t', 'deaths']\n",
    "#features_only = ['deaths']\n",
    "\n",
    "#data_gdf = gpd.read_file(data_path)\n",
    "\n",
    "multiindexed_gdf = data_gdf.set_index(['geoid', 'timestep'])\n",
    "multiindexed_gdf['timestep'] = multiindexed_gdf.index.get_level_values('timestep')\n",
    "num_geoids = len(data_gdf['geoid'].unique())\n",
    "\n",
    "train_shape = (num_geoids, time_window, len(features_only)+1)\n",
    "\n",
    "train_x_BSF_flat, train_y_BS = make_data_quarterly(multiindexed_gdf, first_train_eval_year, last_train_eval_year,\n",
    "                                                  time_window, features_only, train_shape, pred_lag=4)\n",
    "\n",
    "valid_x_BSF_flat, valid_y_BS = make_data_quarterly(multiindexed_gdf, first_validation_year, last_validation_year,\n",
    "                                         time_window, features_only, train_shape, pred_lag=4)\n",
    "\n",
    "test_x_BSF_flat, test_y_BS = make_data_quarterly(multiindexed_gdf, first_test_year, last_test_year,\n",
    "                                       time_window, features_only, train_shape, pred_lag=4)\n",
    "\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "norm_layer.adapt(train_x_BSF_flat)\n",
    "train_x_BSF_flat = norm_layer(train_x_BSF_flat)\n",
    "valid_x_BSF_flat = norm_layer(valid_x_BSF_flat)\n",
    "test_x_BSF_flat = norm_layer(test_x_BSF_flat)\n",
    "\n",
    "top_100_idx_func = partial(top_k_idx, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bafb3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_samples = 37\n",
    "noise=0.4\n",
    "learning_rate = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "df8f7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_top_100 = perturbed(top_100_idx_func,\n",
    "                              num_samples=perturbation_samples,\n",
    "                              sigma=noise,\n",
    "                              noise='normal',\n",
    "                              batched=True)\n",
    "\n",
    "model = PerturbedBPRModel(perturbed_top_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5e9daac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "def weird_loss(a, b):\n",
    "    return -a / b\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=weird_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471dfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1/1 [==============================] - 1s 977ms/step - loss: -0.2091 - val_loss: -0.3290\n",
      "Epoch 2/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2085 - val_loss: -0.3330\n",
      "Epoch 3/5000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: -0.2073 - val_loss: -0.3344\n",
      "Epoch 4/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2100 - val_loss: -0.3345\n",
      "Epoch 5/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2111 - val_loss: -0.3275\n",
      "Epoch 6/5000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: -0.2099 - val_loss: -0.3261\n",
      "Epoch 7/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2107 - val_loss: -0.3303\n",
      "Epoch 8/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2144 - val_loss: -0.3370\n",
      "Epoch 9/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2122 - val_loss: -0.3385\n",
      "Epoch 10/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2148 - val_loss: -0.3355\n",
      "Epoch 11/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2125 - val_loss: -0.3382\n",
      "Epoch 12/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2147 - val_loss: -0.3411\n",
      "Epoch 13/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2133 - val_loss: -0.3398\n",
      "Epoch 14/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2128 - val_loss: -0.3342\n",
      "Epoch 15/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2165 - val_loss: -0.3340\n",
      "Epoch 16/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2159 - val_loss: -0.3341\n",
      "Epoch 17/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2173 - val_loss: -0.3341\n",
      "Epoch 18/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2188 - val_loss: -0.3312\n",
      "Epoch 19/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2194 - val_loss: -0.3342\n",
      "Epoch 20/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2208 - val_loss: -0.3355\n",
      "Epoch 21/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2220 - val_loss: -0.3342\n",
      "Epoch 22/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2221 - val_loss: -0.3342\n",
      "Epoch 23/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2243 - val_loss: -0.3342\n",
      "Epoch 24/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2245 - val_loss: -0.3342\n",
      "Epoch 25/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2267 - val_loss: -0.3285\n",
      "Epoch 26/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2269 - val_loss: -0.3330\n",
      "Epoch 27/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2279 - val_loss: -0.3317\n",
      "Epoch 28/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2281 - val_loss: -0.3344\n",
      "Epoch 29/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2333 - val_loss: -0.3458\n",
      "Epoch 30/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2320 - val_loss: -0.3430\n",
      "Epoch 31/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2346 - val_loss: -0.3415\n",
      "Epoch 32/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2369 - val_loss: -0.3402\n",
      "Epoch 33/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2373 - val_loss: -0.3402\n",
      "Epoch 34/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2387 - val_loss: -0.3402\n",
      "Epoch 35/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2426 - val_loss: -0.3415\n",
      "Epoch 36/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2431 - val_loss: -0.3415\n",
      "Epoch 37/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2431 - val_loss: -0.3416\n",
      "Epoch 38/5000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: -0.2458 - val_loss: -0.3402\n",
      "Epoch 39/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2458 - val_loss: -0.3345\n",
      "Epoch 40/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2486 - val_loss: -0.3331\n",
      "Epoch 41/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2490 - val_loss: -0.3331\n",
      "Epoch 42/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2499 - val_loss: -0.3332\n",
      "Epoch 43/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2524 - val_loss: -0.3333\n",
      "Epoch 44/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2536 - val_loss: -0.3304\n",
      "Epoch 45/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2516 - val_loss: -0.3303\n",
      "Epoch 46/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2537 - val_loss: -0.3303\n",
      "Epoch 47/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2554 - val_loss: -0.3331\n",
      "Epoch 48/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2554 - val_loss: -0.3344\n",
      "Epoch 49/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2572 - val_loss: -0.3344\n",
      "Epoch 50/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2549 - val_loss: -0.3331\n",
      "Epoch 51/5000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: -0.2551 - val_loss: -0.3318\n",
      "Epoch 52/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2553 - val_loss: -0.3318\n",
      "Epoch 53/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2583 - val_loss: -0.3303\n",
      "Epoch 54/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2563 - val_loss: -0.3303\n",
      "Epoch 55/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2566 - val_loss: -0.3303\n",
      "Epoch 56/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2549 - val_loss: -0.3330\n",
      "Epoch 57/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2548 - val_loss: -0.3357\n",
      "Epoch 58/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2566 - val_loss: -0.3357\n",
      "Epoch 59/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2574 - val_loss: -0.3357\n",
      "Epoch 60/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2568 - val_loss: -0.3372\n",
      "Epoch 61/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2599 - val_loss: -0.3357\n",
      "Epoch 62/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2593 - val_loss: -0.3386\n",
      "Epoch 63/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2580 - val_loss: -0.3412\n",
      "Epoch 64/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2630 - val_loss: -0.3398\n",
      "Epoch 65/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2637 - val_loss: -0.3398\n",
      "Epoch 66/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2609 - val_loss: -0.3411\n",
      "Epoch 67/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2621 - val_loss: -0.3398\n",
      "Epoch 68/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2622 - val_loss: -0.3398\n",
      "Epoch 69/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2620 - val_loss: -0.3412\n",
      "Epoch 70/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2620 - val_loss: -0.3468\n",
      "Epoch 71/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2631 - val_loss: -0.3483\n",
      "Epoch 72/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2625 - val_loss: -0.3483\n",
      "Epoch 73/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2630 - val_loss: -0.3523\n",
      "Epoch 74/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2628 - val_loss: -0.3523\n",
      "Epoch 75/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2630 - val_loss: -0.3523\n",
      "Epoch 76/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2629 - val_loss: -0.3538\n",
      "Epoch 77/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2626 - val_loss: -0.3553\n",
      "Epoch 78/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2643 - val_loss: -0.3553\n",
      "Epoch 79/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2624 - val_loss: -0.3509\n",
      "Epoch 80/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2635 - val_loss: -0.3525\n",
      "Epoch 81/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2623 - val_loss: -0.3498\n",
      "Epoch 82/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2660 - val_loss: -0.3498\n",
      "Epoch 83/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2642 - val_loss: -0.3454\n",
      "Epoch 84/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2643 - val_loss: -0.3498\n",
      "Epoch 85/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2644 - val_loss: -0.3485\n",
      "Epoch 86/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2648 - val_loss: -0.3498\n",
      "Epoch 87/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2651 - val_loss: -0.3498\n",
      "Epoch 88/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2656 - val_loss: -0.3527\n",
      "Epoch 89/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2655 - val_loss: -0.3527\n",
      "Epoch 90/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2659 - val_loss: -0.3555\n",
      "Epoch 91/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2661 - val_loss: -0.3555\n",
      "Epoch 92/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2683 - val_loss: -0.3598\n",
      "Epoch 93/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2675 - val_loss: -0.3556\n",
      "Epoch 94/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2708 - val_loss: -0.3596\n",
      "Epoch 95/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2681 - val_loss: -0.3569\n",
      "Epoch 96/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2708 - val_loss: -0.3544\n",
      "Epoch 97/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2697 - val_loss: -0.3544\n",
      "Epoch 98/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2702 - val_loss: -0.3544\n",
      "Epoch 99/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2709 - val_loss: -0.3544\n",
      "Epoch 100/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2692 - val_loss: -0.3544\n",
      "Epoch 101/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2728 - val_loss: -0.3544\n",
      "Epoch 102/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2731 - val_loss: -0.3530\n",
      "Epoch 103/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2714 - val_loss: -0.3515\n",
      "Epoch 104/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2733 - val_loss: -0.3502\n",
      "Epoch 105/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2722 - val_loss: -0.3529\n",
      "Epoch 106/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2738 - val_loss: -0.3488\n",
      "Epoch 107/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2727 - val_loss: -0.3488\n",
      "Epoch 108/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2724 - val_loss: -0.3501\n",
      "Epoch 109/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2752 - val_loss: -0.3516\n",
      "Epoch 110/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2742 - val_loss: -0.3557\n",
      "Epoch 111/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2756 - val_loss: -0.3557\n",
      "Epoch 112/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2755 - val_loss: -0.3583\n",
      "Epoch 113/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2782 - val_loss: -0.3583\n",
      "Epoch 114/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2763 - val_loss: -0.3570\n",
      "Epoch 115/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2801 - val_loss: -0.3583\n",
      "Epoch 116/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2783 - val_loss: -0.3554\n",
      "Epoch 117/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2795 - val_loss: -0.3540\n",
      "Epoch 118/5000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: -0.2810 - val_loss: -0.3527\n",
      "Epoch 119/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2806 - val_loss: -0.3541\n",
      "Epoch 120/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2815 - val_loss: -0.3527\n",
      "Epoch 121/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2828 - val_loss: -0.3513\n",
      "Epoch 122/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2821 - val_loss: -0.3499\n",
      "Epoch 123/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2825 - val_loss: -0.3499\n",
      "Epoch 124/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2847 - val_loss: -0.3485\n",
      "Epoch 125/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2851 - val_loss: -0.3485\n",
      "Epoch 126/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2856 - val_loss: -0.3486\n",
      "Epoch 127/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2850 - val_loss: -0.3486\n",
      "Epoch 128/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2837 - val_loss: -0.3514\n",
      "Epoch 129/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2849 - val_loss: -0.3514\n",
      "Epoch 130/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2858 - val_loss: -0.3514\n",
      "Epoch 131/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2858 - val_loss: -0.3514\n",
      "Epoch 132/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2856 - val_loss: -0.3527\n",
      "Epoch 133/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2858 - val_loss: -0.3527\n",
      "Epoch 134/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2867 - val_loss: -0.3526\n",
      "Epoch 135/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2850 - val_loss: -0.3499\n",
      "Epoch 136/5000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: -0.2852 - val_loss: -0.3485\n",
      "Epoch 137/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.2870 - val_loss: -0.3485\n",
      "Epoch 138/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2854 - val_loss: -0.3470\n",
      "Epoch 139/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2855 - val_loss: -0.3470\n",
      "Epoch 140/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2864 - val_loss: -0.3470\n",
      "Epoch 141/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2872 - val_loss: -0.3456\n",
      "Epoch 142/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2875 - val_loss: -0.3469\n",
      "Epoch 143/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2885 - val_loss: -0.3456\n",
      "Epoch 144/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2853 - val_loss: -0.3456\n",
      "Epoch 145/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2854 - val_loss: -0.3484\n",
      "Epoch 146/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2890 - val_loss: -0.3484\n",
      "Epoch 147/5000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: -0.2862 - val_loss: -0.3497\n",
      "Epoch 148/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2876 - val_loss: -0.3497\n",
      "Epoch 149/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2865 - val_loss: -0.3512\n",
      "Epoch 150/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2869 - val_loss: -0.3498\n",
      "Epoch 151/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2869 - val_loss: -0.3498\n",
      "Epoch 152/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2860 - val_loss: -0.3498\n",
      "Epoch 153/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2875 - val_loss: -0.3485\n",
      "Epoch 154/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2856 - val_loss: -0.3485\n",
      "Epoch 155/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2858 - val_loss: -0.3514\n",
      "Epoch 156/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2853 - val_loss: -0.3527\n",
      "Epoch 157/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2847 - val_loss: -0.3471\n",
      "Epoch 158/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2864 - val_loss: -0.3471\n",
      "Epoch 159/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2856 - val_loss: -0.3486\n",
      "Epoch 160/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2840 - val_loss: -0.3486\n",
      "Epoch 161/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2850 - val_loss: -0.3444\n",
      "Epoch 162/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2858 - val_loss: -0.3457\n",
      "Epoch 163/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2836 - val_loss: -0.3457\n",
      "Epoch 164/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2846 - val_loss: -0.3485\n",
      "Epoch 165/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2846 - val_loss: -0.3471\n",
      "Epoch 166/5000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: -0.2849 - val_loss: -0.3485\n",
      "Epoch 167/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2826 - val_loss: -0.3459\n",
      "Epoch 168/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2849 - val_loss: -0.3430\n",
      "Epoch 169/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2831 - val_loss: -0.3430\n",
      "Epoch 170/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2847 - val_loss: -0.3416\n",
      "Epoch 171/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2864 - val_loss: -0.3402\n",
      "Epoch 172/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2852 - val_loss: -0.3402\n",
      "Epoch 173/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2851 - val_loss: -0.3402\n",
      "Epoch 174/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2856 - val_loss: -0.3402\n",
      "Epoch 175/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2849 - val_loss: -0.3402\n",
      "Epoch 176/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2849 - val_loss: -0.3402\n",
      "Epoch 177/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2862 - val_loss: -0.3402\n",
      "Epoch 178/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2868 - val_loss: -0.3401\n",
      "Epoch 179/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2847 - val_loss: -0.3414\n",
      "Epoch 180/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2850 - val_loss: -0.3414\n",
      "Epoch 181/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2858 - val_loss: -0.3414\n",
      "Epoch 182/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2861 - val_loss: -0.3401\n",
      "Epoch 183/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2867 - val_loss: -0.3386\n",
      "Epoch 184/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.2853 - val_loss: -0.3386\n",
      "Epoch 185/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2857 - val_loss: -0.3386\n",
      "Epoch 186/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2871 - val_loss: -0.3414\n",
      "Epoch 187/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2886 - val_loss: -0.3428\n",
      "Epoch 188/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2873 - val_loss: -0.3428\n",
      "Epoch 189/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2889 - val_loss: -0.3414\n",
      "Epoch 190/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2888 - val_loss: -0.3429\n",
      "Epoch 191/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2867 - val_loss: -0.3358\n",
      "Epoch 192/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2878 - val_loss: -0.3358\n",
      "Epoch 193/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2892 - val_loss: -0.3343\n",
      "Epoch 194/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2884 - val_loss: -0.3343\n",
      "Epoch 195/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2908 - val_loss: -0.3343\n",
      "Epoch 196/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2911 - val_loss: -0.3343\n",
      "Epoch 197/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2895 - val_loss: -0.3370\n",
      "Epoch 198/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2904 - val_loss: -0.3356\n",
      "Epoch 199/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2908 - val_loss: -0.3356\n",
      "Epoch 200/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2904 - val_loss: -0.3370\n",
      "Epoch 201/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.2909 - val_loss: -0.3370\n",
      "Epoch 202/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2917 - val_loss: -0.3411\n",
      "Epoch 203/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2916 - val_loss: -0.3411\n",
      "Epoch 204/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2919 - val_loss: -0.3398\n",
      "Epoch 205/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2919 - val_loss: -0.3411\n",
      "Epoch 206/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2930 - val_loss: -0.3425\n",
      "Epoch 207/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2943 - val_loss: -0.3425\n",
      "Epoch 208/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2941 - val_loss: -0.3425\n",
      "Epoch 209/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2929 - val_loss: -0.3425\n",
      "Epoch 210/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2932 - val_loss: -0.3425\n",
      "Epoch 211/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2934 - val_loss: -0.3439\n",
      "Epoch 212/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2930 - val_loss: -0.3439\n",
      "Epoch 213/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2935 - val_loss: -0.3425\n",
      "Epoch 214/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2930 - val_loss: -0.3467\n",
      "Epoch 215/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2943 - val_loss: -0.3480\n",
      "Epoch 216/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2938 - val_loss: -0.3453\n",
      "Epoch 217/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2930 - val_loss: -0.3439\n",
      "Epoch 218/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2935 - val_loss: -0.3453\n",
      "Epoch 219/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2944 - val_loss: -0.3482\n",
      "Epoch 220/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2942 - val_loss: -0.3482\n",
      "Epoch 221/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2943 - val_loss: -0.3510\n",
      "Epoch 222/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2949 - val_loss: -0.3510\n",
      "Epoch 223/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2957 - val_loss: -0.3510\n",
      "Epoch 224/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2956 - val_loss: -0.3482\n",
      "Epoch 225/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2941 - val_loss: -0.3468\n",
      "Epoch 226/5000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: -0.2950 - val_loss: -0.3468\n",
      "Epoch 227/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2971 - val_loss: -0.3482\n",
      "Epoch 228/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2964 - val_loss: -0.3496\n",
      "Epoch 229/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2970 - val_loss: -0.3481\n",
      "Epoch 230/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2974 - val_loss: -0.3481\n",
      "Epoch 231/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.2962 - val_loss: -0.3467\n",
      "Epoch 232/5000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: -0.2967 - val_loss: -0.3467\n",
      "Epoch 233/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2966 - val_loss: -0.3480\n",
      "Epoch 234/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2980 - val_loss: -0.3451\n",
      "Epoch 235/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2965 - val_loss: -0.3466\n",
      "Epoch 236/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2967 - val_loss: -0.3466\n",
      "Epoch 237/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2969 - val_loss: -0.3452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2959 - val_loss: -0.3452\n",
      "Epoch 239/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2994 - val_loss: -0.3452\n",
      "Epoch 240/5000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: -0.2974 - val_loss: -0.3452\n",
      "Epoch 241/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2990 - val_loss: -0.3438\n",
      "Epoch 242/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2988 - val_loss: -0.3451\n",
      "Epoch 243/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2993 - val_loss: -0.3424\n",
      "Epoch 244/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3001 - val_loss: -0.3424\n",
      "Epoch 245/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3000 - val_loss: -0.3397\n",
      "Epoch 246/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3003 - val_loss: -0.3397\n",
      "Epoch 247/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2992 - val_loss: -0.3412\n",
      "Epoch 248/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2992 - val_loss: -0.3383\n",
      "Epoch 249/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2987 - val_loss: -0.3383\n",
      "Epoch 250/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3005 - val_loss: -0.3383\n",
      "Epoch 251/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2992 - val_loss: -0.3356\n",
      "Epoch 252/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3004 - val_loss: -0.3356\n",
      "Epoch 253/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3000 - val_loss: -0.3356\n",
      "Epoch 254/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2999 - val_loss: -0.3356\n",
      "Epoch 255/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3006 - val_loss: -0.3356\n",
      "Epoch 256/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2993 - val_loss: -0.3370\n",
      "Epoch 257/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3011 - val_loss: -0.3370\n",
      "Epoch 258/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3018 - val_loss: -0.3370\n",
      "Epoch 259/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2992 - val_loss: -0.3370\n",
      "Epoch 260/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.3016 - val_loss: -0.3425\n",
      "Epoch 261/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3013 - val_loss: -0.3453\n",
      "Epoch 262/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2994 - val_loss: -0.3467\n",
      "Epoch 263/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3015 - val_loss: -0.3467\n",
      "Epoch 264/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3009 - val_loss: -0.3467\n",
      "Epoch 265/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3015 - val_loss: -0.3481\n",
      "Epoch 266/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3002 - val_loss: -0.3481\n",
      "Epoch 267/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3014 - val_loss: -0.3481\n",
      "Epoch 268/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3024 - val_loss: -0.3481\n",
      "Epoch 269/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2996 - val_loss: -0.3481\n",
      "Epoch 270/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3003 - val_loss: -0.3440\n",
      "Epoch 271/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3019 - val_loss: -0.3439\n",
      "Epoch 272/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3013 - val_loss: -0.3453\n",
      "Epoch 273/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3008 - val_loss: -0.3454\n",
      "Epoch 274/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3014 - val_loss: -0.3452\n",
      "Epoch 275/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3017 - val_loss: -0.3438\n",
      "Epoch 276/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3009 - val_loss: -0.3480\n",
      "Epoch 277/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3031 - val_loss: -0.3523\n",
      "Epoch 278/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3034 - val_loss: -0.3509\n",
      "Epoch 279/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3012 - val_loss: -0.3495\n",
      "Epoch 280/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3025 - val_loss: -0.3495\n",
      "Epoch 281/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3033 - val_loss: -0.3482\n",
      "Epoch 282/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3028 - val_loss: -0.3468\n",
      "Epoch 283/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3048 - val_loss: -0.3498\n",
      "Epoch 284/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.3027 - val_loss: -0.3498\n",
      "Epoch 285/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3027 - val_loss: -0.3511\n",
      "Epoch 286/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.3026 - val_loss: -0.3497\n",
      "Epoch 287/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3039 - val_loss: -0.3567\n",
      "Epoch 288/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3024 - val_loss: -0.3567\n",
      "Epoch 289/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3023 - val_loss: -0.3567\n",
      "Epoch 290/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3034 - val_loss: -0.3581\n",
      "Epoch 291/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3027 - val_loss: -0.3568\n",
      "Epoch 292/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3025 - val_loss: -0.3595\n",
      "Epoch 293/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3042 - val_loss: -0.3610\n",
      "Epoch 294/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3024 - val_loss: -0.3596\n",
      "Epoch 295/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3023 - val_loss: -0.3596\n",
      "Epoch 296/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3032 - val_loss: -0.3596\n",
      "Epoch 297/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3035 - val_loss: -0.3596\n",
      "Epoch 298/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3023 - val_loss: -0.3610\n",
      "Epoch 299/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.3047 - val_loss: -0.3597\n",
      "Epoch 300/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3025 - val_loss: -0.3582\n",
      "Epoch 301/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3044 - val_loss: -0.3567\n",
      "Epoch 302/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3036 - val_loss: -0.3567\n",
      "Epoch 303/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3041 - val_loss: -0.3567\n",
      "Epoch 304/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3029 - val_loss: -0.3554\n",
      "Epoch 305/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3026 - val_loss: -0.3554\n",
      "Epoch 306/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3035 - val_loss: -0.3554\n",
      "Epoch 307/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3034 - val_loss: -0.3527\n",
      "Epoch 308/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3014 - val_loss: -0.3527\n",
      "Epoch 309/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3023 - val_loss: -0.3541\n",
      "Epoch 310/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3028 - val_loss: -0.3527\n",
      "Epoch 311/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3043 - val_loss: -0.3525\n",
      "Epoch 312/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3029 - val_loss: -0.3555\n",
      "Epoch 313/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3032 - val_loss: -0.3554\n",
      "Epoch 314/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3022 - val_loss: -0.3581\n",
      "Epoch 315/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3045 - val_loss: -0.3609\n",
      "Epoch 316/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3040 - val_loss: -0.3595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3043 - val_loss: -0.3609\n",
      "Epoch 318/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3025 - val_loss: -0.3625\n",
      "Epoch 319/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3038 - val_loss: -0.3639\n",
      "Epoch 320/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3033 - val_loss: -0.3626\n",
      "Epoch 321/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3024 - val_loss: -0.3625\n",
      "Epoch 322/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3052 - val_loss: -0.3625\n",
      "Epoch 323/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3049 - val_loss: -0.3625\n",
      "Epoch 324/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3053 - val_loss: -0.3568\n",
      "Epoch 325/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3039 - val_loss: -0.3568\n",
      "Epoch 326/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3042 - val_loss: -0.3595\n",
      "Epoch 327/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3040 - val_loss: -0.3595\n",
      "Epoch 328/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3071 - val_loss: -0.3609\n",
      "Epoch 329/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3047 - val_loss: -0.3622\n",
      "Epoch 330/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3046 - val_loss: -0.3622\n",
      "Epoch 331/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3046 - val_loss: -0.3608\n",
      "Epoch 332/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3040 - val_loss: -0.3608\n",
      "Epoch 333/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3060 - val_loss: -0.3608\n",
      "Epoch 334/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3059 - val_loss: -0.3622\n",
      "Epoch 335/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3048 - val_loss: -0.3622\n",
      "Epoch 336/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3049 - val_loss: -0.3622\n",
      "Epoch 337/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3060 - val_loss: -0.3608\n",
      "Epoch 338/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3037 - val_loss: -0.3581\n",
      "Epoch 339/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3039 - val_loss: -0.3581\n",
      "Epoch 340/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3035 - val_loss: -0.3594\n",
      "Epoch 341/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3048 - val_loss: -0.3621\n",
      "Epoch 342/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3046 - val_loss: -0.3636\n",
      "Epoch 343/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3033 - val_loss: -0.3636\n",
      "Epoch 344/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3022 - val_loss: -0.3665\n",
      "Epoch 345/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3040 - val_loss: -0.3679\n",
      "Epoch 346/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3023 - val_loss: -0.3666\n",
      "Epoch 347/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3033 - val_loss: -0.3695\n",
      "Epoch 348/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3013 - val_loss: -0.3695\n",
      "Epoch 349/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3034 - val_loss: -0.3735\n",
      "Epoch 350/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3025 - val_loss: -0.3749\n",
      "Epoch 351/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3035 - val_loss: -0.3721\n",
      "Epoch 352/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3031 - val_loss: -0.3721\n",
      "Epoch 353/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3026 - val_loss: -0.3735\n",
      "Epoch 354/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3033 - val_loss: -0.3749\n",
      "Epoch 355/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3043 - val_loss: -0.3749\n",
      "Epoch 356/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3040 - val_loss: -0.3762\n",
      "Epoch 357/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3036 - val_loss: -0.3749\n",
      "Epoch 358/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3038 - val_loss: -0.3749\n",
      "Epoch 359/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3038 - val_loss: -0.3748\n",
      "Epoch 360/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3029 - val_loss: -0.3775\n",
      "Epoch 361/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3052 - val_loss: -0.3762\n",
      "Epoch 362/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3050 - val_loss: -0.3749\n",
      "Epoch 363/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3039 - val_loss: -0.3708\n",
      "Epoch 364/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3040 - val_loss: -0.3708\n",
      "Epoch 365/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3042 - val_loss: -0.3708\n",
      "Epoch 366/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3034 - val_loss: -0.3637\n",
      "Epoch 367/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3036 - val_loss: -0.3651\n",
      "Epoch 368/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3012 - val_loss: -0.3625\n",
      "Epoch 369/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3031 - val_loss: -0.3639\n",
      "Epoch 370/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3032 - val_loss: -0.3625\n",
      "Epoch 371/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3026 - val_loss: -0.3639\n",
      "Epoch 372/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3020 - val_loss: -0.3639\n",
      "Epoch 373/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3009 - val_loss: -0.3639\n",
      "Epoch 374/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3011 - val_loss: -0.3639\n",
      "Epoch 375/5000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: -0.3021 - val_loss: -0.3638\n",
      "Epoch 376/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3024 - val_loss: -0.3638\n",
      "Epoch 377/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3022 - val_loss: -0.3638\n",
      "Epoch 378/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3011 - val_loss: -0.3638\n",
      "Epoch 379/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3011 - val_loss: -0.3638\n",
      "Epoch 380/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3021 - val_loss: -0.3638\n",
      "Epoch 381/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3025 - val_loss: -0.3625\n",
      "Epoch 382/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3002 - val_loss: -0.3610\n",
      "Epoch 383/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3032 - val_loss: -0.3610\n",
      "Epoch 384/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3015 - val_loss: -0.3597\n",
      "Epoch 385/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3037 - val_loss: -0.3611\n",
      "Epoch 386/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3030 - val_loss: -0.3638\n",
      "Epoch 387/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3021 - val_loss: -0.3638\n",
      "Epoch 388/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3026 - val_loss: -0.3638\n",
      "Epoch 389/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3037 - val_loss: -0.3638\n",
      "Epoch 390/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3014 - val_loss: -0.3611\n",
      "Epoch 391/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3024 - val_loss: -0.3611\n",
      "Epoch 392/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3020 - val_loss: -0.3624\n",
      "Epoch 393/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3027 - val_loss: -0.3624\n",
      "Epoch 394/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3018 - val_loss: -0.3624\n",
      "Epoch 395/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3024 - val_loss: -0.3623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3022 - val_loss: -0.3609\n",
      "Epoch 397/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3022 - val_loss: -0.3623\n",
      "Epoch 398/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2998 - val_loss: -0.3596\n",
      "Epoch 399/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3004 - val_loss: -0.3609\n",
      "Epoch 400/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3007 - val_loss: -0.3638\n",
      "Epoch 401/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3008 - val_loss: -0.3638\n",
      "Epoch 402/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3018 - val_loss: -0.3611\n",
      "Epoch 403/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3001 - val_loss: -0.3611\n",
      "Epoch 404/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2988 - val_loss: -0.3596\n",
      "Epoch 405/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2997 - val_loss: -0.3611\n",
      "Epoch 406/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2988 - val_loss: -0.3611\n",
      "Epoch 407/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2994 - val_loss: -0.3611\n",
      "Epoch 408/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2988 - val_loss: -0.3625\n",
      "Epoch 409/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2991 - val_loss: -0.3625\n",
      "Epoch 410/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2994 - val_loss: -0.3625\n",
      "Epoch 411/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2989 - val_loss: -0.3625\n",
      "Epoch 412/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2993 - val_loss: -0.3638\n",
      "Epoch 413/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2989 - val_loss: -0.3625\n",
      "Epoch 414/5000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: -0.2982 - val_loss: -0.3596\n",
      "Epoch 415/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2990 - val_loss: -0.3596\n",
      "Epoch 416/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2976 - val_loss: -0.3596\n",
      "Epoch 417/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2995 - val_loss: -0.3582\n",
      "Epoch 418/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2985 - val_loss: -0.3582\n",
      "Epoch 419/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2985 - val_loss: -0.3582\n",
      "Epoch 420/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2975 - val_loss: -0.3568\n",
      "Epoch 421/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2983 - val_loss: -0.3554\n",
      "Epoch 422/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2989 - val_loss: -0.3540\n",
      "Epoch 423/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2981 - val_loss: -0.3526\n",
      "Epoch 424/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2984 - val_loss: -0.3526\n",
      "Epoch 425/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2994 - val_loss: -0.3570\n",
      "Epoch 426/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2993 - val_loss: -0.3584\n",
      "Epoch 427/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2991 - val_loss: -0.3598\n",
      "Epoch 428/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3009 - val_loss: -0.3612\n",
      "Epoch 429/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2998 - val_loss: -0.3597\n",
      "Epoch 430/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2987 - val_loss: -0.3597\n",
      "Epoch 431/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3000 - val_loss: -0.3611\n",
      "Epoch 432/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3013 - val_loss: -0.3584\n",
      "Epoch 433/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2981 - val_loss: -0.3570\n",
      "Epoch 434/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3008 - val_loss: -0.3585\n",
      "Epoch 435/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3006 - val_loss: -0.3585\n",
      "Epoch 436/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3012 - val_loss: -0.3598\n",
      "Epoch 437/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2993 - val_loss: -0.3612\n",
      "Epoch 438/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3007 - val_loss: -0.3612\n",
      "Epoch 439/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3003 - val_loss: -0.3612\n",
      "Epoch 440/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3016 - val_loss: -0.3612\n",
      "Epoch 441/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3004 - val_loss: -0.3599\n",
      "Epoch 442/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3020 - val_loss: -0.3626\n",
      "Epoch 443/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3005 - val_loss: -0.3626\n",
      "Epoch 444/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2997 - val_loss: -0.3639\n",
      "Epoch 445/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3019 - val_loss: -0.3595\n",
      "Epoch 446/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3040 - val_loss: -0.3555\n",
      "Epoch 447/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3013 - val_loss: -0.3555\n",
      "Epoch 448/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3008 - val_loss: -0.3527\n",
      "Epoch 449/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3013 - val_loss: -0.3512\n",
      "Epoch 450/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3024 - val_loss: -0.3539\n",
      "Epoch 451/5000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: -0.3036 - val_loss: -0.3539\n",
      "Epoch 452/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3025 - val_loss: -0.3510\n",
      "Epoch 453/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3007 - val_loss: -0.3524\n",
      "Epoch 454/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3015 - val_loss: -0.3524\n",
      "Epoch 455/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3020 - val_loss: -0.3595\n",
      "Epoch 456/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3017 - val_loss: -0.3635\n",
      "Epoch 457/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.3018 - val_loss: -0.3650\n",
      "Epoch 458/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3011 - val_loss: -0.3650\n",
      "Epoch 459/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3018 - val_loss: -0.3650\n",
      "Epoch 460/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3013 - val_loss: -0.3664\n",
      "Epoch 461/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3004 - val_loss: -0.3636\n",
      "Epoch 462/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3002 - val_loss: -0.3622\n",
      "Epoch 463/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3008 - val_loss: -0.3567\n",
      "Epoch 464/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.2994 - val_loss: -0.3539\n",
      "Epoch 465/5000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: -0.2995 - val_loss: -0.3539\n",
      "Epoch 466/5000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: -0.3000 - val_loss: -0.3539\n",
      "Epoch 467/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.2988 - val_loss: -0.3526\n",
      "Epoch 468/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2992 - val_loss: -0.3554\n",
      "Epoch 469/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2982 - val_loss: -0.3527\n",
      "Epoch 470/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2990 - val_loss: -0.3527\n",
      "Epoch 471/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2990 - val_loss: -0.3557\n",
      "Epoch 472/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2992 - val_loss: -0.3586\n",
      "Epoch 473/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2977 - val_loss: -0.3586\n",
      "Epoch 474/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2962 - val_loss: -0.3628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2994 - val_loss: -0.3630\n",
      "Epoch 476/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2976 - val_loss: -0.3643\n",
      "Epoch 477/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2971 - val_loss: -0.3643\n",
      "Epoch 478/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2982 - val_loss: -0.3643\n",
      "Epoch 479/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2965 - val_loss: -0.3658\n",
      "Epoch 480/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2979 - val_loss: -0.3658\n",
      "Epoch 481/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2971 - val_loss: -0.3658\n",
      "Epoch 482/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2969 - val_loss: -0.3616\n",
      "Epoch 483/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2971 - val_loss: -0.3616\n",
      "Epoch 484/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2961 - val_loss: -0.3602\n",
      "Epoch 485/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2979 - val_loss: -0.3589\n",
      "Epoch 486/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2981 - val_loss: -0.3644\n",
      "Epoch 487/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2980 - val_loss: -0.3631\n",
      "Epoch 488/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2989 - val_loss: -0.3659\n",
      "Epoch 489/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2987 - val_loss: -0.3673\n",
      "Epoch 490/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2984 - val_loss: -0.3673\n",
      "Epoch 491/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2972 - val_loss: -0.3646\n",
      "Epoch 492/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2968 - val_loss: -0.3646\n",
      "Epoch 493/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2976 - val_loss: -0.3588\n",
      "Epoch 494/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2992 - val_loss: -0.3588\n",
      "Epoch 495/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2981 - val_loss: -0.3575\n",
      "Epoch 496/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2971 - val_loss: -0.3588\n",
      "Epoch 497/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2981 - val_loss: -0.3588\n",
      "Epoch 498/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2995 - val_loss: -0.3602\n",
      "Epoch 499/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2978 - val_loss: -0.3615\n",
      "Epoch 500/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.2971 - val_loss: -0.3574\n",
      "Epoch 501/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2980 - val_loss: -0.3601\n",
      "Epoch 502/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2961 - val_loss: -0.3615\n",
      "Epoch 503/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2994 - val_loss: -0.3629\n",
      "Epoch 504/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2980 - val_loss: -0.3615\n",
      "Epoch 505/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2982 - val_loss: -0.3560\n",
      "Epoch 506/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2985 - val_loss: -0.3545\n",
      "Epoch 507/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2977 - val_loss: -0.3545\n",
      "Epoch 508/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2955 - val_loss: -0.3545\n",
      "Epoch 509/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.2965 - val_loss: -0.3558\n",
      "Epoch 510/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2956 - val_loss: -0.3544\n",
      "Epoch 511/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.2974 - val_loss: -0.3558\n",
      "Epoch 512/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2968 - val_loss: -0.3544\n",
      "Epoch 513/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2974 - val_loss: -0.3558\n",
      "Epoch 514/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2966 - val_loss: -0.3572\n",
      "Epoch 515/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.2970 - val_loss: -0.3572\n",
      "Epoch 516/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2971 - val_loss: -0.3559\n",
      "Epoch 517/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2987 - val_loss: -0.3516\n",
      "Epoch 518/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2979 - val_loss: -0.3530\n",
      "Epoch 519/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2962 - val_loss: -0.3557\n",
      "Epoch 520/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2975 - val_loss: -0.3557\n",
      "Epoch 521/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2984 - val_loss: -0.3513\n",
      "Epoch 522/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2978 - val_loss: -0.3513\n",
      "Epoch 523/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2972 - val_loss: -0.3553\n",
      "Epoch 524/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2990 - val_loss: -0.3553\n",
      "Epoch 525/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2995 - val_loss: -0.3582\n",
      "Epoch 526/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2998 - val_loss: -0.3582\n",
      "Epoch 527/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2976 - val_loss: -0.3582\n",
      "Epoch 528/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2981 - val_loss: -0.3582\n",
      "Epoch 529/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2968 - val_loss: -0.3582\n",
      "Epoch 530/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2999 - val_loss: -0.3582\n",
      "Epoch 531/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2997 - val_loss: -0.3582\n",
      "Epoch 532/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3000 - val_loss: -0.3582\n",
      "Epoch 533/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2999 - val_loss: -0.3582\n",
      "Epoch 534/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3006 - val_loss: -0.3582\n",
      "Epoch 535/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2999 - val_loss: -0.3553\n",
      "Epoch 536/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3002 - val_loss: -0.3553\n",
      "Epoch 537/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2993 - val_loss: -0.3539\n",
      "Epoch 538/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2997 - val_loss: -0.3539\n",
      "Epoch 539/5000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: -0.3005 - val_loss: -0.3554\n",
      "Epoch 540/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3013 - val_loss: -0.3554\n",
      "Epoch 541/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3007 - val_loss: -0.3554\n",
      "Epoch 542/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3023 - val_loss: -0.3582\n",
      "Epoch 543/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3019 - val_loss: -0.3623\n",
      "Epoch 544/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3020 - val_loss: -0.3623\n",
      "Epoch 545/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3012 - val_loss: -0.3609\n",
      "Epoch 546/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3009 - val_loss: -0.3624\n",
      "Epoch 547/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3010 - val_loss: -0.3581\n",
      "Epoch 548/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3023 - val_loss: -0.3581\n",
      "Epoch 549/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3012 - val_loss: -0.3609\n",
      "Epoch 550/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3015 - val_loss: -0.3568\n",
      "Epoch 551/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3030 - val_loss: -0.3582\n",
      "Epoch 552/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3031 - val_loss: -0.3596\n",
      "Epoch 553/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3031 - val_loss: -0.3610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3035 - val_loss: -0.3625\n",
      "Epoch 555/5000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: -0.3042 - val_loss: -0.3597\n",
      "Epoch 556/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3036 - val_loss: -0.3610\n",
      "Epoch 557/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3037 - val_loss: -0.3623\n",
      "Epoch 558/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3046 - val_loss: -0.3637\n",
      "Epoch 559/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3036 - val_loss: -0.3651\n",
      "Epoch 560/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3068 - val_loss: -0.3651\n",
      "Epoch 561/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3038 - val_loss: -0.3665\n",
      "Epoch 562/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3031 - val_loss: -0.3665\n",
      "Epoch 563/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3060 - val_loss: -0.3665\n",
      "Epoch 564/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3048 - val_loss: -0.3651\n",
      "Epoch 565/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3039 - val_loss: -0.3651\n",
      "Epoch 566/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3045 - val_loss: -0.3651\n",
      "Epoch 567/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3038 - val_loss: -0.3651\n",
      "Epoch 568/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3057 - val_loss: -0.3651\n",
      "Epoch 569/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3033 - val_loss: -0.3651\n",
      "Epoch 570/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3052 - val_loss: -0.3665\n",
      "Epoch 571/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3034 - val_loss: -0.3636\n",
      "Epoch 572/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3050 - val_loss: -0.3651\n",
      "Epoch 573/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3053 - val_loss: -0.3666\n",
      "Epoch 574/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3049 - val_loss: -0.3666\n",
      "Epoch 575/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3041 - val_loss: -0.3652\n",
      "Epoch 576/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3033 - val_loss: -0.3598\n",
      "Epoch 577/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3046 - val_loss: -0.3570\n",
      "Epoch 578/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3030 - val_loss: -0.3570\n",
      "Epoch 579/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3036 - val_loss: -0.3570\n",
      "Epoch 580/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3032 - val_loss: -0.3612\n",
      "Epoch 581/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3059 - val_loss: -0.3583\n",
      "Epoch 582/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3036 - val_loss: -0.3598\n",
      "Epoch 583/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3050 - val_loss: -0.3625\n",
      "Epoch 584/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3033 - val_loss: -0.3612\n",
      "Epoch 585/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3037 - val_loss: -0.3639\n",
      "Epoch 586/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3039 - val_loss: -0.3625\n",
      "Epoch 587/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3031 - val_loss: -0.3611\n",
      "Epoch 588/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3036 - val_loss: -0.3611\n",
      "Epoch 589/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3046 - val_loss: -0.3611\n",
      "Epoch 590/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3043 - val_loss: -0.3611\n",
      "Epoch 591/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3034 - val_loss: -0.3597\n",
      "Epoch 592/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3031 - val_loss: -0.3597\n",
      "Epoch 593/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3041 - val_loss: -0.3611\n",
      "Epoch 594/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3032 - val_loss: -0.3625\n",
      "Epoch 595/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3056 - val_loss: -0.3625\n",
      "Epoch 596/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3032 - val_loss: -0.3597\n",
      "Epoch 597/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3048 - val_loss: -0.3597\n",
      "Epoch 598/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3045 - val_loss: -0.3597\n",
      "Epoch 599/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3026 - val_loss: -0.3597\n",
      "Epoch 600/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3046 - val_loss: -0.3625\n",
      "Epoch 601/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3041 - val_loss: -0.3625\n",
      "Epoch 602/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3051 - val_loss: -0.3598\n",
      "Epoch 603/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3033 - val_loss: -0.3598\n",
      "Epoch 604/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3044 - val_loss: -0.3597\n",
      "Epoch 605/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3031 - val_loss: -0.3583\n",
      "Epoch 606/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3037 - val_loss: -0.3583\n",
      "Epoch 607/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3033 - val_loss: -0.3583\n",
      "Epoch 608/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3025 - val_loss: -0.3596\n",
      "Epoch 609/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3037 - val_loss: -0.3597\n",
      "Epoch 610/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3061 - val_loss: -0.3625\n",
      "Epoch 611/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3043 - val_loss: -0.3625\n",
      "Epoch 612/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3037 - val_loss: -0.3625\n",
      "Epoch 613/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3046 - val_loss: -0.3639\n",
      "Epoch 614/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3042 - val_loss: -0.3611\n",
      "Epoch 615/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3028 - val_loss: -0.3611\n",
      "Epoch 616/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3031 - val_loss: -0.3625\n",
      "Epoch 617/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3047 - val_loss: -0.3625\n",
      "Epoch 618/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3057 - val_loss: -0.3611\n",
      "Epoch 619/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3069 - val_loss: -0.3611\n",
      "Epoch 620/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3047 - val_loss: -0.3626\n",
      "Epoch 621/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3044 - val_loss: -0.3626\n",
      "Epoch 622/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3060 - val_loss: -0.3639\n",
      "Epoch 623/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3051 - val_loss: -0.3653\n",
      "Epoch 624/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3066 - val_loss: -0.3667\n",
      "Epoch 625/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3060 - val_loss: -0.3639\n",
      "Epoch 626/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3070 - val_loss: -0.3639\n",
      "Epoch 627/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3058 - val_loss: -0.3639\n",
      "Epoch 628/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3060 - val_loss: -0.3639\n",
      "Epoch 629/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3073 - val_loss: -0.3626\n",
      "Epoch 630/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3053 - val_loss: -0.3608\n",
      "Epoch 631/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3052 - val_loss: -0.3609\n",
      "Epoch 632/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3048 - val_loss: -0.3609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3061 - val_loss: -0.3581\n",
      "Epoch 634/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3051 - val_loss: -0.3581\n",
      "Epoch 635/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3063 - val_loss: -0.3567\n",
      "Epoch 636/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3054 - val_loss: -0.3540\n",
      "Epoch 637/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3070 - val_loss: -0.3526\n",
      "Epoch 638/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3069 - val_loss: -0.3513\n",
      "Epoch 639/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3054 - val_loss: -0.3513\n",
      "Epoch 640/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3067 - val_loss: -0.3526\n",
      "Epoch 641/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3071 - val_loss: -0.3554\n",
      "Epoch 642/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3079 - val_loss: -0.3511\n",
      "Epoch 643/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3075 - val_loss: -0.3539\n",
      "Epoch 644/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3057 - val_loss: -0.3539\n",
      "Epoch 645/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3068 - val_loss: -0.3539\n",
      "Epoch 646/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3068 - val_loss: -0.3566\n",
      "Epoch 647/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3075 - val_loss: -0.3566\n",
      "Epoch 648/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3071 - val_loss: -0.3566\n",
      "Epoch 649/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3060 - val_loss: -0.3540\n",
      "Epoch 650/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3075 - val_loss: -0.3540\n",
      "Epoch 651/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3079 - val_loss: -0.3555\n",
      "Epoch 652/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3069 - val_loss: -0.3555\n",
      "Epoch 653/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3076 - val_loss: -0.3555\n",
      "Epoch 654/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3082 - val_loss: -0.3555\n",
      "Epoch 655/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3078 - val_loss: -0.3570\n",
      "Epoch 656/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3077 - val_loss: -0.3583\n",
      "Epoch 657/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3075 - val_loss: -0.3569\n",
      "Epoch 658/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3095 - val_loss: -0.3542\n",
      "Epoch 659/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3078 - val_loss: -0.3542\n",
      "Epoch 660/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3081 - val_loss: -0.3542\n",
      "Epoch 661/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3088 - val_loss: -0.3570\n",
      "Epoch 662/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3081 - val_loss: -0.3612\n",
      "Epoch 663/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3073 - val_loss: -0.3597\n",
      "Epoch 664/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3078 - val_loss: -0.3612\n",
      "Epoch 665/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3063 - val_loss: -0.3612\n",
      "Epoch 666/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3075 - val_loss: -0.3597\n",
      "Epoch 667/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3075 - val_loss: -0.3570\n",
      "Epoch 668/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3076 - val_loss: -0.3543\n",
      "Epoch 669/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3061 - val_loss: -0.3557\n",
      "Epoch 670/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3064 - val_loss: -0.3543\n",
      "Epoch 671/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3075 - val_loss: -0.3516\n",
      "Epoch 672/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3062 - val_loss: -0.3516\n",
      "Epoch 673/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3070 - val_loss: -0.3516\n",
      "Epoch 674/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3074 - val_loss: -0.3516\n",
      "Epoch 675/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3071 - val_loss: -0.3543\n",
      "Epoch 676/5000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: -0.3067 - val_loss: -0.3543\n",
      "Epoch 677/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3064 - val_loss: -0.3543\n",
      "Epoch 678/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3078 - val_loss: -0.3543\n",
      "Epoch 679/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3079 - val_loss: -0.3571\n",
      "Epoch 680/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3057 - val_loss: -0.3571\n",
      "Epoch 681/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3067 - val_loss: -0.3543\n",
      "Epoch 682/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3060 - val_loss: -0.3543\n",
      "Epoch 683/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3057 - val_loss: -0.3543\n",
      "Epoch 684/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3070 - val_loss: -0.3583\n",
      "Epoch 685/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3065 - val_loss: -0.3583\n",
      "Epoch 686/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3048 - val_loss: -0.3583\n",
      "Epoch 687/5000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: -0.3059 - val_loss: -0.3583\n",
      "Epoch 688/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3068 - val_loss: -0.3583\n",
      "Epoch 689/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3048 - val_loss: -0.3569\n",
      "Epoch 690/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.3045 - val_loss: -0.3528\n",
      "Epoch 691/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3057 - val_loss: -0.3569\n",
      "Epoch 692/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3050 - val_loss: -0.3556\n",
      "Epoch 693/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3041 - val_loss: -0.3556\n",
      "Epoch 694/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3074 - val_loss: -0.3556\n",
      "Epoch 695/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3052 - val_loss: -0.3585\n",
      "Epoch 696/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3051 - val_loss: -0.3585\n",
      "Epoch 697/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3062 - val_loss: -0.3585\n",
      "Epoch 698/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3061 - val_loss: -0.3585\n",
      "Epoch 699/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3061 - val_loss: -0.3557\n",
      "Epoch 700/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.3063 - val_loss: -0.3557\n",
      "Epoch 701/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3039 - val_loss: -0.3557\n",
      "Epoch 702/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3056 - val_loss: -0.3571\n",
      "Epoch 703/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3066 - val_loss: -0.3571\n",
      "Epoch 704/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3057 - val_loss: -0.3600\n",
      "Epoch 705/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3066 - val_loss: -0.3585\n",
      "Epoch 706/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3044 - val_loss: -0.3586\n",
      "Epoch 707/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3064 - val_loss: -0.3586\n",
      "Epoch 708/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3064 - val_loss: -0.3600\n",
      "Epoch 709/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3055 - val_loss: -0.3601\n",
      "Epoch 710/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3061 - val_loss: -0.3574\n",
      "Epoch 711/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3053 - val_loss: -0.3574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3054 - val_loss: -0.3574\n",
      "Epoch 713/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3042 - val_loss: -0.3587\n",
      "Epoch 714/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3059 - val_loss: -0.3587\n",
      "Epoch 715/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3060 - val_loss: -0.3558\n",
      "Epoch 716/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3061 - val_loss: -0.3573\n",
      "Epoch 717/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3052 - val_loss: -0.3629\n",
      "Epoch 718/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3057 - val_loss: -0.3642\n",
      "Epoch 719/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3041 - val_loss: -0.3571\n",
      "Epoch 720/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3058 - val_loss: -0.3543\n",
      "Epoch 721/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3054 - val_loss: -0.3557\n",
      "Epoch 722/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3045 - val_loss: -0.3557\n",
      "Epoch 723/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.3054 - val_loss: -0.3557\n",
      "Epoch 724/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3056 - val_loss: -0.3572\n",
      "Epoch 725/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3051 - val_loss: -0.3572\n",
      "Epoch 726/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3056 - val_loss: -0.3572\n",
      "Epoch 727/5000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: -0.3041 - val_loss: -0.3572\n",
      "Epoch 728/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3052 - val_loss: -0.3572\n",
      "Epoch 729/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3059 - val_loss: -0.3544\n",
      "Epoch 730/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3053 - val_loss: -0.3544\n",
      "Epoch 731/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3055 - val_loss: -0.3544\n",
      "Epoch 732/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.3047 - val_loss: -0.3531\n",
      "Epoch 733/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3049 - val_loss: -0.3517\n",
      "Epoch 734/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.3059 - val_loss: -0.3490\n",
      "Epoch 735/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.3058 - val_loss: -0.3491\n",
      "Epoch 736/5000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: -0.3045 - val_loss: -0.3504\n",
      "Epoch 737/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3031 - val_loss: -0.3504\n",
      "Epoch 738/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3015 - val_loss: -0.3518\n",
      "Epoch 739/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3022 - val_loss: -0.3504\n",
      "Epoch 740/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3034 - val_loss: -0.3475\n",
      "Epoch 741/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3012 - val_loss: -0.3475\n",
      "Epoch 742/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.3012 - val_loss: -0.3475\n",
      "Epoch 743/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.3000 - val_loss: -0.3461\n",
      "Epoch 744/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3011 - val_loss: -0.3461\n",
      "Epoch 745/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2989 - val_loss: -0.3433\n",
      "Epoch 746/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2994 - val_loss: -0.3433\n",
      "Epoch 747/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2983 - val_loss: -0.3433\n",
      "Epoch 748/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2990 - val_loss: -0.3447\n",
      "Epoch 749/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2992 - val_loss: -0.3433\n",
      "Epoch 750/5000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: -0.2979 - val_loss: -0.3433\n",
      "Epoch 751/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2974 - val_loss: -0.3433\n",
      "Epoch 752/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2977 - val_loss: -0.3447\n",
      "Epoch 753/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2987 - val_loss: -0.3431\n",
      "Epoch 754/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2977 - val_loss: -0.3458\n",
      "Epoch 755/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2973 - val_loss: -0.3458\n",
      "Epoch 756/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2971 - val_loss: -0.3500\n",
      "Epoch 757/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2980 - val_loss: -0.3500\n",
      "Epoch 758/5000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: -0.2981 - val_loss: -0.3500\n",
      "Epoch 759/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2985 - val_loss: -0.3500\n",
      "Epoch 760/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -0.2984 - val_loss: -0.3554\n",
      "Epoch 761/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2980 - val_loss: -0.3596\n",
      "Epoch 762/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.2986 - val_loss: -0.3584\n",
      "Epoch 763/5000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: -0.2979 - val_loss: -0.3570\n",
      "Epoch 764/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.2985 - val_loss: -0.3556\n",
      "Epoch 765/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.2988 - val_loss: -0.3570\n",
      "Epoch 766/5000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: -0.2999 - val_loss: -0.3570\n",
      "Epoch 767/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.2983 - val_loss: -0.3612\n",
      "Epoch 768/5000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: -0.2990 - val_loss: -0.3625\n",
      "Epoch 769/5000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: -0.2998 - val_loss: -0.3585\n",
      "Epoch 770/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.2993 - val_loss: -0.3544\n",
      "Epoch 771/5000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: -0.3000 - val_loss: -0.3558\n",
      "Epoch 772/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3001 - val_loss: -0.3558\n",
      "Epoch 773/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3009 - val_loss: -0.3558\n",
      "Epoch 774/5000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: -0.3015 - val_loss: -0.3584\n",
      "Epoch 775/5000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: -0.3002 - val_loss: -0.3585\n",
      "Epoch 776/5000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: -0.3016 - val_loss: -0.3640\n",
      "Epoch 777/5000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: -0.2997 - val_loss: -0.3627\n",
      "Epoch 778/5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(train_x_BSF_flat, train_y_BS, epochs=epochs, batch_size=batch_dim_size,\n",
    "          validation_data=(valid_x_BSF_flat, valid_y_BS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4bd7c07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'perturbed_bpr_model_11/dense_30/kernel:0' shape=(220, 100) dtype=float32, numpy=\n",
       " array([[ 0.00719592, -0.04645859, -0.01844875, ..., -0.04718753,\n",
       "          0.03084159,  0.14573094],\n",
       "        [-0.11836787, -0.12660244,  0.02698829, ..., -0.08388493,\n",
       "         -0.14309686,  0.19262102],\n",
       "        [-0.08026059, -0.28874218,  0.10318363, ..., -0.05022891,\n",
       "          0.02977351,  0.3901074 ],\n",
       "        ...,\n",
       "        [ 0.23114634,  0.08450731, -0.03968769, ..., -0.20577903,\n",
       "         -0.14238843, -0.15449598],\n",
       "        [-0.13269791, -0.06289726,  0.2431028 , ...,  0.16756043,\n",
       "         -0.20101394,  0.24970037],\n",
       "        [-0.16971661, -0.25981182,  0.2715672 , ...,  0.07830626,\n",
       "          0.02652317,  0.31739092]], dtype=float32)>,\n",
       " <tf.Variable 'perturbed_bpr_model_11/dense_30/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([ 0.06196941,  0.161347  ,  0.26962522,  0.08456077, -0.12389129,\n",
       "        -0.18943824, -0.16642849, -0.06824225, -0.01711683, -0.04803375,\n",
       "        -0.12577438,  0.14450517, -0.1745591 ,  0.18152225, -0.01784974,\n",
       "         0.07673255,  0.22689706, -0.10442719,  0.27293193, -0.12214922,\n",
       "        -0.04902637,  0.29734105,  0.07263076, -0.08457791,  0.23699948,\n",
       "         0.2743411 ,  0.13241151,  0.16187541,  0.2872746 ,  0.09286996,\n",
       "        -0.21985103,  0.09495785,  0.11223248, -0.10286745, -0.04915763,\n",
       "         0.11608356, -0.1514701 , -0.04466423,  0.25726283,  0.20983182,\n",
       "         0.01257624,  0.32293814, -0.04589473, -0.03503021, -0.17706649,\n",
       "         0.07564362, -0.13077693,  0.01432978,  0.17703971,  0.18873183,\n",
       "        -0.1131293 ,  0.03481518,  0.05778114, -0.07319631,  0.2078463 ,\n",
       "        -0.13609533, -0.0713748 , -0.23473269,  0.09235203,  0.2635128 ,\n",
       "        -0.07138819, -0.16536959,  0.18316275,  0.08979566,  0.16930754,\n",
       "         0.1387612 ,  0.05420332,  0.08587062,  0.01027954, -0.0775041 ,\n",
       "         0.13040826, -0.00127377, -0.20082243, -0.07727101,  0.0616587 ,\n",
       "        -0.16904022, -0.14829528, -0.03036118,  0.00722793,  0.03337456,\n",
       "         0.20450987, -0.01673643, -0.05501471,  0.30078977,  0.00882818,\n",
       "         0.13204947,  0.2834816 ,  0.12339916,  0.2860619 , -0.15078622,\n",
       "         0.07579398,  0.02290337, -0.11744312, -0.19973963, -0.05175095,\n",
       "         0.03661655, -0.24238974,  0.10001019, -0.0937991 ,  0.28242272],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'perturbed_bpr_model_11/dense_31/kernel:0' shape=(100, 50) dtype=float32, numpy=\n",
       " array([[ 0.3113129 ,  0.02425809, -0.01151917, ...,  0.21526329,\n",
       "         -0.05677716,  0.16523115],\n",
       "        [-0.17206028,  0.18039775, -0.05794205, ...,  0.17394324,\n",
       "         -0.26211557,  0.077457  ],\n",
       "        [ 0.08679532,  0.09552915, -0.14032826, ..., -0.02540003,\n",
       "         -0.02940189, -0.07073361],\n",
       "        ...,\n",
       "        [-0.12224188, -0.1279378 ,  0.09245271, ...,  0.10310875,\n",
       "         -0.20233272, -0.0471791 ],\n",
       "        [ 0.24100548,  0.13626106, -0.03960603, ..., -0.01096263,\n",
       "         -0.02946306, -0.11800308],\n",
       "        [ 0.3603098 , -0.22570513, -0.21392712, ...,  0.21894561,\n",
       "         -0.05973308, -0.11217644]], dtype=float32)>,\n",
       " <tf.Variable 'perturbed_bpr_model_11/dense_31/bias:0' shape=(50,) dtype=float32, numpy=\n",
       " array([ 1.00005575e-01, -1.01531610e-01, -9.30095464e-02,  1.28929794e-01,\n",
       "        -2.11383514e-02,  1.31412940e-02,  8.54101852e-02, -4.35329787e-03,\n",
       "        -4.51109149e-02, -8.34780857e-02, -2.51342393e-02, -6.97468817e-02,\n",
       "        -4.40792404e-02, -4.19074111e-02,  6.55528679e-02, -8.15586522e-02,\n",
       "         2.17970908e-02, -9.60994139e-02, -1.11547448e-01, -9.36332047e-02,\n",
       "        -3.14469375e-02, -6.54800460e-02,  3.69069465e-02,  7.53033012e-02,\n",
       "        -6.25198185e-02, -9.80031118e-02, -1.60127878e-02, -5.32463156e-02,\n",
       "        -8.15062895e-02, -2.33605169e-02, -7.91660473e-02, -1.29606880e-04,\n",
       "        -1.16635807e-01, -8.08569565e-02, -1.01729184e-01,  1.50765851e-01,\n",
       "        -8.43051672e-02, -7.82075524e-02,  1.44016489e-01, -3.91147844e-02,\n",
       "        -9.93565917e-02,  1.23817310e-01,  1.38814626e-02, -2.04298068e-02,\n",
       "         1.82215184e-01,  2.22326294e-01, -9.66285393e-02,  1.24819204e-01,\n",
       "        -9.09582153e-02,  8.57323557e-02], dtype=float32)>,\n",
       " <tf.Variable 'perturbed_bpr_model_11/dense_32/kernel:0' shape=(50, 10) dtype=float32, numpy=\n",
       " array([[ 1.95875078e-01, -2.46811315e-01, -4.72223073e-01,\n",
       "         -3.37265074e-01, -1.58412158e-01, -2.98508465e-01,\n",
       "          9.60430354e-02, -2.32306033e-01,  2.01758429e-01,\n",
       "         -5.38044333e-01],\n",
       "        [ 1.27926514e-01, -7.43270740e-02, -3.57296988e-02,\n",
       "          1.54645473e-01, -6.18487597e-02, -1.65955633e-01,\n",
       "         -1.44008636e-01, -1.04995251e-01,  1.21135712e-01,\n",
       "         -2.25630909e-01],\n",
       "        [ 1.01998784e-01,  2.74834663e-01,  2.42172644e-01,\n",
       "         -6.27384633e-02, -2.57651299e-01,  2.14182794e-01,\n",
       "         -3.62503797e-01, -3.65473032e-01, -1.92731217e-01,\n",
       "          2.06002608e-01],\n",
       "        [ 1.80075482e-01, -3.71258795e-01, -2.61296749e-01,\n",
       "         -4.57373053e-01,  4.95965667e-02, -5.16647063e-02,\n",
       "          7.59669468e-02, -4.27374803e-02, -1.76100850e-01,\n",
       "          2.19880007e-02],\n",
       "        [-3.09117049e-01, -9.19109881e-02, -1.04829565e-01,\n",
       "         -1.77065432e-01,  8.50035623e-02, -1.63977668e-01,\n",
       "         -3.30010265e-01, -2.44378030e-01,  1.53936893e-01,\n",
       "          2.86754787e-01],\n",
       "        [-1.84941307e-01, -9.42193866e-02,  1.68555781e-01,\n",
       "          7.64851421e-02,  1.92565575e-01, -2.71570951e-01,\n",
       "         -2.11914703e-01, -2.54993409e-01, -2.98617601e-01,\n",
       "          1.77060336e-01],\n",
       "        [-3.36234808e-01, -9.63456109e-02, -5.33538982e-02,\n",
       "         -3.18772912e-01, -3.91505957e-02, -1.34833217e-01,\n",
       "         -3.63499910e-01, -3.25140543e-02, -3.27505410e-01,\n",
       "          1.19200572e-01],\n",
       "        [-3.17619503e-01,  1.62278488e-01,  1.76362067e-01,\n",
       "         -1.34711757e-01,  5.00876643e-02, -1.02883123e-01,\n",
       "          8.53721332e-03, -3.73590767e-01, -6.22936115e-02,\n",
       "         -3.04138541e-01],\n",
       "        [ 4.50599473e-03,  6.22530654e-03, -1.69582382e-01,\n",
       "         -2.77122319e-01,  6.16991259e-02,  1.63004920e-01,\n",
       "         -1.36213854e-01,  6.70165047e-02, -2.08193555e-01,\n",
       "         -1.54059425e-01],\n",
       "        [-6.40305281e-02, -9.45914909e-02, -1.51089743e-01,\n",
       "         -7.33821094e-02, -7.71872029e-02, -2.39271931e-02,\n",
       "         -6.22283109e-03,  8.93587619e-02, -1.17347300e-01,\n",
       "         -2.47684762e-01],\n",
       "        [-1.63376451e-01, -1.76221833e-01, -8.79399776e-02,\n",
       "          2.71648973e-01,  2.03685328e-01,  1.80371910e-01,\n",
       "          1.17239309e-03,  1.95545807e-01,  7.11564496e-02,\n",
       "          2.71087345e-02],\n",
       "        [ 1.98562518e-01,  2.26768106e-01,  1.36282668e-01,\n",
       "          1.77778900e-01, -1.76433399e-01,  5.20889461e-02,\n",
       "          1.07710838e-01,  6.88004047e-02,  3.79579067e-01,\n",
       "          2.68558979e-01],\n",
       "        [ 1.85561851e-01, -2.74629951e-01,  1.32847220e-01,\n",
       "          9.18688998e-02, -2.90123411e-02, -1.21978475e-02,\n",
       "         -2.81141460e-01, -2.68001437e-01, -4.08039421e-01,\n",
       "          5.27159162e-02],\n",
       "        [ 2.01915324e-01, -2.76733011e-01, -1.47309035e-01,\n",
       "         -5.33955880e-02,  1.85078800e-01,  4.88565164e-03,\n",
       "          6.42105117e-02,  4.80438694e-02, -8.63084942e-02,\n",
       "          2.22420931e-01],\n",
       "        [-1.20843187e-01,  2.14826494e-01, -5.20745099e-01,\n",
       "         -5.03885746e-01, -1.17487498e-01, -7.05916733e-02,\n",
       "         -1.67038009e-01, -1.23388231e-01, -1.28016338e-01,\n",
       "         -4.74609315e-01],\n",
       "        [-4.52269837e-02, -4.85737473e-02,  3.85734327e-02,\n",
       "         -1.27406925e-01, -3.50466631e-02,  2.11743396e-02,\n",
       "         -2.19038561e-01, -8.04390162e-02, -4.00949478e-01,\n",
       "         -2.45187446e-01],\n",
       "        [-1.88211471e-01, -4.64112610e-02,  1.86433837e-01,\n",
       "          2.17997115e-02, -3.57263386e-01, -1.66166067e-01,\n",
       "          6.01466000e-02,  8.10768083e-02,  3.05383652e-01,\n",
       "          1.46421671e-01],\n",
       "        [-9.27900299e-02,  5.01757115e-02, -7.38479495e-02,\n",
       "          1.40812576e-01,  1.24622725e-01,  2.04784513e-01,\n",
       "          3.48151237e-01, -3.68483812e-01,  1.47933155e-01,\n",
       "          1.81888655e-01],\n",
       "        [ 1.38218164e-01,  1.31157368e-01, -2.24358708e-01,\n",
       "          1.89895332e-01, -4.49910462e-02, -2.86634684e-01,\n",
       "         -4.32112478e-02, -9.71412882e-02,  2.19657168e-01,\n",
       "         -9.17737409e-02],\n",
       "        [-2.68564343e-01,  1.87938005e-01,  7.75916949e-02,\n",
       "          2.63299793e-02, -1.22361057e-01, -2.59364992e-01,\n",
       "         -2.91448295e-01, -1.97657049e-01,  6.67273551e-02,\n",
       "          2.75994122e-01],\n",
       "        [ 4.38353419e-02, -1.97173193e-01,  1.76865473e-01,\n",
       "          1.77994445e-01, -3.64645034e-01, -2.39299789e-01,\n",
       "         -2.07451239e-01, -3.81498516e-01,  1.52016319e-02,\n",
       "         -1.25958147e-02],\n",
       "        [-2.67997812e-02, -1.59805149e-01,  3.03359628e-01,\n",
       "          7.13107288e-02, -2.25620851e-01, -8.62153247e-02,\n",
       "          1.24562107e-01,  1.63213417e-01,  2.07317457e-01,\n",
       "          4.45367247e-01],\n",
       "        [-2.24349797e-01, -1.52326509e-01, -3.39937843e-02,\n",
       "         -7.42606595e-02,  4.65432517e-02,  1.01402573e-01,\n",
       "         -1.38725251e-01, -2.34633327e-01, -4.71298471e-02,\n",
       "         -1.70796979e-02],\n",
       "        [-2.30849937e-01,  1.05772898e-01, -5.12394421e-02,\n",
       "         -5.12629151e-01, -1.84971705e-01,  1.84530363e-04,\n",
       "         -2.36932307e-01, -2.18882173e-01,  1.46651983e-01,\n",
       "         -2.23187909e-01],\n",
       "        [-1.69038365e-03, -1.36010442e-02,  3.80972326e-01,\n",
       "          5.47939539e-01, -2.81193852e-01, -9.04562026e-02,\n",
       "         -2.19127193e-01,  1.93251193e-01, -1.84302941e-01,\n",
       "          4.24676031e-01],\n",
       "        [ 2.12972671e-01, -9.25237015e-02, -2.39837710e-02,\n",
       "          1.31174415e-01, -2.76887212e-02,  2.34827772e-01,\n",
       "          6.97093084e-02, -2.16010153e-01,  3.39141607e-01,\n",
       "         -8.13458406e-04],\n",
       "        [ 9.72609967e-02, -1.00987246e-02,  4.42921137e-03,\n",
       "         -2.78848290e-01,  2.80591995e-01, -7.00618327e-02,\n",
       "         -3.78961563e-01, -6.85406253e-02, -2.21157983e-01,\n",
       "          1.10433735e-01],\n",
       "        [-2.20569521e-01,  1.76623866e-01,  2.12192416e-01,\n",
       "         -1.72434732e-01, -3.27922404e-01,  9.17558074e-02,\n",
       "          1.84106246e-01,  2.30492547e-01, -2.15500534e-01,\n",
       "         -5.79158217e-02],\n",
       "        [ 1.78445682e-01, -2.38114551e-01,  7.36327097e-02,\n",
       "          2.97517702e-02,  1.57616481e-01,  4.48315516e-02,\n",
       "          1.14810899e-01, -9.93466452e-02, -7.25081116e-02,\n",
       "          2.67807901e-01],\n",
       "        [-1.66401267e-01, -2.57866472e-01,  1.37110025e-01,\n",
       "         -1.87973320e-01,  1.07490584e-01, -2.50243515e-01,\n",
       "         -1.65756419e-01, -2.46731982e-01,  1.47876620e-01,\n",
       "          2.39208996e-01],\n",
       "        [-7.43888766e-02,  2.02003151e-01, -1.10826269e-01,\n",
       "          1.76130965e-01,  5.12799025e-02,  6.81056976e-02,\n",
       "         -7.21341446e-02, -3.30697328e-01,  2.94280443e-02,\n",
       "          2.47210965e-01],\n",
       "        [-1.92759320e-01, -3.55180949e-01, -1.81252390e-01,\n",
       "          2.27042958e-01,  1.23760991e-01,  5.07974364e-02,\n",
       "          1.81521803e-01,  1.51001379e-01,  2.15816021e-01,\n",
       "          3.33198681e-02],\n",
       "        [ 1.49819598e-01,  2.27570936e-01,  2.90653408e-01,\n",
       "          2.52694577e-01,  2.53324300e-01, -1.61939204e-01,\n",
       "         -3.44983004e-02,  7.12018013e-02, -2.20719531e-01,\n",
       "         -1.12911640e-02],\n",
       "        [ 2.46512070e-01, -1.49606064e-01, -2.06386581e-01,\n",
       "          1.13632433e-01,  2.96614587e-01, -8.18201527e-02,\n",
       "         -4.70998660e-02, -2.41093218e-01, -1.41083315e-01,\n",
       "         -4.22945768e-02],\n",
       "        [ 1.78166956e-01, -2.05719009e-01, -4.46621701e-02,\n",
       "         -3.38124454e-01,  2.46528815e-02,  7.20852166e-02,\n",
       "         -1.12458011e-02,  4.95458208e-02,  9.84982327e-02,\n",
       "          8.15842077e-02],\n",
       "        [-2.26894587e-01, -7.74592385e-02, -2.21854731e-01,\n",
       "         -4.05027233e-02, -1.39676025e-02, -1.61600247e-01,\n",
       "         -1.07849196e-01,  1.58209756e-01, -2.09390372e-01,\n",
       "         -4.91277039e-01],\n",
       "        [-1.15753368e-01, -1.56408891e-01, -2.40146548e-01,\n",
       "         -1.87319636e-01,  1.39068410e-01,  6.53621256e-02,\n",
       "          5.67889623e-02, -3.07009459e-01, -2.15299100e-01,\n",
       "          3.59101556e-02],\n",
       "        [-1.39454186e-01,  1.67293683e-01, -1.26616418e-01,\n",
       "         -2.64139920e-01, -1.39324376e-02, -2.06063315e-01,\n",
       "         -1.39188513e-01,  9.70063508e-02,  1.16148353e-01,\n",
       "          3.74552011e-02],\n",
       "        [ 8.11601803e-02, -2.49201834e-01, -1.84712425e-01,\n",
       "         -9.73212719e-02, -2.78652221e-01,  9.98514220e-02,\n",
       "         -2.08563879e-01, -5.04094400e-02, -8.72000083e-02,\n",
       "         -4.85181987e-01],\n",
       "        [-1.20132817e-02, -2.77752012e-01,  4.02832091e-01,\n",
       "          2.61985213e-01, -2.47055069e-01,  2.28398517e-01,\n",
       "         -1.89489424e-01, -2.28795797e-01,  3.44108380e-02,\n",
       "          2.45864898e-01],\n",
       "        [-9.76900477e-03, -1.37335155e-02,  7.01337382e-02,\n",
       "          1.26210421e-01, -2.84071594e-01, -1.65182948e-01,\n",
       "          1.14877053e-01,  2.20132731e-02, -2.11608663e-01,\n",
       "          7.93082342e-02],\n",
       "        [-3.01901937e-01, -1.77844107e-01, -2.85863698e-01,\n",
       "          8.93211961e-02, -2.80980915e-01,  6.94303587e-02,\n",
       "         -1.86458215e-01, -1.16454929e-01,  2.50128936e-02,\n",
       "         -3.00435036e-01],\n",
       "        [-2.09402591e-01,  5.74486963e-02, -2.97486354e-02,\n",
       "         -1.41114086e-01,  2.63312072e-01, -1.25086710e-01,\n",
       "          1.46693796e-01, -3.07484090e-01,  3.13747466e-01,\n",
       "          1.39975205e-01],\n",
       "        [-6.63043410e-02, -1.31920457e-01,  1.00735977e-01,\n",
       "         -1.38303265e-01,  9.91932154e-02, -1.17301501e-01,\n",
       "         -4.23665270e-02, -1.35113835e-01,  6.43513575e-02,\n",
       "         -2.64238060e-01],\n",
       "        [-2.57805139e-01, -3.88115674e-01, -1.46983087e-01,\n",
       "         -2.70715445e-01,  7.28125572e-02, -1.63426489e-01,\n",
       "         -3.56729805e-01, -1.95077494e-01,  2.24544741e-02,\n",
       "         -3.54700059e-01],\n",
       "        [-3.41798782e-01, -2.09105402e-01, -1.78845361e-01,\n",
       "         -5.87644935e-01, -2.97720805e-02, -1.75244510e-01,\n",
       "         -2.24397853e-01, -2.05036014e-01, -4.02478129e-01,\n",
       "         -3.51247281e-01],\n",
       "        [ 1.07048534e-01,  1.57502115e-01,  3.78697477e-02,\n",
       "          8.15012157e-02, -2.29941517e-01,  1.60440862e-01,\n",
       "          6.42969832e-02,  6.57608658e-02,  6.73384443e-02,\n",
       "          3.48730862e-01],\n",
       "        [-1.78216219e-01,  1.40187100e-01, -3.25875729e-01,\n",
       "          8.99039954e-02, -2.30339587e-01, -3.58662903e-02,\n",
       "         -3.55251968e-01, -1.54223561e-01,  1.66799843e-01,\n",
       "         -3.95193756e-01],\n",
       "        [ 5.14905676e-02, -5.03151380e-02, -1.15405239e-01,\n",
       "          8.16883072e-02, -2.72549987e-01, -1.05052650e-01,\n",
       "         -1.45196036e-01,  1.43677980e-01, -1.43060133e-01,\n",
       "         -6.32309392e-02],\n",
       "        [-7.50273243e-02, -2.58960873e-01, -1.72438741e-01,\n",
       "         -8.69045705e-02, -2.51995087e-01,  7.87629560e-02,\n",
       "         -9.94431153e-02, -3.36013705e-01,  4.86193411e-02,\n",
       "          8.54166448e-02]], dtype=float32)>,\n",
       " <tf.Variable 'perturbed_bpr_model_11/dense_32/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.10525838, -0.0728705 , -0.00609684, -0.0477941 ,  0.01350171,\n",
       "        -0.07551055, -0.08296724, -0.07980055, -0.00713027, -0.03374817],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'perturbed_bpr_model_11/dense_33/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
       " array([[ 0.4051138 ],\n",
       "        [ 0.62207377],\n",
       "        [-0.6162775 ],\n",
       "        [-0.35231346],\n",
       "        [-0.11070294],\n",
       "        [-0.5943433 ],\n",
       "        [ 0.57698303],\n",
       "        [ 0.44531274],\n",
       "        [-0.00659022],\n",
       "        [-0.34358066]], dtype=float32)>,\n",
       " <tf.Variable 'perturbed_bpr_model_11/dense_33/bias:0' shape=(1,) dtype=float32, numpy=array([0.15289459], dtype=float32)>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b9bc2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>deaths</th>\n",
       "      <th>month</th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>COUNTYFP</th>\n",
       "      <th>TRACTCE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>NAMELSAD</th>\n",
       "      <th>MTFCC</th>\n",
       "      <th>...</th>\n",
       "      <th>TRACTCE_y</th>\n",
       "      <th>month_sinc</th>\n",
       "      <th>season</th>\n",
       "      <th>season_sin</th>\n",
       "      <th>qtr_since_</th>\n",
       "      <th>year_since</th>\n",
       "      <th>self_t-1</th>\n",
       "      <th>neighbor_t</th>\n",
       "      <th>geometry</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoid</th>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">25001010100</th>\n",
       "      <th>0.0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>001</td>\n",
       "      <td>10100</td>\n",
       "      <td>101</td>\n",
       "      <td>Census Tract 101</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jan-jun</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>POLYGON ((-70.25001 42.06410, -70.24959 42.065...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>001</td>\n",
       "      <td>10100</td>\n",
       "      <td>101</td>\n",
       "      <td>Census Tract 101</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>jan-jun</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>POLYGON ((-70.25001 42.06410, -70.24959 42.065...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>001</td>\n",
       "      <td>10100</td>\n",
       "      <td>101</td>\n",
       "      <td>Census Tract 101</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>jul-dec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>POLYGON ((-70.25001 42.06410, -70.24959 42.065...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>001</td>\n",
       "      <td>10100</td>\n",
       "      <td>101</td>\n",
       "      <td>Census Tract 101</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>jul-dec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>POLYGON ((-70.25001 42.06410, -70.24959 42.065...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>001</td>\n",
       "      <td>10100</td>\n",
       "      <td>101</td>\n",
       "      <td>Census Tract 101</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>jan-jun</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>POLYGON ((-70.25001 42.06410, -70.24959 42.065...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">25027761402</th>\n",
       "      <th>83.0</th>\n",
       "      <td>2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>027</td>\n",
       "      <td>761402</td>\n",
       "      <td>7614.02</td>\n",
       "      <td>Census Tract 7614.02</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249.0</td>\n",
       "      <td>jul-dec</td>\n",
       "      <td>41.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>POLYGON ((-71.63921 42.53096, -71.63906 42.531...</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84.0</th>\n",
       "      <td>2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>027</td>\n",
       "      <td>761402</td>\n",
       "      <td>7614.02</td>\n",
       "      <td>Census Tract 7614.02</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>jan-jun</td>\n",
       "      <td>42.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>POLYGON ((-71.63921 42.53096, -71.63906 42.531...</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85.0</th>\n",
       "      <td>2021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>027</td>\n",
       "      <td>761402</td>\n",
       "      <td>7614.02</td>\n",
       "      <td>Census Tract 7614.02</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>jan-jun</td>\n",
       "      <td>42.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>POLYGON ((-71.63921 42.53096, -71.63906 42.531...</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86.0</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>027</td>\n",
       "      <td>761402</td>\n",
       "      <td>7614.02</td>\n",
       "      <td>Census Tract 7614.02</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.0</td>\n",
       "      <td>jul-dec</td>\n",
       "      <td>43.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>POLYGON ((-71.63921 42.53096, -71.63906 42.531...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87.0</th>\n",
       "      <td>2021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>027</td>\n",
       "      <td>761402</td>\n",
       "      <td>7614.02</td>\n",
       "      <td>Census Tract 7614.02</td>\n",
       "      <td>G5020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261.0</td>\n",
       "      <td>jul-dec</td>\n",
       "      <td>43.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>POLYGON ((-71.63921 42.53096, -71.63906 42.531...</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142560 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      year  quarter  deaths  month STATEFP COUNTYFP TRACTCE   \n",
       "geoid       timestep                                                          \n",
       "25001010100 0.0       2000      1.0     0.0      1      25      001   10100  \\\n",
       "            1.0       2000      2.0     0.0      4      25      001   10100   \n",
       "            2.0       2000      3.0     0.0      7      25      001   10100   \n",
       "            3.0       2000      4.0     0.0     10      25      001   10100   \n",
       "            4.0       2001      1.0     3.0      1      25      001   10100   \n",
       "...                    ...      ...     ...    ...     ...      ...     ...   \n",
       "25027761402 83.0      2020      4.0     0.0     10      25      027  761402   \n",
       "            84.0      2021      1.0     1.0      1      25      027  761402   \n",
       "            85.0      2021      2.0     0.0      4      25      027  761402   \n",
       "            86.0      2021      3.0     0.0      7      25      027  761402   \n",
       "            87.0      2021      4.0     0.0     10      25      027  761402   \n",
       "\n",
       "                         NAME              NAMELSAD  MTFCC  ... TRACTCE_y   \n",
       "geoid       timestep                                        ...             \n",
       "25001010100 0.0           101      Census Tract 101  G5020  ...       NaN  \\\n",
       "            1.0           101      Census Tract 101  G5020  ...       NaN   \n",
       "            2.0           101      Census Tract 101  G5020  ...       NaN   \n",
       "            3.0           101      Census Tract 101  G5020  ...       NaN   \n",
       "            4.0           101      Census Tract 101  G5020  ...       NaN   \n",
       "...                       ...                   ...    ...  ...       ...   \n",
       "25027761402 83.0      7614.02  Census Tract 7614.02  G5020  ...       NaN   \n",
       "            84.0      7614.02  Census Tract 7614.02  G5020  ...       NaN   \n",
       "            85.0      7614.02  Census Tract 7614.02  G5020  ...       NaN   \n",
       "            86.0      7614.02  Census Tract 7614.02  G5020  ...       NaN   \n",
       "            87.0      7614.02  Census Tract 7614.02  G5020  ...       NaN   \n",
       "\n",
       "                      month_sinc   season  season_sin  qtr_since_  year_since   \n",
       "geoid       timestep                                                            \n",
       "25001010100 0.0              0.0  jan-jun         0.0         0.0         0.0  \\\n",
       "            1.0              3.0  jan-jun         0.0         1.0         0.0   \n",
       "            2.0              6.0  jul-dec         1.0         2.0         0.0   \n",
       "            3.0              9.0  jul-dec         1.0         3.0         0.0   \n",
       "            4.0             12.0  jan-jun         2.0         4.0         1.0   \n",
       "...                          ...      ...         ...         ...         ...   \n",
       "25027761402 83.0           249.0  jul-dec        41.0        83.0        20.0   \n",
       "            84.0           252.0  jan-jun        42.0        84.0        21.0   \n",
       "            85.0           255.0  jan-jun        42.0        85.0        21.0   \n",
       "            86.0           258.0  jul-dec        43.0        86.0        21.0   \n",
       "            87.0           261.0  jul-dec        43.0        87.0        21.0   \n",
       "\n",
       "                      self_t-1  neighbor_t   \n",
       "geoid       timestep                         \n",
       "25001010100 0.0            0.0       0.000  \\\n",
       "            1.0            0.0       0.000   \n",
       "            2.0            0.0       0.000   \n",
       "            3.0            0.0       0.000   \n",
       "            4.0            0.0       0.000   \n",
       "...                        ...         ...   \n",
       "25027761402 83.0           0.0       0.125   \n",
       "            84.0           0.0       0.125   \n",
       "            85.0           0.0       0.000   \n",
       "            86.0           0.0       0.000   \n",
       "            87.0           0.0       0.375   \n",
       "\n",
       "                                                               geometry   \n",
       "geoid       timestep                                                      \n",
       "25001010100 0.0       POLYGON ((-70.25001 42.06410, -70.24959 42.065...  \\\n",
       "            1.0       POLYGON ((-70.25001 42.06410, -70.24959 42.065...   \n",
       "            2.0       POLYGON ((-70.25001 42.06410, -70.24959 42.065...   \n",
       "            3.0       POLYGON ((-70.25001 42.06410, -70.24959 42.065...   \n",
       "            4.0       POLYGON ((-70.25001 42.06410, -70.24959 42.065...   \n",
       "...                                                                 ...   \n",
       "25027761402 83.0      POLYGON ((-71.63921 42.53096, -71.63906 42.531...   \n",
       "            84.0      POLYGON ((-71.63921 42.53096, -71.63906 42.531...   \n",
       "            85.0      POLYGON ((-71.63921 42.53096, -71.63906 42.531...   \n",
       "            86.0      POLYGON ((-71.63921 42.53096, -71.63906 42.531...   \n",
       "            87.0      POLYGON ((-71.63921 42.53096, -71.63906 42.531...   \n",
       "\n",
       "                      timestep  \n",
       "geoid       timestep            \n",
       "25001010100 0.0            0.0  \n",
       "            1.0            1.0  \n",
       "            2.0            2.0  \n",
       "            3.0            3.0  \n",
       "            4.0            4.0  \n",
       "...                        ...  \n",
       "25027761402 83.0          83.0  \n",
       "            84.0          84.0  \n",
       "            85.0          85.0  \n",
       "            86.0          86.0  \n",
       "            87.0          87.0  \n",
       "\n",
       "[142560 rows x 34 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiindexed_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2a7e8e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 1620, 220), dtype=float32, numpy=\n",
       "array([[[-0.7479397 ,  1.8678857 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.647509  ],\n",
       "        [-1.2349257 ,  2.1685455 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.647509  ],\n",
       "        [-0.9121866 ,  2.0892835 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.647509  ],\n",
       "        ...,\n",
       "        [-0.10952955, -0.57149386, -1.4142135 , ..., -0.5008921 ,\n",
       "         -0.45583406, -1.647509  ],\n",
       "        [ 0.77810806, -0.37315318, -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.647509  ],\n",
       "        [ 0.9257272 , -0.39440045, -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.647509  ]],\n",
       "\n",
       "       [[-0.7479397 ,  1.8678857 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.474087  ],\n",
       "        [-1.2349257 ,  2.1685455 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.474087  ],\n",
       "        [-0.9121866 ,  2.0892835 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.474087  ],\n",
       "        ...,\n",
       "        [-0.10952955, -0.57149386, -1.4142135 , ..., -0.5008921 ,\n",
       "         -0.45583406, -1.474087  ],\n",
       "        [ 0.77810806, -0.37315318, -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.474087  ],\n",
       "        [ 0.9257272 , -0.39440045, -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.474087  ]],\n",
       "\n",
       "       [[-0.7479397 ,  1.8678857 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.300665  ],\n",
       "        [-1.2349257 ,  2.1685455 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.300665  ],\n",
       "        [-0.9121866 ,  2.0892835 , -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.300665  ],\n",
       "        ...,\n",
       "        [-0.10952955, -0.57149386, -1.4142135 , ..., -0.5008921 ,\n",
       "         -0.45583406, -1.300665  ],\n",
       "        [ 0.77810806, -0.37315318, -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.300665  ],\n",
       "        [ 0.9257272 , -0.39440045, -1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406, -1.300665  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.7479397 ,  1.8678857 ,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.300665  ],\n",
       "        [-1.2349257 ,  2.1685455 ,  1.4142135 , ...,  6.027843  ,\n",
       "         -0.45583406,  1.300665  ],\n",
       "        [-0.9121866 ,  2.0892835 ,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.300665  ],\n",
       "        ...,\n",
       "        [-0.10952955, -0.57149386,  1.4142135 , ..., -0.5008921 ,\n",
       "         -0.45583406,  1.300665  ],\n",
       "        [ 0.77810806, -0.37315318,  1.4142135 , ...,  1.340546  ,\n",
       "         -0.45583406,  1.300665  ],\n",
       "        [ 0.9257272 , -0.39440045,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.300665  ]],\n",
       "\n",
       "       [[-0.7479397 ,  1.8678857 ,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.474087  ],\n",
       "        [-1.2349257 ,  2.1685455 ,  1.4142135 , ...,  6.027843  ,\n",
       "         -0.45583406,  1.474087  ],\n",
       "        [-0.9121866 ,  2.0892835 ,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.474087  ],\n",
       "        ...,\n",
       "        [-0.10952955, -0.57149386,  1.4142135 , ..., -0.5008921 ,\n",
       "         -0.45583406,  1.474087  ],\n",
       "        [ 0.77810806, -0.37315318,  1.4142135 , ...,  1.340546  ,\n",
       "         -0.45583406,  1.474087  ],\n",
       "        [ 0.9257272 , -0.39440045,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.474087  ]],\n",
       "\n",
       "       [[-0.7479397 ,  1.8678857 ,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.647509  ],\n",
       "        [-1.2349257 ,  2.1685455 ,  1.4142135 , ...,  6.027843  ,\n",
       "         -0.45583406,  1.647509  ],\n",
       "        [-0.9121866 ,  2.0892835 ,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.647509  ],\n",
       "        ...,\n",
       "        [-0.10952955, -0.57149386,  1.4142135 , ..., -0.5008921 ,\n",
       "         -0.45583406,  1.647509  ],\n",
       "        [ 0.77810806, -0.37315318,  1.4142135 , ...,  1.340546  ,\n",
       "         -0.45583406,  1.647509  ],\n",
       "        [ 0.9257272 , -0.39440045,  1.4142135 , ..., -1.0031025 ,\n",
       "         -0.45583406,  1.647509  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_BSF_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a81d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
