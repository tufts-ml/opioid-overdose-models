{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4837a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/gpflow/session.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Run a zero-inflated GP on opioid data\"\"\"\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "idx = pd.IndexSlice\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import copy\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "code_dir = '/cluster/home/kheuto01/code/zero-inflated-gp/'\n",
    "sys.path.append(code_dir)\n",
    "from onoffgpf import OnOffSVGP, OnOffLikelihood\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eedb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    https://stackoverflow.com/a/4913653/1748679\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "    return c * r\n",
    "\n",
    "\n",
    "def top_X(y_true, y_pred, X=10):\n",
    "    top_X_predicted = y_pred.sort_values(ascending=False)[:X]\n",
    "    top_X_true = y_true.sort_values(ascending=False)[:X]\n",
    "\n",
    "    undisputed_top_predicted = top_X_predicted[top_X_predicted > top_X_predicted.min()]\n",
    "    num_tied_spots = X - len(undisputed_top_predicted)\n",
    "    undisputed_top_true = top_X_true[top_X_true > top_X_true.min()]\n",
    "    num_true_ties = X - len(undisputed_top_true)\n",
    "\n",
    "    tied_top_predicted = top_X_predicted[top_X_predicted == top_X_predicted.min()]\n",
    "    tied_top_true = top_X_true[top_X_true == top_X_true.min()]\n",
    "\n",
    "    error_in_top_true_ties = np.abs(tied_top_true - y_pred[tied_top_true.index]).sort_values(ascending=True)\n",
    "    error_in_top_pred_ties = np.abs(y_true[tied_top_predicted.index] - tied_top_predicted).sort_values(ascending=True)\n",
    "    top_true_tied_geoids = error_in_top_true_ties[:num_true_ties].index\n",
    "    top_pred_tied_geoids = error_in_top_pred_ties[:num_tied_spots].index\n",
    "\n",
    "    best_possible_top_true_geoids = pd.Index.union(undisputed_top_true.index, top_true_tied_geoids)\n",
    "    best_possible_top_pred_geoids = pd.Index.union(undisputed_top_predicted.index, top_pred_tied_geoids)\n",
    "\n",
    "    # True values of GEOIDS with highest actual deaths. If ties, finds tied locations that match preds best\n",
    "    best_possible_true = y_true[best_possible_top_true_geoids]\n",
    "    best_possible_pred = y_true[best_possible_top_pred_geoids]\n",
    "\n",
    "    assert (len(best_possible_true) == X)\n",
    "    assert (len(best_possible_pred) == X)\n",
    "\n",
    "    best_possible_absolute = np.abs(best_possible_true.sum() - best_possible_pred.sum())\n",
    "    best_possible_ratio = np.abs(best_possible_pred).sum() / np.abs(best_possible_true).sum()\n",
    "\n",
    "    bootstrapped_tied_indices = np.random.choice(tied_top_predicted.index, (1000, num_tied_spots))\n",
    "    bootstrapped_all_indices = [pd.Index.union(undisputed_top_predicted.index,\n",
    "                                               bootstrap_index) for bootstrap_index in bootstrapped_tied_indices]\n",
    "\n",
    "    bootstrapped_absolute = np.mean([np.abs(top_X_true.sum() - y_true[indices].sum())\n",
    "                                     for indices in bootstrapped_all_indices])\n",
    "    bootstrapped_ratio = np.mean([np.abs(y_true[indices]).sum() / np.abs(top_X_true).sum()\n",
    "                                  for indices in bootstrapped_all_indices])\n",
    "\n",
    "    return best_possible_absolute, best_possible_ratio, bootstrapped_absolute, bootstrapped_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b0e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time='qtr'\n",
    "data_dir='/cluster/tufts/hugheslab/datasets/NSF_OD/'\n",
    "inducing_points=3\n",
    "iterations=10\n",
    "out_dir='/cluster/home/kheuto01/test/'\n",
    "auto_kernel=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdead140",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = os.path.join(data_dir, 'results')\n",
    "mass_shapefile = os.path.join(data_dir, 'shapefiles', 'MA_2021')\n",
    "\n",
    "svi_file = os.path.join(result_dir, 'svi_month')\n",
    "svi_gdf = gpd.read_file(svi_file)\n",
    "# Call it \"grid_squar\" because geopandas only supports len 10 columns\n",
    "svi_gdf = svi_gdf.rename(columns={'INTPTLAT': 'lat', 'INTPTLON': 'lon', 'GEOID': 'grid_squar'})\n",
    "# Make lat and lon floats\n",
    "svi_gdf.loc[:, 'lat'] = svi_gdf.lat.astype(float)\n",
    "svi_gdf.loc[:, 'lon'] = svi_gdf.lon.astype(float)\n",
    "deaths_gdf = svi_gdf\n",
    "\n",
    "# Used when we just need the unique tracts and their locations\n",
    "just_grid = deaths_gdf.loc[\n",
    "    (deaths_gdf['year'] == 2000) & (deaths_gdf['month'] == 1), ['grid_squar', 'geometry', 'lat', 'lon']]\n",
    "\n",
    "# Calculate each squares neighbors\n",
    "neighbors = {}\n",
    "for _, row in just_grid.iterrows():\n",
    "    just_grid.loc[:, 'haversine'] = just_grid.apply(lambda x: haversine(row['lon'], row['lat'],\n",
    "                                                                        x['lon'], x['lat']),\n",
    "                                                    axis=1)\n",
    "    matching_neighbors = just_grid[just_grid['haversine'] < 8]['grid_squar'].values\n",
    "    neighbors[row['grid_squar']] = matching_neighbors\n",
    "\n",
    "tracts = deaths_gdf['grid_squar'].unique()\n",
    "min_year = deaths_gdf.year.min()\n",
    "max_year = deaths_gdf.year.max()\n",
    "deaths_gdf = deaths_gdf.set_index(['grid_squar', 'year', 'month']).sort_index()\n",
    "\n",
    "month_since_2000 = 0\n",
    "season_since_2000 = 0\n",
    "qtr_since_2000 = 0\n",
    "year_since_2000 = 0\n",
    "for year in range(min_year, max_year + 1):\n",
    "    for month in range(1, 12 + 1):\n",
    "\n",
    "        if month in [1, 2, 3, 4, 5, 6]:\n",
    "            season = 'jan-jun'\n",
    "        else:\n",
    "            season = 'jul-dec'\n",
    "\n",
    "        if month <= 3:\n",
    "            qtr = 1\n",
    "        elif month <= 6:\n",
    "            qtr = 2\n",
    "        elif month <= 9:\n",
    "            qtr = 3\n",
    "        else:\n",
    "            qtr = 4\n",
    "\n",
    "        deaths_gdf.loc[idx[:, year, month], 'month_since_2000'] = month_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'season'] = season\n",
    "        deaths_gdf.loc[idx[:, year, month], 'season_since_2000'] = season_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'qtr'] = qtr\n",
    "        deaths_gdf.loc[idx[:, year, month], 'qtr_since_2000'] = qtr_since_2000\n",
    "        deaths_gdf.loc[idx[:, year, month], 'year_since_2000'] = year_since_2000\n",
    "\n",
    "        month_since_2000 += 1\n",
    "\n",
    "        if month in [6, 12]:\n",
    "            season_since_2000 += 1\n",
    "\n",
    "        if month in [3, 6, 9, 12]:\n",
    "            qtr_since_2000 += 1\n",
    "\n",
    "        if month == 12:\n",
    "            year_since_2000 += 1\n",
    "\n",
    "deaths_gdf = deaths_gdf.reset_index()\n",
    "tracts = deaths_gdf['grid_squar'].unique()\n",
    "min_year = deaths_gdf.year.min()\n",
    "max_year = deaths_gdf.year.max()\n",
    "deaths_gdf = deaths_gdf.set_index(['grid_squar', 'year', 'month']).sort_index()\n",
    "deaths_gdf.loc[idx[:, :, :], 'last_timestep'] = deaths_gdf.loc[idx[:, :, :], 'deaths'].shift(1, )\n",
    "deaths_gdf.loc[idx[:, :, :], 'last_year'] = deaths_gdf.loc[idx[:, :, :], 'deaths'].shift(12)\n",
    "deaths_gdf.loc[idx[:, :, :], 'delta_deaths'] = deaths_gdf.loc[idx[:, :, :], 'deaths'] - deaths_gdf.loc[\n",
    "    idx[:, :, :], 'last_timestep']\n",
    "for tract in tracts:\n",
    "    deaths_gdf.loc[idx[tract, :, :], 'neighbors_last_timestep'] = \\\n",
    "        deaths_gdf.loc[idx[neighbors[tract], :, :], 'last_timestep'].groupby(level=['year', 'month']).mean().shift(\n",
    "            1).values\n",
    "    deaths_gdf.loc[idx[tract, :, :], 'neighbors_last_year'] = \\\n",
    "        deaths_gdf.loc[idx[neighbors[tract], :, :], 'last_year'].groupby(level=['year', 'month']).mean().shift(\n",
    "            12).values\n",
    "\n",
    "deaths_gdf = deaths_gdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ea4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_deaths = copy.deepcopy(deaths_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebecce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if time=='qtr':\n",
    "        timestep_col = 'qtr_since_2000'\n",
    "        deaths_gdf_meta = deaths_gdf.groupby(['grid_squar', 'year', timestep_col]).mean()[\n",
    "            ['theme_3_pc', 'lon', 'theme_2_pc', 'lat', 'svi_pctile', 'theme_1_pc', 'theme_4_pc']]\n",
    "        deaths_gdf = deaths_gdf.groupby(['grid_squar', 'year', timestep_col]).sum(min_count=3)[\n",
    "            ['deaths', 'delta_deaths', 'last_timestep', 'last_year', 'neighbors_last_timestep', 'neighbors_last_year']]\n",
    "\n",
    "        deaths_gdf = deaths_gdf.merge(deaths_gdf_meta, left_index=True, right_index=True)\n",
    "        deaths_gdf.loc[idx[:, :, :], 'last_timestep'] = deaths_gdf.loc[idx[:, :, :], 'deaths'].shift(1, )\n",
    "        deaths_gdf.loc[idx[:, :, :], 'last_year'] = deaths_gdf.loc[idx[:, :, :], 'deaths'].shift(2)\n",
    "        deaths_gdf.loc[idx[:, :, :], 'delta_deaths'] = deaths_gdf.loc[idx[:, :, :], 'deaths'] - \\\n",
    "                                                       deaths_gdf.loc[idx[:, :], 'last_timestep']\n",
    "        for tract in tracts:\n",
    "            deaths_gdf.loc[idx[tract, :, :], 'neighbors_last_timestep'] = \\\n",
    "                deaths_gdf.loc[idx[neighbors[tract], :, :], 'last_timestep'].groupby(\n",
    "                    level=[timestep_col, 'year']).mean().shift(1).values\n",
    "            deaths_gdf.loc[idx[tract, :, :], 'neighbors_last_year'] = \\\n",
    "                deaths_gdf.loc[idx[neighbors[tract], :, :], 'last_year'].groupby(\n",
    "                    level=[timestep_col, 'year']).mean().shift(4).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f25908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021f2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/gpflow/model.py:142: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/gpflow/session.py:74: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/gpflow/param.py:450: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/gpflow/transforms.py:153: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'timesteps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9f50eb6e6be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mpred_2019\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mpred_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_2019\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mmaes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_10s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_50s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_100s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'timesteps'"
     ]
    }
   ],
   "source": [
    "deaths_gdf_with_autoregressive = deaths_gdf.reset_index()\n",
    "if auto_kernel:\n",
    "    features = ['grid_squar', 'lat', 'lon', timestep_col, 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "     'svi_pctile', 'neighbors_last_timestep', 'last_timestep']\n",
    "    features_no_idx = ['lat', 'lon', timestep_col, 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "     'svi_pctile', 'neighbors_last_timestep', 'last_timestep']\n",
    "else:\n",
    "    features = ['grid_squar', 'lat', 'lon', timestep_col, 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "     'svi_pctile']\n",
    "    features_no_idx = ['lat', 'lon', timestep_col, 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "     'svi_pctile']\n",
    "    \n",
    "train_x_through_2018 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2018][features].dropna()\n",
    "train_y_through_2018 = deaths_gdf_with_autoregressive.loc[train_x_through_2018.index][\n",
    "    ['grid_squar', timestep_col, 'deaths']].dropna()\n",
    "train_x_through_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] <= 2019][\n",
    "    features].dropna()\n",
    "train_y_through_2019 = deaths_gdf_with_autoregressive.loc[train_x_through_2019.index][\n",
    "    ['grid_squar', timestep_col, 'deaths']].dropna()\n",
    "\n",
    "x_just_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2019][\n",
    "    features]\n",
    "y_just_2019 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2019][\n",
    "    ['grid_squar', timestep_col, 'deaths']]\n",
    "x_just_2020 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2020][\n",
    "    features]\n",
    "y_just_2020 = deaths_gdf_with_autoregressive[deaths_gdf_with_autoregressive['year'] == 2020][\n",
    "    ['grid_squar', timestep_col, 'deaths']]\n",
    "\n",
    "spatial_kernel = gpflow.kernels.RBF(2, active_dims=[0, 1])\n",
    "temporal_kernel = gpflow.kernels.RBF(1, active_dims=[2])\n",
    "demo_kernel = gpflow.kernels.RBF(5, active_dims=[3, 4, 5, 6, 7])\n",
    "\n",
    "if auto_kernel:\n",
    "    autoregressive_kernel = gpflow.kernels.RBF(2, active_dims=[8,9])\n",
    "    gaussian_kernel = spatial_kernel + temporal_kernel + demo_kernel + autoregressive_kernel\n",
    "else:\n",
    "    gaussian_kernel = spatial_kernel + temporal_kernel + demo_kernel\n",
    "\n",
    "f_kernel = copy.deepcopy(gaussian_kernel)\n",
    "g_kernel = copy.deepcopy(gaussian_kernel)\n",
    "likelihood = OnOffLikelihood()\n",
    "\n",
    "random = np.random.default_rng(seed=1)\n",
    "\n",
    "M = inducing_points\n",
    "\n",
    "N = len(train_x_through_2018)\n",
    "Z = random.choice(train_x_through_2018[\n",
    "                      features_no_idx].values, size=M, replace=False)\n",
    "\n",
    "Zf = copy.deepcopy(Z)\n",
    "Zg = copy.deepcopy(Z)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x_through_2018.loc[:,\n",
    "                                                    features_no_idx],\n",
    "                                                    train_y_through_2018.loc[:, 'deaths'].values.reshape(-1,\n",
    "                                                                                                         1))).repeat().shuffle(\n",
    "    N)\n",
    "\n",
    "m = OnOffSVGP(train_x_through_2018.loc[:, features_no_idx].values,\n",
    "              train_y_through_2018.loc[:, 'deaths'].values.reshape(-1, 1)\n",
    "              , kernf=f_kernel,\n",
    "              kerng=g_kernel\n",
    "              , likelihood=OnOffLikelihood()\n",
    "              , Zf=Zf,\n",
    "              Zg=Zg\n",
    "              )\n",
    "\n",
    "# fix the model noise term\n",
    "m.likelihood.variance = 0.01\n",
    "m.likelihood.variance.fixed = False\n",
    "\n",
    "m.optimize(maxiter=iterations)  # ,method= tf.train.AdamOptimizer(learning_rate = 0.01)\n",
    "\n",
    "pred_2019 = m.predict_onoffgp(x_just_2019.loc[:, features_no_idx].values)\n",
    "pred_2019 = pred_2019[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "115b4e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06427505],\n",
       "       [0.06427505],\n",
       "       [0.06427505],\n",
       "       ...,\n",
       "       [0.02553089],\n",
       "       [0.02553089],\n",
       "       [0.02553089]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee3dad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06427505],\n",
       "       [0.06796331],\n",
       "       [0.05975341],\n",
       "       ...,\n",
       "       [0.02710086],\n",
       "       [0.02543728],\n",
       "       [0.02553089]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_time_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db5894c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grid_squar\n",
       "25001010100    0.064275\n",
       "25001010100    0.064275\n",
       "25001010100    0.064275\n",
       "25001010100    0.064275\n",
       "25001010206    0.067963\n",
       "                 ...   \n",
       "25027761401    0.025437\n",
       "25027761402    0.025531\n",
       "25027761402    0.025531\n",
       "25027761402    0.025531\n",
       "25027761402    0.025531\n",
       "Length: 6480, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2019_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "537c26ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'file' (pos 2) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-aa21f18cbfe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavemodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'file' (pos 2) not found"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_timesteps = x_just_2019[timestep_col].unique()\n",
    "\n",
    "\n",
    "maes, top_10s, top_50s, top_100s = [], [], [], []\n",
    "for timestep in pred_timesteps:\n",
    "    single_time_pred = pred_2019[x_just_2019[timestep_col]==timestep]\n",
    "    single_pred_df = pd.Series(single_time_pred.squeeze(), index=x_just_2019[x_just_2019[timestep_col]==timestep].grid_squar)\n",
    "    single_time_true = y_just_2019[y_just_2019[timestep_col]==timestep]\n",
    "\n",
    "    maes.append(mean_absolute_error(single_time_true.deaths, single_time_pred))\n",
    "    top_10s.append(top_X(single_time_true.set_index('grid_squar')['deaths'], single_pred_df, 10))\n",
    "    top_50s.append(top_X(single_time_true.set_index('grid_squar')['deaths'], single_pred_df, 50))\n",
    "    top_100s.append(top_X(single_time_true.set_index('grid_squar')['deaths'], single_pred_df, 100))\n",
    "\n",
    "model_fname = os.path.join(out_dir, 'model.pkl')\n",
    "result_fname = os.path.join(out_dir, 'res.pkl')\n",
    "\n",
    "m.savemodel(model_fname)\n",
    "with open(result_fname, 'wb') as outfile:\n",
    "    pickle.dump((maes, top_10s, top_50s, top_100s), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "783feb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "370dcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x_through_2018.loc[:, ['lat','lon', 'qtr_since_2000', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile',]], \n",
    "                                                   train_y_through_2018.loc[:,'deaths'].values.reshape(-1,1))).repeat().shuffle(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b1d6bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x_through_2018.loc[:, ['lat','lon', 'season_since_2000', 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile', 'neighbors_last_timestep', 'last_timestep']], \n",
    "                                                   train_y_through_2018.loc[:,'deaths'].values.reshape(-1,1))).repeat().shuffle(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2dbc12dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grid_squar',\n",
       " 'lat',\n",
       " 'lon',\n",
       " 'qtr_since_2000',\n",
       " 'theme_1_pc',\n",
       " 'theme_2_pc',\n",
       " 'theme_3_pc',\n",
       " 'theme_4_pc',\n",
       " 'svi_pctile']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1582bd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_squar</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>qtr_since_2000</th>\n",
       "      <th>theme_1_pc</th>\n",
       "      <th>theme_2_pc</th>\n",
       "      <th>theme_3_pc</th>\n",
       "      <th>theme_4_pc</th>\n",
       "      <th>svi_pctile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>42.059829</td>\n",
       "      <td>-70.200407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.6872</td>\n",
       "      <td>0.6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>42.059829</td>\n",
       "      <td>-70.200407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.6872</td>\n",
       "      <td>0.6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>42.059829</td>\n",
       "      <td>-70.200407</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.6872</td>\n",
       "      <td>0.6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>42.059829</td>\n",
       "      <td>-70.200407</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.6872</td>\n",
       "      <td>0.6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>42.059829</td>\n",
       "      <td>-70.200407</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.6872</td>\n",
       "      <td>0.6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142543</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>42.531342</td>\n",
       "      <td>-71.592751</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142544</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>42.531342</td>\n",
       "      <td>-71.592751</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142545</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>42.531342</td>\n",
       "      <td>-71.592751</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142546</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>42.531342</td>\n",
       "      <td>-71.592751</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142547</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>42.531342</td>\n",
       "      <td>-71.592751</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123120 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_squar        lat        lon  qtr_since_2000  theme_1_pc  \\\n",
       "0       25001010100  42.059829 -70.200407             0.0      0.7270   \n",
       "1       25001010100  42.059829 -70.200407             1.0      0.7270   \n",
       "2       25001010100  42.059829 -70.200407             2.0      0.7270   \n",
       "3       25001010100  42.059829 -70.200407             3.0      0.7270   \n",
       "4       25001010100  42.059829 -70.200407             4.0      0.7270   \n",
       "...             ...        ...        ...             ...         ...   \n",
       "142543  25027761402  42.531342 -71.592751            71.0      0.1522   \n",
       "142544  25027761402  42.531342 -71.592751            72.0      0.1522   \n",
       "142545  25027761402  42.531342 -71.592751            73.0      0.1522   \n",
       "142546  25027761402  42.531342 -71.592751            74.0      0.1522   \n",
       "142547  25027761402  42.531342 -71.592751            75.0      0.1522   \n",
       "\n",
       "        theme_2_pc  theme_3_pc  theme_4_pc  svi_pctile  \n",
       "0           0.2972      0.5268      0.6872      0.6230  \n",
       "1           0.2972      0.5268      0.6872      0.6230  \n",
       "2           0.2972      0.5268      0.6872      0.6230  \n",
       "3           0.2972      0.5268      0.6872      0.6230  \n",
       "4           0.2972      0.5268      0.6872      0.6230  \n",
       "...            ...         ...         ...         ...  \n",
       "142543      0.2139      0.3928      0.1570      0.1229  \n",
       "142544      0.2139      0.3928      0.1570      0.1229  \n",
       "142545      0.2139      0.3928      0.1570      0.1229  \n",
       "142546      0.2139      0.3928      0.1570      0.1229  \n",
       "142547      0.2139      0.3928      0.1570      0.1229  \n",
       "\n",
       "[123120 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_through_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "898c984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_squar</th>\n",
       "      <th>qtr_since_2000</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25001010100</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142543</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142544</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142545</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142546</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142547</th>\n",
       "      <td>25027761402</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_squar  qtr_since_2000  deaths\n",
       "0       25001010100             0.0     NaN\n",
       "1       25001010100             1.0     NaN\n",
       "2       25001010100             2.0     NaN\n",
       "3       25001010100             3.0     NaN\n",
       "4       25001010100             4.0     NaN\n",
       "...             ...             ...     ...\n",
       "142543  25027761402            71.0     NaN\n",
       "142544  25027761402            72.0     NaN\n",
       "142545  25027761402            73.0     NaN\n",
       "142546  25027761402            74.0     NaN\n",
       "142547  25027761402            75.0     NaN\n",
       "\n",
       "[123120 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_gdf_with_autoregressive.loc[train_x_through_2018.index][\n",
    "    ['grid_squar', timestep_col, 'deaths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a61c5e4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got 42.0598291",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-080859cb34d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                                     features],\n\u001b[1;32m      3\u001b[0m                                                     train_y_through_2018.loc[:, 'deaths'].values.reshape(-1,\n\u001b[0;32m----> 4\u001b[0;31m                                                                                                          1))).repeat().shuffle(\n\u001b[0m\u001b[1;32m      5\u001b[0m     N)\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   1683\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m   2219\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m       \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m     \u001b[0mbatched_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mprepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mprepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"component_%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                          as_ref=False):\n\u001b[1;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[1;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 246\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    283\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    285\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    571\u001b[0m     raise TypeError(\n\u001b[1;32m    572\u001b[0m         \"Element type not supported in TensorProto: %s\" % numpy_dtype.name)\n\u001b[0;32m--> 573\u001b[0;31m   \u001b[0mappend_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36mtensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got 42.0598291"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x_through_2018.loc[:,\n",
    "                                                    features],\n",
    "                                                    train_y_through_2018.loc[:, 'deaths'].values.reshape(-1,\n",
    "                                                                                                         1))).repeat().shuffle(\n",
    "    N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd0130b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got 42.0598291",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-453b981f7aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                                     features].values,\n\u001b[1;32m      3\u001b[0m                                                     train_y_through_2018.loc[:, 'deaths'].values.reshape(-1,\n\u001b[0;32m----> 4\u001b[0;31m                                                                                                          1)))\n\u001b[0m",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   1683\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m   2219\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m       \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m     \u001b[0mbatched_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mprepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mprepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"component_%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                          as_ref=False):\n\u001b[1;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[1;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 246\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    283\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    285\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    571\u001b[0m     raise TypeError(\n\u001b[1;32m    572\u001b[0m         \"Element type not supported in TensorProto: %s\" % numpy_dtype.name)\n\u001b[0;32m--> 573\u001b[0;31m   \u001b[0mappend_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36mtensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/zigp_36/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got 42.0598291"
     ]
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices((train_x_through_2018.loc[:,\n",
    "                                                    features].values,\n",
    "                                                    train_y_through_2018.loc[:, 'deaths'].values.reshape(-1,\n",
    "                                                                                                         1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48cde297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         42.059829\n",
       "1         42.059829\n",
       "2         42.059829\n",
       "3         42.059829\n",
       "4         42.059829\n",
       "            ...    \n",
       "142543    42.531342\n",
       "142544    42.531342\n",
       "142545    42.531342\n",
       "142546    42.531342\n",
       "142547    42.531342\n",
       "Name: lat, Length: 123120, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_through_2018.loc[:,\n",
    "                                                    'lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a63f182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['25001010100', 42.0598291, -70.2004073, ..., 0.5268,\n",
       "        0.6872000000000001, 0.623],\n",
       "       ['25001010100', 42.0598291, -70.2004073, ..., 0.5268,\n",
       "        0.6872000000000001, 0.623],\n",
       "       ['25001010100', 42.0598291, -70.2004073, ..., 0.5268,\n",
       "        0.6872000000000001, 0.623],\n",
       "       ...,\n",
       "       ['25027761402', 42.5313417, -71.5927511, ..., 0.3928, 0.157,\n",
       "        0.1229],\n",
       "       ['25027761402', 42.5313417, -71.5927511, ..., 0.3928, 0.157,\n",
       "        0.1229],\n",
       "       ['25027761402', 42.5313417, -71.5927511, ..., 0.3928, 0.157,\n",
       "        0.1229]], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_through_2018.loc[:,\n",
    "                                                    features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b94df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
