{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3ab975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import geopandas as gpd\n",
    "from pandas import IndexSlice as idx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from tensorflow.python.data.ops.iterator_ops import OwnedIterator as DatasetOwnedIterator\n",
    "\n",
    "#from metrics import fixed_top_X\n",
    "#from model_runner import run_adam\n",
    "\n",
    "code_dir = '/cluster/home/kheuto01/code/zero-inflated-gp/'\n",
    "sys.path.append(code_dir)\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/perturbations/'\n",
    "sys.path.append(code_dir)\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/diff_bpr'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "from perturbations import perturbed\n",
    "from bpr import bpr_variable_k_no_ties\n",
    "\n",
    "from onoffgpf import OnOffSVGP, OnOffSVGPPoiMC, OnOffLikelihood,OnOffSVGPBatch\n",
    "gpflow.config.default_float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90cc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/cluster/tufts/hugheslab/datasets/NSF_OD/results_20220606_update/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447de0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_dir, 'clean_annual_tract')\n",
    "timestep_col = 'timestep'\n",
    "geography_col = 'geoid'\n",
    "outcome_col = 'deaths'\n",
    "last_train_year = 2018\n",
    "first_train_year = 2000\n",
    "test_years = 2\n",
    "use_auto = False\n",
    "use_svi = True\n",
    "seed=360\n",
    "inducing_points = 200\n",
    "learning_rate = 0.001\n",
    "minibatch_size = 100\n",
    "\n",
    "sigma = 0.05\n",
    "bpr_samples = 37\n",
    "noise='normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d42c7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx_cols = [geography_col, 'lat','lon', timestep_col,\n",
    "              'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "              'svi_pctile','year',\n",
    "              'neighbor_t', 'self_t-1']\n",
    "y_idx_cols = [geography_col, timestep_col, outcome_col]\n",
    "features_only = ['lat','lon', timestep_col,\n",
    "                 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "                 'svi_pctile',\n",
    "                 'neighbor_t', 'self_t-1']\n",
    "\n",
    "data_gdf = gpd.read_file(data_path)\n",
    "\n",
    "train_x = data_gdf[(data_gdf['year'] <= last_train_year) &\n",
    "                   (data_gdf['year'] >= first_train_year)][x_idx_cols]\n",
    "train_y = data_gdf[(data_gdf['year'] <= last_train_year) &\n",
    "                   (data_gdf['year'] >= first_train_year)][y_idx_cols]\n",
    "test_x = data_gdf[(data_gdf['year'] > last_train_year) &\n",
    "                  (data_gdf['year'] <= last_train_year+test_years)][x_idx_cols]\n",
    "test_y = data_gdf[(data_gdf['year'] > last_train_year) &\n",
    "                  (data_gdf['year'] <= last_train_year+test_years)][y_idx_cols]\n",
    "\n",
    "num_data = train_x.shape[0]\n",
    "num_latent = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "deb39dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 10\n",
    "first_train_eval_year = 2014\n",
    "last_train_eval_year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e1605f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiindexed_gdf = data_gdf.set_index(['geoid','year'])\n",
    "num_geoids = len(data_gdf['geoid'].unique())\n",
    "\n",
    "train_shape = (num_geoids, time_window, len(features_only))\n",
    "\n",
    "timestep_feature_idx = features_only.index('timestep')\n",
    "\n",
    "xs =[]\n",
    "ys = []\n",
    "\n",
    "for eval_year in range(first_train_eval_year, last_train_eval_year+1):\n",
    "    \n",
    "    train_x_df = multiindexed_gdf.loc[idx[:,eval_year-time_window:eval_year-1], features_only]\n",
    "    train_y_df = multiindexed_gdf.loc[idx[:,eval_year], 'deaths']\n",
    "    \n",
    "    train_x_vals = train_x_df.values.reshape(train_shape)\n",
    "    # make sure we did reshape right way\n",
    "    assert((train_x_vals[:,4,timestep_feature_idx]==train_x_vals[0,4,timestep_feature_idx]).all())\n",
    "    train_y_vals = train_y_df.values\n",
    "    \n",
    "    xs.append(train_x_vals)\n",
    "    ys.append(train_y_vals)\n",
    "    \n",
    "    \n",
    "x_BSTD = np.stack(xs,axis=0)\n",
    "y_BS = np.stack(ys)\n",
    "\n",
    "x_BSTD = tf.convert_to_tensor(x_BSTD, dtype=tf.float32)\n",
    "y_BS = tf.convert_to_tensor(y_BS, dtype=tf.float32)\n",
    "\n",
    "B, S, T, D = x_BSTD.shape\n",
    "\n",
    "assert(B==len( range(first_train_eval_year, last_train_eval_year+1)))\n",
    "assert(S==num_geoids)\n",
    "assert(T==time_window)\n",
    "assert(D==len(features_only))\n",
    "\n",
    "# Reshape the training data to flatten the dimensions\n",
    "x_BSF_flat = tf.reshape(x_BSTD, (B, S, T * D), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2434f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_idx(input_BD, **kwargs):\n",
    "    \n",
    "    _, idx_BD = tf.math.top_k(input_BD, **kwargs)\n",
    "    input_depth = input_BD.shape[-1]\n",
    "    one_hot_idx_BKD = tf.one_hot(idx_BD, input_depth)\n",
    "    #Sum over k dimension so we dont have to worry about sorting\n",
    "    k_hot_idx_BD = tf.reduce_sum(one_hot_idx_BKD, axis=-2)\n",
    "    \n",
    "    \n",
    "    return k_hot_idx_BD\n",
    "top_100_idx = partial(top_k_idx, k=100)\n",
    "perturbed_top_100 = perturbed(top_100_idx,\n",
    "                         num_samples=bpr_samples,\n",
    "                         sigma=sigma,\n",
    "                         noise=noise,\n",
    "                         batched=True)\n",
    "\n",
    "class PerturbedBPRModel(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            top_100_indicators = perturbed_top_100(y_pred)\n",
    "            true_top_100_val, true_top_100_idx = tf.math.top_k(y,k=100)\n",
    "            \n",
    "            denominator = tf.reduce_sum(true_top_100_val, axis=-1)\n",
    "            numerator = tf.reduce_sum(top_100_indicators*y, axis=-1)\n",
    "            \n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(numerator, denominator, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ab87a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow model\n",
    "linear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(T, input_shape=(S,T * D,), activation='relu',\n",
    "                          ),\n",
    "    tf.keras.layers.Dense(1, input_shape=(S,T ), activation=None,\n",
    "                          )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "dd87a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(S,T*D))\n",
    "outputs = tf.squeeze(linear_model(inputs),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3018b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PerturbedBPRModel(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3edb219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1cbdddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "def weird_loss(a,b):\n",
    "    return -a/b\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=weird_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7e5fd212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: -0.2243\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2085\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2019\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.1980\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.1990\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2011\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.1999\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.1990\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2037\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2072\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2126\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2146\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.2117\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2248\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2312\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2484\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.2612\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2644\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2707\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2761\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2720\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2746\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.2701\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2619\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2547\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2501\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2501\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2523\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.2524\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.2544\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2516\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2508\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2561\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2610\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2712\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2782\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2885\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2881\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2957\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3029\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3156\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3343\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3456\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3549\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3615\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3685\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3745\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3766\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3772\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3787\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3792\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3782\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3817\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3007\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2757\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2774\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2829\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2790\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2835\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2875\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2884\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2909\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2960\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2953\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.2998\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2999\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3012\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3038\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3046\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3103\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3102\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3097\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3112\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3127\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3144\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3147\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3160\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3159\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3150\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3149\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3139\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3136\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3112\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3125\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3109\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3119\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3117\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3089\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3087\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3070\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3078\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3072\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3073\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3067\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3049\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3043\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3047\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3046\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3039\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3043\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3042\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3012\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3045\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3016\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3035\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3040\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3029\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3040\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3058\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3021\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3045\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3041\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3044\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3062\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3069\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3091\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3099\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3108\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3125\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3146\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3159\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3178\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3190\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3189\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3201\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3204\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3218\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3206\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3233\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3228\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3224\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3216\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3209\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3178\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3184\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3191\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3211\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: -0.3203\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3216\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3192\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3210\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3207\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3222\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3231\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3233\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3239\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3239\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3236\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3249\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3257\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3258\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3250\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3264\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: -0.3232\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3254\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3244\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3230\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3258\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3241\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3248\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3247\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3269\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3242\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3251\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3264\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3249\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3222\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3242\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3241\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3241\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3253\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3259\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3244\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3243\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3249\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3237\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3254\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3222\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3212\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3212\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3214\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3185\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3196\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3181\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3190\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3188\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3199\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3179\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3174\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3188\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3180\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3183\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3167\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3177\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3188\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3181\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3189\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3195\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3188\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3174\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3182\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3177\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3184\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3176\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3197\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3172\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3167\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3168\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3187\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3195\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3177\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3200\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3195\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3199\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3210\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3211\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3212\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3208\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3212\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3206\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3216\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3215\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3201\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3205\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3209\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3217\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3218\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3209\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3222\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3232\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3213\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3212\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3210\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3218\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3199\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3201\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3198\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3194\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3208\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3214\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3215\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3213\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3213\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3208\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3228\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3230\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3224\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3228\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3222\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3233\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3220\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3221\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3225\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3230\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3231\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3218\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3236\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3244\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3239\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3238\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3246\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3259\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3260\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3253\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3265\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3278\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3285\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3286\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3281\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3280\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3300\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3297\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3294\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3308\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3302\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3314\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3314\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3321\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3322\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3323\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3323\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3331\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3329\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3342\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3351\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3355\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3368\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3363\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3370\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3376\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3380\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3377\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3395\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3385\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3394\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3406\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3392\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3403\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3400\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3400\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3401\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3410\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3414\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3415\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3403\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3410\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3410\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3412\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3406\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3400\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3400\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3414\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3402\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3421\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3412\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3425\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3430\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3420\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3424\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3417\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3428\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3416\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3427\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3421\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3412\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3419\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3428\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3429\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3428\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3428\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3438\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3428\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3424\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3426\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3433\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3435\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3433\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3430\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3453\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3438\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3448\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3438\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3440\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3443\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3433\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3427\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3441\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3436\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3437\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3423\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3427\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3419\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3437\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3431\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3445\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3428\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3434\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3424\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3433\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3435\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3425\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3421\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3431\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3410\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3438\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3445\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3451\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3434\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3450\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3446\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3467\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3452\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3467\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3461\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3459\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3471\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3456\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3463\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3470\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3459\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3458\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3480\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: -0.3472\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3492\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3486\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3499\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3482\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3498\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3496\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3500\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3487\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3510\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3491\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3496\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3474\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3490\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3482\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3486\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3475\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3486\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3484\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3477\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3466\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3492\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3479\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3469\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3468\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3476\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3482\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3484\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3475\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3472\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3474\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3463\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3466\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3471\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3466\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3459\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3462\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3467\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3452\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3456\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3465\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3463\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3444\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3467\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3458\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3454\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3447\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3456\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3452\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3458\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3448\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3458\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3439\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3441\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3431\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3434\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3438\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3440\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3429\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3437\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3422\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3444\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3422\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3440\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3432\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3441\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3437\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3432\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3431\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3448\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3435\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3433\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3445\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3435\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3430\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3435\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3441\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3429\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3432\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3439\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3426\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3439\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3448\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3425\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3436\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3430\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3434\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3434\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3434\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3431\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3424\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3430\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3436\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3414\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3419\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3412\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3404\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3425\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3413\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3433\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3415\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3414\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3432\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3431\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3421\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3441\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3429\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3429\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3435\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3436\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3445\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3434\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3448\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3442\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3446\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3471\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3467\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3456\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3468\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3455\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3465\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3462\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3460\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3458\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3445\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3457\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3451\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3462\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3431\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3451\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3441\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3451\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3447\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3437\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3435\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3425\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3430\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3424\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3431\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3432\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3427\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3428\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3437\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3423\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3414\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3429\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3439\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3446\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3423\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3427\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3427\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3415\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3427\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3426\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3421\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3423\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3431\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3426\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3425\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: -0.3424\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: -0.3420\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3442\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3428\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3427\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3430\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3429\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3443\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3441\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3440\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3421\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3443\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3448\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3434\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3422\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3432\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3440\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3441\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3433\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3439\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3434\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3443\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3431\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3448\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3425\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3428\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3441\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3421\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3438\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3426\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3417\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3416\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3425\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3431\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3440\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3409\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: -0.3430\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3428\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3429\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3431\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3430\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3431\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3441\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3445\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3451\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3453\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3437\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3455\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3451\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3468\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3453\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3447\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3459\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3474\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3482\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3470\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3464\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3473\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3468\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3471\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3473\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3479\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3470\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3459\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3455\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3472\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3445\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3481\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3469\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3467\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3479\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3471\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3473\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3467\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3461\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3472\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3462\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3462\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3466\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3452\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3465\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3457\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3454\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3466\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3467\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3449\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3470\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3465\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3476\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3463\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3473\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3482\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3475\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3478\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3468\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3471\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3456\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3467\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3458\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3463\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3467\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3455\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3465\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3462\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3459\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3464\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3456\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3459\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3446\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3457\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3463\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3457\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3467\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3455\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3466\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3455\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3471\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3459\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3451\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3454\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3458\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3465\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3462\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3458\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3468\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3464\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3480\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3473\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3472\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3470\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3471\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3463\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3463\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3476\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3490\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3466\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3469\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3484\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3475\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3481\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3477\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3503\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3483\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3492\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3491\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3485\n",
      "Epoch 689/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3480\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3474\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3478\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3475\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3483\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3473\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3450\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3465\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3463\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3474\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3446\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3449\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3455\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3461\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3456\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3451\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3467\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3452\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3458\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3443\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3458\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3457\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3463\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3459\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3453\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3458\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3454\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3461\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3448\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3466\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3455\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3458\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3455\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3464\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3465\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3451\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3480\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3463\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3467\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3459\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3455\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3459\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3456\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3461\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3451\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3452\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3450\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3455\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3455\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3449\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3455\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3444\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3444\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3456\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3440\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3455\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3448\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3443\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3453\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3450\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3447\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3455\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3464\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3444\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3446\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3434\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3431\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3434\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3419\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3423\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3416\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3425\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3420\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3399\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3396\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3400\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3399\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3393\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3389\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3381\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3379\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3377\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3369\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3351\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3354\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3355\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3357\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3331\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3345\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3331\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3322\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3313\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3311\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3306\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3318\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3302\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3313\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3303\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3289\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3300\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3293\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3290\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3295\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3286\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3289\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3303\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3299\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3293\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3293\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3294\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3275\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3291\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3281\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3282\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3299\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3289\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3288\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3293\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3291\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3283\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3295\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3273\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3281\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3276\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3277\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3277\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3265\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3257\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3253\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3257\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3250\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3250\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3257\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3253\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3240\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3241\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3245\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3247\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3240\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3236\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3237\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3231\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3241\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3241\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3236\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3223\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3221\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3227\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3217\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3219\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3224\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3217\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3214\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3216\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3211\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3213\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3199\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3190\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3181\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3202\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3192\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3185\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3178\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3184\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3180\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3184\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3189\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3184\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3167\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3178\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3181\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3183\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3185\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3176\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3169\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3168\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3160\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3160\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3172\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3166\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3161\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3143\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3159\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3158\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3149\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3151\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3138\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3120\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3131\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3139\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3134\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3131\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3132\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3123\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3134\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3140\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3133\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3150\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3146\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3167\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3152\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: -0.3167\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: -0.3149\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3162\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3178\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3169\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3179\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3174\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3175\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3176\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3191\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3188\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3184\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3200\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3198\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3198\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3195\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3199\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3193\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3182\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3182\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3172\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3167\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3161\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3157\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3136\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3140\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3135\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3137\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3128\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3111\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3095\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3096\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3103\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3076\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3076\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: -0.3069\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3066\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3053\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3066\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3056\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3051\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3049\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3041\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3063\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3058\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3038\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3048\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: -0.3052\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3049\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3034\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3052\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3047\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3035\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3041\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3046\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3039\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3038\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3044\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: -0.3041\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3049\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3058\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3047\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3041\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3036\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3038\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3035\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3020\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3013\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3009\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3009\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3002\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3002\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3007\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2999\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3014\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.2985\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.2989\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2990\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2993\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3008\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2987\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2994\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2997\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.2991\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3002\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.2989\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.2994\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3002\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2982\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.2987\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3008\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.2996\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3018\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3016\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: -0.3016\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3018\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3038\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: -0.3028\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3025\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3021\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3048\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3041\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: -0.3039\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3024\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3045\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: -0.3032\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: -0.3040\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3047\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: -0.3063\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3064\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: -0.3052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b6c08ea5130>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_BSF_flat, y_BS, epochs=1000, batch_size=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c0dda850",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_BSF_flat, training=True)  # Forward pass\n",
    "top_100_indicators = perturbed_top_100(y_pred)\n",
    "true_top_100_val, true_top_100_idx = tf.math.top_k(y_BS,k=100)\n",
    "\n",
    "denominator = tf.reduce_sum(true_top_100_val, axis=-1)\n",
    "numerator = tf.reduce_sum(top_100_indicators*y_pred, axis=-1)\n",
    "\n",
    "# Compute the loss value\n",
    "# (the loss function is configured in `compile()`)\n",
    "loss = model.compiled_loss(numerator, denominator, regularization_losses=model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43546f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([5243.3545, 5301.8384, 5358.162 , 5417.177 , 5473.1704],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ec60154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = partial(tf.math.top_k, k=100)\n",
    "perturbed_top_100 = perturbed(top_100,\n",
    "                         num_samples=bpr_samples,\n",
    "                         sigma=sigma,\n",
    "                         noise='normal',\n",
    "                         batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8f782f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_preds = tf.squeeze(model(tf.expand_dims(x_BSF_flat[0,:,:],axis=0)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "de62ecba",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Pack as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Pack] name: packed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[191], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperturbed_top_100\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_preds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/opioid-overdose-models/perturbations/perturbations.py:182\u001b[0m, in \u001b[0;36mperturbed.<locals>.wrapper\u001b[0;34m(input_tensor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreshape(g, original_input_shape)\n\u001b[1;32m    180\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m forward_output, grad\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:343\u001b[0m, in \u001b[0;36mBind.__call__\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:297\u001b[0m, in \u001b[0;36mcustom_gradient.<locals>.decorated\u001b[0;34m(wrapped, args, kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decorated function with custom gradient.\"\"\"\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_mode_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _graph_mode_decorator(wrapped, args, kwargs)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:543\u001b[0m, in \u001b[0;36m_eager_mode_decorator\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement custom gradient decorator for eager mode.\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tape_lib\u001b[38;5;241m.\u001b[39mVariableWatcher() \u001b[38;5;28;01mas\u001b[39;00m variable_watcher:\n\u001b[0;32m--> 543\u001b[0m   result, grad_fn \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m    545\u001b[0m     nest\u001b[38;5;241m.\u001b[39mflatten(args))\n\u001b[1;32m    546\u001b[0m flat_kwargs \u001b[38;5;241m=\u001b[39m composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m    547\u001b[0m     nest\u001b[38;5;241m.\u001b[39mflatten(kwargs))\n",
      "File \u001b[0;32m~/code/opioid-overdose-models/perturbations/perturbations.py:152\u001b[0m, in \u001b[0;36mperturbed.<locals>.wrapper.<locals>.forward\u001b[0;34m(input_tensor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m perturbed_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_input, perturbed_input_shape)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Either\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#   (Default case): [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk]\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# or\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m#   (Full-reduce case) [NB] -> [N, B]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m perturbed_output_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[0;32m--> 152\u001b[0m     [[num_samples], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_output\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    153\u001b[0m perturbed_output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_output, perturbed_output_shape)\n\u001b[1;32m    155\u001b[0m forward_output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(perturbed_output, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Pack as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Pack] name: packed"
     ]
    }
   ],
   "source": [
    "perturbed_top_100(sample_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8739663c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1620), dtype=float32, numpy=\n",
       "array([[ 0.08766611, -0.10226385,  0.05699642, ...,  0.5287748 ,\n",
       "         0.09916075,  0.12338884]], dtype=float32)>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da088f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 06:10:35.626976: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [30780,10]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-18 06:10:35.627359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [30780,10]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x.loc[:, features_only].values,\n",
    "                                                    train_y.loc[:, outcome_col].values.reshape(-1, 1))).repeat().shuffle(num_data)\n",
    "train_iter = iter(train_dataset.batch(minibatch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bd6bef6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbed_loss_on_batch(model, data_batch):\n",
    "    KL = model.build_prior_KL()\n",
    "    \n",
    "    X, Y = data_batch\n",
    "    \n",
    "    gfmean, gfvar, gfmeanu, _, _, _, _, _, _ = self.build_predict(X)\n",
    "\n",
    "    y_pred = gfmean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03080a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_perturbed_loss(model, compile=True):\n",
    "    \n",
    "    \n",
    "    training_loss = partial \n",
    "    \n",
    "    if isinstance(data, DatasetOwnedIterator):\n",
    "        if compile:\n",
    "            # lambda because: https://github.com/GPflow/GPflow/issues/1929\n",
    "            training_loss_lambda = lambda d: self.training_loss(d)\n",
    "            input_signature = [data.element_spec]\n",
    "            training_loss = tf.function(training_loss_lambda, input_signature=input_signature)\n",
    "\n",
    "        def closure() -> tf.Tensor:\n",
    "            assert isinstance(data, DatasetOwnedIterator)  # Hint for mypy.\n",
    "            batch = next(data)\n",
    "            return training_loss(batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "681c7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model.training_loss_closure(train_iter, compile=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24000984",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def optimization_step():\n",
    "    optimizer.minimize(training_loss, model.trainable_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65678d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logf = []\n",
    "for step in range(10000):\n",
    "    optimization_step()\n",
    "    if step % 10 == 0:\n",
    "        elbo = -training_loss().numpy()\n",
    "        logf.append(elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b776167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=908538.6419173388>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a738336",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} params.shape[0]: 10 should be equal to indices.shape[0]: 1 [Op:GatherV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperturbed_bpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/opioid-overdose-models/perturbations/perturbations.py:182\u001b[0m, in \u001b[0;36mperturbed.<locals>.wrapper\u001b[0;34m(input_tensor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreshape(g, original_input_shape)\n\u001b[1;32m    180\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m forward_output, grad\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:343\u001b[0m, in \u001b[0;36mBind.__call__\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:297\u001b[0m, in \u001b[0;36mcustom_gradient.<locals>.decorated\u001b[0;34m(wrapped, args, kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decorated function with custom gradient.\"\"\"\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_mode_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _graph_mode_decorator(wrapped, args, kwargs)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:543\u001b[0m, in \u001b[0;36m_eager_mode_decorator\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement custom gradient decorator for eager mode.\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tape_lib\u001b[38;5;241m.\u001b[39mVariableWatcher() \u001b[38;5;28;01mas\u001b[39;00m variable_watcher:\n\u001b[0;32m--> 543\u001b[0m   result, grad_fn \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m    545\u001b[0m     nest\u001b[38;5;241m.\u001b[39mflatten(args))\n\u001b[1;32m    546\u001b[0m flat_kwargs \u001b[38;5;241m=\u001b[39m composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m    547\u001b[0m     nest\u001b[38;5;241m.\u001b[39mflatten(kwargs))\n",
      "File \u001b[0;32m~/code/opioid-overdose-models/perturbations/perturbations.py:144\u001b[0m, in \u001b[0;36mperturbed.<locals>.wrapper.<locals>.forward\u001b[0;34m(input_tensor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m perturbed_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_input, flat_batch_dim_shape)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Calls user-defined function in a perturbation agnostic manner.\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m perturbed_output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\u001b[39;00m\n\u001b[1;32m    146\u001b[0m perturbed_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_input, perturbed_input_shape)\n",
      "Cell \u001b[0;32mIn[78], line 25\u001b[0m, in \u001b[0;36mbpr_variable_k_no_ties\u001b[0;34m(y_true, y_pred, k)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Numerator is sum of true values at the locations indicated by predictions\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Note: there could be ties here. We choose to ignore and deal with noise\u001b[39;00m\n\u001b[1;32m     24\u001b[0m batch_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1\u001b[39m, tf\u001b[38;5;241m.\u001b[39mrank(y_true)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m true_val_at_pred_top_k \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k_pred_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m numerator \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(true_val_at_pred_top_k, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m bpr_k_value \u001b[38;5;241m=\u001b[39m numerator \u001b[38;5;241m/\u001b[39m denominator\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} params.shape[0]: 10 should be equal to indices.shape[0]: 1 [Op:GatherV2]"
     ]
    }
   ],
   "source": [
    "perturbed_bpr(tf.expand_dims(tf.constant([.3, .2, .1, .5, .4]), axis=0), \n",
    "              tf.expand_dims(tf.constant([.3, .2, .1, .5, .4]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e94e7426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.array(range(1000),dtype=np.float32),-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2af29aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_variable_k_no_ties(y_true, y_pred, k=None):\n",
    "    \"\"\"Calculate BPR-k often not used due to loss functions expected to only take 2 arguments\n",
    "\n",
    "    Args:\n",
    "        y_true: True outcome\n",
    "        y_pred: predicted outcome\n",
    "        k (int): Threshold for BPR. Required, but defaults to None because partial re\n",
    "\n",
    "    Returns:\n",
    "        The BPR-k score\n",
    "\n",
    "    Note: This method DOES NOT handle ties, as it is meant to be used in a perturbed fashion\n",
    "    \"\"\"\n",
    "\n",
    "    _, top_k_pred_idx = tf.math.top_k(y_pred, k=k)\n",
    "    top_k_true_val, top_k_true_idx = tf.math.top_k(y_true, k=k)\n",
    "\n",
    "    # Denominator is actual top-k\n",
    "    # Impossible to have ties here, a tie wouldn't change the value\n",
    "    denominator = tf.reduce_sum(top_k_true_val, axis=-1)\n",
    "\n",
    "    # Numerator is sum of true values at the locations indicated by predictions\n",
    "    # Note: there could be ties here. We choose to ignore and deal with noise\n",
    "    batch_dims = min(1, tf.rank(y_true)-1)\n",
    "    true_val_at_pred_top_k = tf.gather(y_true, top_k_pred_idx, batch_dims=batch_dims, axis=-1)\n",
    "    numerator = tf.reduce_sum(true_val_at_pred_top_k, axis=-1)\n",
    "\n",
    "    bpr_k_value = numerator / denominator\n",
    "\n",
    "    return bpr_k_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "168c1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.expand_dims(tf.constant([[.3, .2, .1, .5, .4],[.3, .2, .1, .5, .4]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b6398d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m perturbed_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_input, flat_batch_dim_shape)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calls user-defined function in a perturbation agnostic manner.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m perturbed_output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m(perturbed_input, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\u001b[39;00m\n\u001b[1;32m     15\u001b[0m perturbed_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_input, perturbed_input_shape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'func' is not defined"
     ]
    }
   ],
   "source": [
    "  input_shape = tf.shape(input_tensor)  # [B, D1, ... Dk], k >= 1\n",
    "  perturbed_input_shape = tf.concat([[bpr_samples], input_shape], axis=0)\n",
    "\n",
    "  noises = sample_noise_with_gradients('normal', perturbed_input_shape)\n",
    "  additive_noise, noise_gradient = tuple(\n",
    "      [tf.cast(noise, dtype=input_tensor.dtype) for noise in noises])\n",
    "  perturbed_input = tf.expand_dims(input_tensor, 0) + sigma * additive_noise\n",
    "\n",
    "  # [N, B, D1, ..., Dk] -> [NB, D1, ..., Dk].\n",
    "  flat_batch_dim_shape = tf.concat([[-1], input_shape[1:]], axis=0)\n",
    "  perturbed_input = tf.reshape(perturbed_input, flat_batch_dim_shape)\n",
    "  # Calls user-defined function in a perturbation agnostic manner.\n",
    "  perturbed_output = func(perturbed_input, *args, **kwargs)\n",
    "  # [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\n",
    "  perturbed_input = tf.reshape(perturbed_input, perturbed_input_shape)\n",
    "  # Either\n",
    "  #   (Default case): [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk]\n",
    "  # or\n",
    "  #   (Full-reduce case) [NB] -> [N, B]\n",
    "  perturbed_output_shape = tf.concat(\n",
    "      [[num_samples], [-1], tf.shape(perturbed_output)[1:]], axis=0)\n",
    "  perturbed_output = tf.reshape(perturbed_output, perturbed_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6da447ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "_GUMBEL = 'gumbel'\n",
    "_NORMAL = 'normal'\n",
    "SUPPORTED_NOISES = (_GUMBEL, _NORMAL)\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "def sample_noise_with_gradients(\n",
    "    noise, shape):\n",
    "  \"\"\"Samples a noise tensor according to a distribution with its gradient.\n",
    "\n",
    "  Args:\n",
    "   noise: (str) a type of supported noise distribution.\n",
    "   shape: tf.Tensor<int>, the shape of the tensor to sample.\n",
    "\n",
    "  Returns:\n",
    "   A tuple Tensor<float>[shape], Tensor<float>[shape] that corresponds to the\n",
    "   sampled noise and the gradient of log the underlying probability\n",
    "   distribution function. For instance, for a gaussian noise (normal), the\n",
    "   gradient is equal to the noise itself.\n",
    "\n",
    "  Raises:\n",
    "   ValueError in case the requested noise distribution is not supported.\n",
    "   See perturbations.SUPPORTED_NOISES for the list of supported distributions.\n",
    "  \"\"\"\n",
    "  if noise not in SUPPORTED_NOISES:\n",
    "    raise ValueError('{} noise is not supported. Use one of [{}]'.format(\n",
    "        noise, SUPPORTED_NOISES))\n",
    "\n",
    "  if noise == _GUMBEL:\n",
    "    sampler = tfp.distributions.Gumbel(0.0, 1.0)\n",
    "    samples = sampler.sample(shape)\n",
    "    gradients = 1 - tf.math.exp(-samples)\n",
    "  elif noise == _NORMAL:\n",
    "    sampler = tfp.distributions.Normal(0.0, 1.0)\n",
    "    samples = sampler.sample(shape)\n",
    "    gradients = samples\n",
    "\n",
    "  return samples, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5957a97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([10,  2,  5], dtype=int32)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbed_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "41a71685",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} params.shape[0]: 100 should be equal to indices.shape[0]: 2 [Op:GatherV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperturbed_bpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/opioid-overdose-models/perturbations/perturbations.py:182\u001b[0m, in \u001b[0;36mperturbed.<locals>.wrapper\u001b[0;34m(input_tensor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreshape(g, original_input_shape)\n\u001b[1;32m    180\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m forward_output, grad\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:343\u001b[0m, in \u001b[0;36mBind.__call__\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:297\u001b[0m, in \u001b[0;36mcustom_gradient.<locals>.decorated\u001b[0;34m(wrapped, args, kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decorated function with custom gradient.\"\"\"\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_mode_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _graph_mode_decorator(wrapped, args, kwargs)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:543\u001b[0m, in \u001b[0;36m_eager_mode_decorator\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement custom gradient decorator for eager mode.\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tape_lib\u001b[38;5;241m.\u001b[39mVariableWatcher() \u001b[38;5;28;01mas\u001b[39;00m variable_watcher:\n\u001b[0;32m--> 543\u001b[0m   result, grad_fn \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m    545\u001b[0m     nest\u001b[38;5;241m.\u001b[39mflatten(args))\n\u001b[1;32m    546\u001b[0m flat_kwargs \u001b[38;5;241m=\u001b[39m composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m    547\u001b[0m     nest\u001b[38;5;241m.\u001b[39mflatten(kwargs))\n",
      "File \u001b[0;32m~/code/opioid-overdose-models/perturbations/perturbations.py:144\u001b[0m, in \u001b[0;36mperturbed.<locals>.wrapper.<locals>.forward\u001b[0;34m(input_tensor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m perturbed_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_input, flat_batch_dim_shape)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Calls user-defined function in a perturbation agnostic manner.\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m perturbed_output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\u001b[39;00m\n\u001b[1;32m    146\u001b[0m perturbed_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(perturbed_input, perturbed_input_shape)\n",
      "Cell \u001b[0;32mIn[78], line 25\u001b[0m, in \u001b[0;36mbpr_variable_k_no_ties\u001b[0;34m(y_true, y_pred, k)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Numerator is sum of true values at the locations indicated by predictions\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Note: there could be ties here. We choose to ignore and deal with noise\u001b[39;00m\n\u001b[1;32m     24\u001b[0m batch_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1\u001b[39m, tf\u001b[38;5;241m.\u001b[39mrank(y_true)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m true_val_at_pred_top_k \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k_pred_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m numerator \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(true_val_at_pred_top_k, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m bpr_k_value \u001b[38;5;241m=\u001b[39m numerator \u001b[38;5;241m/\u001b[39m denominator\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} params.shape[0]: 100 should be equal to indices.shape[0]: 2 [Op:GatherV2]"
     ]
    }
   ],
   "source": [
    "perturbed_bpr(perturbed_input,\n",
    "             tf.constant([[.3, .2, .1, .5, .4],[.3, .2, .1, .5, .4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9e5362a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 60 values, but the requested shape has 6 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Numerator is sum of true values at the locations indicated by predictions\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Note: there could be ties here. We choose to ignore and deal with noise\u001b[39;00m\n\u001b[1;32m     14\u001b[0m batch_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1\u001b[39m, tf\u001b[38;5;241m.\u001b[39mrank(y_true)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m true_val_at_pred_top_k \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k_pred_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m numerator \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(true_val_at_pred_top_k, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m bpr_k_value \u001b[38;5;241m=\u001b[39m numerator \u001b[38;5;241m/\u001b[39m denominator\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/miniconda3/envs/ptopk_tf_again/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 60 values, but the requested shape has 6 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "    #y_pred = tf.expand_dims(perturbed_input,axis=0)\n",
    "    y_pred = perturbed_input\n",
    "    y_true =  tf.expand_dims(tf.constant([[.3, .2, .1, .5, .4],[.3, .2, .1, .5, .4]]), axis=0)\n",
    "    \n",
    "    _, top_k_pred_idx = tf.math.top_k(y_pred, k=3)\n",
    "    top_k_true_val, top_k_true_idx = tf.math.top_k(y_true, k=3)\n",
    "\n",
    "    # Denominator is actual top-k\n",
    "    # Impossible to have ties here, a tie wouldn't change the value\n",
    "    denominator = tf.reduce_sum(top_k_true_val, axis=-1)\n",
    "\n",
    "    # Numerator is sum of true values at the locations indicated by predictions\n",
    "    # Note: there could be ties here. We choose to ignore and deal with noise\n",
    "    batch_dims = min(1, tf.rank(y_true)-1)\n",
    "    true_val_at_pred_top_k = tf.gather_nd(y_true, top_k_pred_idx, batch_dims=2,)\n",
    "    numerator = tf.reduce_sum(true_val_at_pred_top_k, axis=-1)\n",
    "\n",
    "    bpr_k_value = numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "83fb8e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 5])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b187e6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2, 5])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f4635d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "859576c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36d22d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[1.       , 1.       , 1.       , 0.9166666, 1.       , 1.       ,\n",
       "        1.       , 0.9166666, 1.       , 0.9166666]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6bd7c61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[1.       , 1.       , 1.       , 0.9166666, 1.       , 1.       ,\n",
       "        1.       , 0.9166666, 1.       , 0.9166666]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c1b3c13",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'geopandas' has no attribute 'IndexSlice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexSlice\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'geopandas' has no attribute 'IndexSlice'"
     ]
    }
   ],
   "source": [
    "gpd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bca2ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geoid        year\n",
       "25001010100  2004    0.0\n",
       "             2005    2.0\n",
       "             2006    0.0\n",
       "             2007    0.0\n",
       "             2008    0.0\n",
       "                    ... \n",
       "25027761402  2010    0.0\n",
       "             2011    0.0\n",
       "             2012    0.0\n",
       "             2013    0.0\n",
       "             2014    0.0\n",
       "Name: deaths, Length: 17820, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a496e5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.metrics.base_metric.Mean at 0x2b6ba01f0be0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988767d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
