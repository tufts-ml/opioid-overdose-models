{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a36e7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 20:37:19.456239: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-22 20:37:19.458320: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-22 20:37:19.508072: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-22 20:37:19.509143: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 20:37:22.239959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import sys\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import geopandas as gpd\n",
    "from pandas import IndexSlice as idx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from tensorflow.python.data.ops.iterator_ops import OwnedIterator as DatasetOwnedIterator\n",
    "\n",
    "#from metrics import fixed_top_X\n",
    "#from model_runner import run_adam\n",
    "\n",
    "code_dir = '/cluster/home/kheuto01/code/zero-inflated-gp/'\n",
    "sys.path.append(code_dir)\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/perturbations/'\n",
    "sys.path.append(code_dir)\n",
    "code_dir = '/cluster/home/kheuto01/code/opioid-overdose-models/diff_bpr'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "from perturbations import perturbed\n",
    "from bpr import bpr_variable_k_no_ties\n",
    "\n",
    "from onoffgpf import OnOffSVGP, OnOffSVGPPoiMC, OnOffLikelihood,OnOffSVGPBatch\n",
    "gpflow.config.default_float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fef3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/cluster/tufts/hugheslab/datasets/NSF_OD/results_20220606_update/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1b58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_dir, 'clean_annual_tract')\n",
    "timestep_col = 'timestep'\n",
    "geography_col = 'geoid'\n",
    "outcome_col = 'deaths'\n",
    "last_train_year = 2018\n",
    "first_train_year = 2000\n",
    "test_years = 2\n",
    "use_auto = False\n",
    "use_svi = True\n",
    "seed=360\n",
    "inducing_points = 200\n",
    "learning_rate = 0.001\n",
    "minibatch_size = 100\n",
    "\n",
    "sigma = 0.05\n",
    "bpr_samples = 37\n",
    "noise='normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020b00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx_cols = [geography_col, 'lat','lon', timestep_col,\n",
    "              'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "              'svi_pctile','year',\n",
    "              'neighbor_t', 'self_t-1']\n",
    "y_idx_cols = [geography_col, timestep_col, outcome_col]\n",
    "features_only = ['lat','lon', timestep_col,\n",
    "                 'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "                 'svi_pctile',\n",
    "                 'neighbor_t', 'self_t-1']\n",
    "\n",
    "data_gdf = gpd.read_file(data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d57c7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 10\n",
    "first_train_eval_year = 2014\n",
    "last_train_eval_year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13611353",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiindexed_gdf = data_gdf.set_index(['geoid','year'])\n",
    "num_geoids = len(data_gdf['geoid'].unique())\n",
    "\n",
    "train_shape = (num_geoids, time_window, len(['deaths']))\n",
    "\n",
    "xs =[]\n",
    "ys = []\n",
    "\n",
    "for eval_year in range(first_train_eval_year, last_train_eval_year+1):\n",
    "    \n",
    "    train_x_df = multiindexed_gdf.loc[idx[:,eval_year-time_window:eval_year-1], 'deaths']\n",
    "    train_y_df = multiindexed_gdf.loc[idx[:,eval_year], 'deaths']\n",
    "    \n",
    "    train_x_vals = train_x_df.values.reshape(train_shape)\n",
    "\n",
    "    train_y_vals = train_y_df.values\n",
    "    \n",
    "    xs.append(train_x_vals)\n",
    "    ys.append(train_y_vals)\n",
    "    \n",
    "    \n",
    "x_BSTD = np.stack(xs,axis=0)\n",
    "y_BS = np.stack(ys)\n",
    "\n",
    "x_BSTD = tf.convert_to_tensor(x_BSTD, dtype=tf.float32)\n",
    "y_BS = tf.convert_to_tensor(y_BS, dtype=tf.float32)\n",
    "\n",
    "B, S, T, D = x_BSTD.shape\n",
    "\n",
    "assert(B==len( range(first_train_eval_year, last_train_eval_year+1)))\n",
    "assert(S==num_geoids)\n",
    "assert(T==time_window)\n",
    "assert(D==1)\n",
    "\n",
    "# Reshape the training data to flatten the dimensions\n",
    "x_BSF_flat = tf.reshape(x_BSTD, (B, S, T * D), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49cf4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_year=2019\n",
    "test_x_df = multiindexed_gdf.loc[idx[:,test_year-time_window:test_year-1], 'deaths']\n",
    "test_y_df = multiindexed_gdf.loc[idx[:,test_year], 'deaths']\n",
    "\n",
    "test_x_vals = test_x_df.values.reshape(train_shape)\n",
    "\n",
    "test_y_vals = test_y_df.values\n",
    "\n",
    "test_x_BSTD = np.expand_dims(test_x_vals,axis=0)\n",
    "test_y_BS = np.expand_dims(test_y_vals,axis=0)\n",
    "\n",
    "test_x_BSTD = tf.convert_to_tensor(test_x_BSTD, dtype=tf.float32)\n",
    "test_y_BS = tf.convert_to_tensor(test_y_BS, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Reshape the training data to flatten the dimensions\n",
    "test_x_BSF_flat = tf.reshape(test_x_BSTD, (1, S, T * D), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2c5843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_idx(input_BD, **kwargs):\n",
    "    \n",
    "    _, idx_BD = tf.math.top_k(input_BD, **kwargs)\n",
    "    input_depth = input_BD.shape[-1]\n",
    "    one_hot_idx_BKD = tf.one_hot(idx_BD, input_depth)\n",
    "    #Sum over k dimension so we dont have to worry about sorting\n",
    "    k_hot_idx_BD = tf.reduce_sum(one_hot_idx_BKD, axis=-2)\n",
    "    \n",
    "    \n",
    "    return k_hot_idx_BD\n",
    "\n",
    "top_100_idx = partial(top_k_idx, k=100)\n",
    "perturbed_top_100 = perturbed(top_100_idx,\n",
    "                         num_samples=bpr_samples,\n",
    "                         sigma=sigma,\n",
    "                         noise=noise,\n",
    "                         batched=True)\n",
    "\n",
    "class PerturbedBPRModel(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            top_100_indicators = perturbed_top_100(y_pred)\n",
    "            true_top_100_val, true_top_100_idx = tf.math.top_k(y,k=100)\n",
    "            \n",
    "            denominator = tf.reduce_sum(true_top_100_val, axis=-1)\n",
    "            numerator = tf.reduce_sum(top_100_indicators*y, axis=-1)\n",
    "            \n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(numerator, denominator, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_pred = self(x, training=False)  # Forward pass\n",
    "        top_100_indicators = perturbed_top_100(y_pred)\n",
    "        true_top_100_val, true_top_100_idx = tf.math.top_k(y,k=100)\n",
    "\n",
    "        denominator = tf.reduce_sum(true_top_100_val, axis=-1)\n",
    "        numerator = tf.reduce_sum(top_100_indicators*y, axis=-1)\n",
    "\n",
    "        # Compute the loss value\n",
    "        # (the loss function is configured in `compile()`)\n",
    "        self.compiled_loss(numerator, denominator, regularization_losses=self.losses)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff11cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow model\n",
    "linear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(T, input_shape=(S,T * D,), activation='relu',\n",
    "                          ),\n",
    "    tf.keras.layers.Dense(1, input_shape=(S,T ), activation=None,\n",
    "                          )\n",
    "])\n",
    "\n",
    "# Functional api\n",
    "inputs = tf.keras.Input(shape=(S,T*D))\n",
    "outputs = tf.squeeze(linear_model(inputs),axis=-1)\n",
    "model = PerturbedBPRModel(inputs, outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "\n",
    "# Compile the model\n",
    "def weird_loss(a,b):\n",
    "    return -a/b\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=weird_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56121bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: -0.4041 - val_loss: -0.4605\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: -0.4042 - val_loss: -0.4619\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4044 - val_loss: -0.4631\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4054 - val_loss: -0.4622\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4063 - val_loss: -0.4640\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4081 - val_loss: -0.4665\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4092 - val_loss: -0.4663\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4099 - val_loss: -0.4679\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4112 - val_loss: -0.4686\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4114 - val_loss: -0.4705\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4129 - val_loss: -0.4686\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4125 - val_loss: -0.4703\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4129 - val_loss: -0.4697\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4113 - val_loss: -0.4692\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4087 - val_loss: -0.4691\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4088 - val_loss: -0.4678\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4066 - val_loss: -0.4701\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: -0.4083 - val_loss: -0.4711\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: -0.4065 - val_loss: -0.4700\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: -0.4066 - val_loss: -0.4709\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4064 - val_loss: -0.4705\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4087 - val_loss: -0.4722\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4073 - val_loss: -0.4725\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: -0.4088 - val_loss: -0.4724\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: -0.4062 - val_loss: -0.4738\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4077 - val_loss: -0.4721\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4062 - val_loss: -0.4749\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4080 - val_loss: -0.4755\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4088 - val_loss: -0.4761\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4095 - val_loss: -0.4779\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4105 - val_loss: -0.4770\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4108 - val_loss: -0.4771\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4110 - val_loss: -0.4773\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4115 - val_loss: -0.4775\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4122 - val_loss: -0.4802\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.4118 - val_loss: -0.4813\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4131 - val_loss: -0.4842\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4129 - val_loss: -0.4864\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4134 - val_loss: -0.4915\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4128 - val_loss: -0.4941\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4121 - val_loss: -0.4952\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4112 - val_loss: -0.4933\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4110 - val_loss: -0.4947\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.4089 - val_loss: -0.4950\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4098 - val_loss: -0.4987\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4088 - val_loss: -0.5001\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4106 - val_loss: -0.5046\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4088 - val_loss: -0.5046\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4080 - val_loss: -0.5094\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4064 - val_loss: -0.5098\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4024 - val_loss: -0.5083\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4031 - val_loss: -0.5095\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4023 - val_loss: -0.5099\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4023 - val_loss: -0.5085\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4038 - val_loss: -0.5077\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4025 - val_loss: -0.5092\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4027 - val_loss: -0.5074\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: -0.4014 - val_loss: -0.5076\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4003 - val_loss: -0.5106\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.4012 - val_loss: -0.5071\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4021 - val_loss: -0.5118\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.4032 - val_loss: -0.5111\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4035 - val_loss: -0.5098\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4023 - val_loss: -0.5113\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: -0.4039 - val_loss: -0.5079\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.4021 - val_loss: -0.5043\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: -0.4004 - val_loss: -0.4995\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.3996 - val_loss: -0.4953\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.3995 - val_loss: -0.4893\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.3984 - val_loss: -0.4894\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.3985 - val_loss: -0.4917\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.3986 - val_loss: -0.4905\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.3985 - val_loss: -0.4880\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.3980 - val_loss: -0.4895\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.3997 - val_loss: -0.4890\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.3996 - val_loss: -0.4895\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.3986 - val_loss: -0.4893\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.3990 - val_loss: -0.4879\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: -0.3991 - val_loss: -0.4899\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: -0.3996 - val_loss: -0.4904\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.4012 - val_loss: -0.4921\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4020 - val_loss: -0.4912\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4022 - val_loss: -0.4932\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.4023 - val_loss: -0.4935\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4024 - val_loss: -0.4943\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4024 - val_loss: -0.4997\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4030 - val_loss: -0.4982\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: -0.4037 - val_loss: -0.4986\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: -0.4047 - val_loss: -0.4977\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: -0.4051 - val_loss: -0.4987\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: -0.4071 - val_loss: -0.4980\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.4073 - val_loss: -0.4973\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.4083 - val_loss: -0.5006\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: -0.4077 - val_loss: -0.5035\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: -0.4087 - val_loss: -0.5047\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: -0.4077 - val_loss: -0.5049\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: -0.4071 - val_loss: -0.5035\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: -0.4066 - val_loss: -0.5008\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4067 - val_loss: -0.4992\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: -0.4049 - val_loss: -0.4988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b02b4c5eee0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_BSF_flat, y_BS, epochs=100, batch_size=5, validation_data=(test_x_BSF_flat, test_y_BS))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d350786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1620), dtype=float32, numpy=\n",
       "array([[-1.5925725, -1.7996557,       -inf, ...,       -inf,       -inf,\n",
       "              -inf],\n",
       "       [      -inf,       -inf,       -inf, ...,       -inf,       -inf,\n",
       "              -inf],\n",
       "       [      -inf,       -inf, -0.7904694, ...,       -inf,       -inf,\n",
       "              -inf],\n",
       "       [      -inf, -0.9780889,       -inf, ...,       -inf,       -inf,\n",
       "              -inf],\n",
       "       [      -inf,       -inf,       -inf, ...,       -inf,       -inf,\n",
       "        -0.5099018]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_loss(model(x_BSF_flat),y_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb20be1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: -0.4995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.4994802474975586"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x_BSF_flat, test_y_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36c78625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1620), dtype=float32, numpy=\n",
       "array([[ 0.02142696, -1.0956964 , -0.61507833, ..., -0.26376894,\n",
       "        -0.26376894, -0.26091912]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_x_BSF_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0234255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1620), dtype=float32, numpy=array([[1., 1., 0., ..., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f4a890f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1620), dtype=float32, numpy=\n",
       "array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 2., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a510846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
