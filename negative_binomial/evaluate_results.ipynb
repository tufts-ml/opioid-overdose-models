{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import IndexSlice as idx\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "\n",
    "def fast_bpr(true_val, pred_val, K=100, bootstrap_samples=1000):\n",
    "    \"\"\"\n",
    "\n",
    "    :param true_val: Pandas dataframe indexed on location\n",
    "    :param pred_val: Pandas dataframe indexed on location\n",
    "    :param K: Number of locations to consider\n",
    "    :param bootstrap_samples: Number of samples to take when evaluating ties\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    top_K_predicted = pred_val.sort_values(ascending=False).iloc[:K]\n",
    "    top_K_true = true_val.sort_values(ascending=False).iloc[:K]\n",
    "\n",
    "    # Now we check for ties\n",
    "    undisputed_top_predicted = top_K_predicted[top_K_predicted > top_K_predicted.min()]\n",
    "    num_tied_spots = K - len(undisputed_top_predicted)\n",
    "    undisputed_top_true = top_K_true[top_K_true > top_K_true.min()]\n",
    "    num_true_ties = K - len(undisputed_top_true)\n",
    "\n",
    "    tied_top_predicted = pred_val[pred_val == top_K_predicted.min()]\n",
    "    tied_top_true = true_val[true_val == top_K_true.min()]\n",
    "\n",
    "    # now randomly choose locations from the tied spots\n",
    "    bootstrapped_tied_indices = np.random.choice(tied_top_predicted.index, (bootstrap_samples, num_tied_spots))\n",
    "    undisputed_pred_idx = undisputed_top_predicted.index.values\n",
    "    bootstrapped_all_indices = [np.concatenate((undisputed_pred_idx, bootstrap_index))\n",
    "                                for bootstrap_index in bootstrapped_tied_indices]\n",
    "\n",
    "\n",
    "    denominator =  top_K_true.sum()\n",
    "    numerators = [true_val[indicies].sum() for indicies in bootstrapped_all_indices]\n",
    "\n",
    "    bootstrapped_ratio = np.mean([numerator / denominator\n",
    "                                  for numerator in numerators])\n",
    "\n",
    "    return bootstrapped_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"negative_binom_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>geoid</th>\n",
       "      <th>year</th>\n",
       "      <th>observed</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17031010100</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1.752481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17031010100</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1.364469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17031010100</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>1.797619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17031010100</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>2.094287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17031010100</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>2.406157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>6636</td>\n",
       "      <td>17031844700</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>1.989525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>6637</td>\n",
       "      <td>17031844700</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>2.759450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>6638</td>\n",
       "      <td>17031844700</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2.705266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>6639</td>\n",
       "      <td>17031844700</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>3.064403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639</th>\n",
       "      <td>6640</td>\n",
       "      <td>17031844700</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>3.240211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6640 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        geoid  year  observed  predicted\n",
       "0              1  17031010100  2018         0   1.752481\n",
       "1              2  17031010100  2019         2   1.364469\n",
       "2              3  17031010100  2020         3   1.797619\n",
       "3              4  17031010100  2021         4   2.094287\n",
       "4              5  17031010100  2022         4   2.406157\n",
       "...          ...          ...   ...       ...        ...\n",
       "6635        6636  17031844700  2018         6   1.989525\n",
       "6636        6637  17031844700  2019         3   2.759450\n",
       "6637        6638  17031844700  2020         5   2.705266\n",
       "6638        6639  17031844700  2021         4   3.064403\n",
       "6639        6640  17031844700  2022         1   3.240211\n",
       "\n",
       "[6640 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_locations=250\n",
    "bpr_uncertainty_samples=50\n",
    "seed=360\n",
    "num_locations = len(results['geoid'].unique())\n",
    "\n",
    "num_sampled = num_locations - removed_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "results_over_time = []\n",
    "true_deaths = []\n",
    "output_deaths=[]\n",
    "for year in range(2021, 2022+1):\n",
    "    evaluation_deaths = results[results['year'] == year]['observed']\n",
    "    predicted_deaths = results[results['year'] == year]['predicted']\n",
    "    true_deaths.append(evaluation_deaths)\n",
    "    output_deaths.append(predicted_deaths)\n",
    "\n",
    "    results_over_samples = []\n",
    "    for _ in range(bpr_uncertainty_samples):\n",
    "        sampled_indicies = rng.choice(range(num_locations), size=num_sampled, replace=False)\n",
    "        results_over_samples.append(fast_bpr(evaluation_deaths.iloc[sampled_indicies], predicted_deaths.iloc[sampled_indicies]))\n",
    "\n",
    "    results_over_time.append(results_over_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroes model (Mean, 95% CI): 79.9,\n",
      "      (78.1-\n",
      "       81.6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bpr_samples_both_years = (np.array(results_over_time[0]) + \\\n",
    "                          np.array(results_over_time[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Zeroes model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_results, mae_results = calculate_metrics(true_deaths, output_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Zeroes Model (Mean, 95% CI): 1.42, (1.37-1.48)\n",
      "MAE for Zeroes Model (Mean, 95% CI): 0.96, (0.93-0.98)\n"
     ]
    }
   ],
   "source": [
    "rmse_mean, rmse_conf_interval = rmse_results\n",
    "mae_mean, mae_conf_interval = mae_results\n",
    "\n",
    "print_results(\"RMSE for Zeroes Model\", rmse_mean, rmse_conf_interval)\n",
    "print_results(\"MAE for Zeroes Model\", mae_mean, mae_conf_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics(evaluation_deaths, predicted_deaths, \n",
    "                      num_locations_removed = 250, confidence_level=0.95, seed=360):\n",
    "        \"\"\"\n",
    "        @Return: joint RMSE and joint MAE alongside confidence interval\n",
    "        @param: evaluation_deaths pulled from multiindexed_gdf, not sampled yet\n",
    "        @param: predicted_deaths - corresponding model returns, already sampled\n",
    "        \"\"\"\n",
    "        rng = np.random.default_rng(seed=seed) \n",
    "        num_years = len(evaluation_deaths)\n",
    "        num_uncertainty_samples = len(predicted_deaths) // num_years\n",
    "\n",
    "\n",
    "        #make sure each element in evaluation_deaths is of same len, set num_locations to that len\n",
    "        lengths = [len(sub_list) for sub_list in evaluation_deaths]\n",
    "        if all(length == lengths[0] for length in lengths):\n",
    "             num_locations = lengths[0] #1328 for cook county, 1620 for MA\n",
    "        \n",
    "        num_sampled = num_locations - num_locations_removed \n",
    "\n",
    "        #initialize lists to store values \n",
    "        mae_over_samples = [] \n",
    "        rmse_over_samples = []\n",
    "\n",
    "        #calculate metrics for each year across diff. samples of predicted values and actual values\n",
    "        for i in range(num_years): \n",
    "\n",
    "            sampled_indices = rng.choice(range(num_locations), size=num_sampled, replace=False)\n",
    "            current_eval_deaths = evaluation_deaths[i].iloc[sampled_indices]\n",
    "            current_predicted_deaths = predicted_deaths[i].iloc[sampled_indices]\n",
    "\n",
    "            #for test time 1, go through first half of predicted_deaths\n",
    "            if i == 0: \n",
    "                for _ in range(num_uncertainty_samples):\n",
    "                    mae_over_samples.append(mean_absolute_error(current_eval_deaths, current_predicted_deaths))\n",
    "                    rmse_over_samples.append(sqrt(mean_squared_error(current_eval_deaths, current_predicted_deaths)))\n",
    "\n",
    "            #for test time 2, go through second half of predicted_deaths\n",
    "            else:\n",
    "                upper_bound = len(evaluation_deaths)*num_uncertainty_samples \n",
    "                for _ in range(num_uncertainty_samples, upper_bound):\n",
    "                    mae_over_samples.append(mean_absolute_error(current_eval_deaths, current_predicted_deaths))\n",
    "                    rmse_over_samples.append(sqrt(mean_squared_error(current_eval_deaths, current_predicted_deaths)))\n",
    "\n",
    "        #calculate mean and confidence interval (95%) based off joint rmse/mae vals\n",
    "        joint_rmse_mean = np.mean(rmse_over_samples)\n",
    "        joint_mae_mean = np.mean(mae_over_samples)\n",
    "   \n",
    "        #calculate mean and confidence interval (95%) based off joint rmse/mae vals\n",
    "        confidence_level = max(0, min(confidence_level, 1)) \n",
    "        \n",
    "        joint_rmse_lower = np.percentile(rmse_over_samples, (1 - confidence_level) * 100 / 2)\n",
    "        joint_rmse_upper = np.percentile(rmse_over_samples, 100 - (1 - confidence_level) * 100 / 2)\n",
    "\n",
    "        joint_mae_lower = np.percentile(mae_over_samples, (1 - confidence_level) * 100 / 2)\n",
    "        joint_mae_upper = np.percentile(mae_over_samples, 100 - (1 - confidence_level) * 100 / 2)\n",
    "\n",
    "        return (joint_rmse_mean, (joint_rmse_lower, joint_rmse_upper)), \\\n",
    "            (joint_mae_mean, (joint_mae_lower, joint_mae_upper))\n",
    "\n",
    "\n",
    "\n",
    "###HELPER function to print results\n",
    "def print_results(metric_name, mean_value, confidence_interval, confidence_level=0.95):\n",
    "    '''Prints results from calculate_metrics'''\n",
    "    print(f\"{metric_name} (Mean, {confidence_level*100:.0f}% CI): {mean_value:.2f}, \"\n",
    "          f\"({confidence_interval[0]:.2f}-{confidence_interval[1]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
