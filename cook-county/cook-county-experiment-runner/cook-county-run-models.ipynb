{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# local import\n",
    "from make_datasets import make_data\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "#retrieve cleaned data frames \n",
    "data_dir = '/Users/jyontika/Desktop/opioid-overdose-models/cook-county/cleaning-cook-county/'\n",
    "gdf_annual = pd.read_csv(f'{data_dir}/cook_county_gdf_year.csv')\n",
    "\n",
    "#convert to gpd (was having trouble importing csv as gdf)\n",
    "gdf_annual['geometry'] = gdf_annual['geometry'].apply(wkt.loads)\n",
    "gdf_annual = gpd.GeoDataFrame(gdf_annual, geometry='geometry')\n",
    "gdf_annual.crs = {'init': 'EPSG:4269'}\n",
    "type(gdf_annual)\n",
    "\n",
    "data_gdf = gdf_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process dataframe into a data frame with a Multiindex on location and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the important columns\n",
    "timestep_col = 'timestep'\n",
    "geography_col = 'geoid'\n",
    "outcome_col = 'deaths'\n",
    "\n",
    "# These are the columns we could possibly want in the X dataframe\n",
    "x_idx_cols = [geography_col, 'lat', 'lon', timestep_col,\n",
    "              'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "              'svi_pctile', 'year',\n",
    "              'neighbor_t', 'deaths']\n",
    "\n",
    "# These are the columns we could want in the Y dataframe\n",
    "y_idx_cols = [geography_col, timestep_col, outcome_col]\n",
    "\n",
    "# These are the features we want\n",
    "features_only = ['deaths']\n",
    "add_spacetime = True\n",
    "add_svi = True\n",
    "if add_spacetime:\n",
    "    features_only += ['lat', 'lon', timestep_col]\n",
    "if add_svi:\n",
    "    features_only += ['theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile']\n",
    "\n",
    "\n",
    "# #jyontika's parameters\n",
    "validation_year = 2020\n",
    "first_test_year = 2021\n",
    "last_test_year = 2022\n",
    "first_test_timestep = 6\n",
    "last_test_timestep = 7\n",
    "lookback_years= 3 #use 3 lookback years\n",
    "first_train_eval_year = validation_year - lookback_years #2017\n",
    "last_train_eval_year = validation_year -1 #2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multiindex\n",
    "multiindexed_gdf = data_gdf.set_index([geography_col, timestep_col])\n",
    "\n",
    "# re-add the timestep column as a feature because it's useful\n",
    "multiindexed_gdf[timestep_col] = multiindexed_gdf.index.get_level_values(timestep_col)\n",
    "\n",
    "# Track number of locations\n",
    "num_geoids = len(data_gdf[geography_col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lookback_years)\n",
    "print(num_geoids)\n",
    "print(len(features_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BSF, y_BS = make_data(multiindexed_gdf, first_train_eval_year, last_train_eval_year, lookback_years,\n",
    "          features_only, num_geoids)\n",
    "x_test_BSF, y_test_BS = make_data(multiindexed_gdf, first_test_year, last_test_year, lookback_years,\n",
    "          features_only, num_geoids)\n",
    "          \n",
    "# For the weighted historical average model, we only use deaths as features\n",
    "x_BSF_death_only, y_BS_death_only = make_data(multiindexed_gdf, first_train_eval_year, last_train_eval_year, lookback_years,\n",
    "          ['deaths'], num_geoids)\n",
    "x_test_BSF_death_only, y_test_BS_death_only =make_data(multiindexed_gdf, first_test_year, last_test_year, lookback_years,\n",
    "          ['deaths'], num_geoids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BSF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_BS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Zeroes Model\n",
    "### lookback = 3 (param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_zeroes = models.all_zeroes_model(multiindexed_gdf,\n",
    "                                        first_test_timestep, last_test_timestep,\n",
    "                                        num_geoids, bpr_uncertainty_samples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_zeroes[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_zeroes[0]) + \\\n",
    "                          np.array(bpr_over_time_zeroes[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Zeroes model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming multiindexed_gdf contains the actual target predictions with 'year' and 'deaths' columns\n",
    "actual_values_2021 = multiindexed_gdf[multiindexed_gdf['year'] == 2021]['deaths'].values\n",
    "actual_values_2022 = multiindexed_gdf[multiindexed_gdf['year'] == 2022]['deaths'].values\n",
    "\n",
    "# Calculate the model predictions \n",
    "bpr_samples_2021 = np.mean(bpr_over_time_zeroes[0])\n",
    "bpr_samples_2022 = np.mean(bpr_over_time_zeroes[1])\n",
    "\n",
    "# Calculate RMSE for model\n",
    "rmse_2021 = np.sqrt(np.mean((bpr_samples_2021 - actual_values_2021)**2))\n",
    "rmse_2022 = np.sqrt(np.mean((bpr_samples_2022 - actual_values_2022)**2))\n",
    "\n",
    "joint_rmse = np.mean([rmse_2021, rmse_2022])\n",
    "\n",
    "print(f\"Zeroes model RMSE for 2021: {rmse_2021:.2f}\")\n",
    "print(f\"Zeroes model RMSE for 2022: {rmse_2022:.2f}\")\n",
    "print(f\"Joint RMSE for 2021 and 2022: {joint_rmse:.2f}\")\n",
    "print(\" \")\n",
    "\n",
    "mae_2021_samples = np.mean(np.abs(bpr_samples_2021 - actual_values_2021))\n",
    "mae_2022_samples = np.mean(np.abs(bpr_samples_2022 - actual_values_2022))\n",
    "\n",
    "# Take the average MAE for each year\n",
    "mae_2021 = np.mean(mae_2021_samples)\n",
    "mae_2022 = np.mean(mae_2022_samples)\n",
    "\n",
    "# Calculate the joint MAE (mean of individual MAE values from both years)\n",
    "joint_mae = np.mean([mae_2021, mae_2022])\n",
    "\n",
    "print(f\"Zeroes model MAE for 2021: {mae_2021:.2f}\")\n",
    "print(f\"Zeroes model MAE for 2022: {mae_2022:.2f}\")\n",
    "print(f\"Joint MAE for 2021 and 2022: {joint_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Year\n",
    "#### lookback = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_last_time = models.last_time_model(multiindexed_gdf, first_test_timestep, last_test_timestep, num_geoids,\n",
    "                     1,bpr_uncertainty_samples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_last_time[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_last_time[0]) + \\\n",
    "                          np.array(bpr_over_time_last_time[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Last Year model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values_2021 = multiindexed_gdf[multiindexed_gdf['year'] == 2021]['deaths'].values\n",
    "actual_values_2022 = multiindexed_gdf[multiindexed_gdf['year'] == 2022]['deaths'].values\n",
    "\n",
    "# Calculate the model predictions \n",
    "bpr_samples_2021 = np.mean(bpr_over_time_last_time[0])\n",
    "bpr_samples_2022 = np.mean(bpr_over_time_last_time[1])\n",
    "\n",
    "# Calculate RMSE for model\n",
    "rmse_2021 = np.sqrt(np.mean((bpr_samples_2021 - actual_values_2021)**2))\n",
    "rmse_2022 = np.sqrt(np.mean((bpr_samples_2022 - actual_values_2022)**2))\n",
    "\n",
    "joint_rmse = np.mean([rmse_2021, rmse_2022])\n",
    "\n",
    "print(f\"Last Year model RMSE for 2021: {rmse_2021:.2f}\")\n",
    "print(f\"Last Year model RMSE for 2022: {rmse_2022:.2f}\")\n",
    "print(f\"Joint RMSE for 2021 and 2022: {joint_rmse:.2f}\")\n",
    "print(\" \")\n",
    "\n",
    "mae_2021_samples = np.mean(np.abs(bpr_samples_2021 - actual_values_2021))\n",
    "mae_2022_samples = np.mean(np.abs(bpr_samples_2022 - actual_values_2022))\n",
    "\n",
    "# Take the average MAE for each year\n",
    "mae_2021 = np.mean(mae_2021_samples)\n",
    "mae_2022 = np.mean(mae_2022_samples)\n",
    "\n",
    "# Calculate the joint MAE (mean of individual MAE values from both years)\n",
    "joint_mae = np.mean([mae_2021, mae_2022])\n",
    "\n",
    "print(f\"Last Year model model MAE for 2021: {mae_2021:.2f}\")\n",
    "print(f\"Last Year model MAE for 2022: {mae_2022:.2f}\")\n",
    "print(f\"Joint MAE for 2021 and 2022: {joint_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Average \n",
    "#### lookback = 6 years for cook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_avg_time = models.historical_average_model(multiindexed_gdf, first_test_timestep, last_test_timestep, num_geoids,\n",
    "                     1, 6, bpr_uncertainty_samples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_avg_time[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_avg_time[0]) + \\\n",
    "                          np.array(bpr_over_time_avg_time[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Historical Average model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values_2021 = multiindexed_gdf[multiindexed_gdf['year'] == 2021]['deaths'].values\n",
    "actual_values_2022 = multiindexed_gdf[multiindexed_gdf['year'] == 2022]['deaths'].values\n",
    "\n",
    "# Calculate the model predictions \n",
    "bpr_samples_2021 = np.mean(bpr_over_time_avg_time[0])\n",
    "bpr_samples_2022 = np.mean(bpr_over_time_avg_time[1])\n",
    "\n",
    "# Calculate RMSE for model\n",
    "rmse_2021 = np.sqrt(np.mean((bpr_samples_2021 - actual_values_2021)**2))\n",
    "rmse_2022 = np.sqrt(np.mean((bpr_samples_2022 - actual_values_2022)**2))\n",
    "\n",
    "joint_rmse = np.mean([rmse_2021, rmse_2022])\n",
    "\n",
    "print(f\"Historical Average RMSE for 2021: {rmse_2021:.2f}\")\n",
    "print(f\"Historical Average RMSE for 2022: {rmse_2022:.2f}\")\n",
    "print(f\"Joint RMSE for 2021 and 2022: {joint_rmse:.2f}\")\n",
    "print(\" \")\n",
    "\n",
    "mae_2021_samples = np.mean(np.abs(bpr_samples_2021 - actual_values_2021))\n",
    "mae_2022_samples = np.mean(np.abs(bpr_samples_2022 - actual_values_2022))\n",
    "\n",
    "# Take the average MAE for each year\n",
    "mae_2021 = np.mean(mae_2021_samples)\n",
    "mae_2022 = np.mean(mae_2022_samples)\n",
    "\n",
    "# Calculate the joint MAE (mean of individual MAE values from both years)\n",
    "joint_mae = np.mean([mae_2021, mae_2022])\n",
    "\n",
    "print(f\"Historical Average  MAE for 2021: {mae_2021:.2f}\")\n",
    "print(f\"Historical Average  MAE for 2022: {mae_2022:.2f}\")\n",
    "print(f\"Joint MAE for 2021 and 2022: {joint_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Historical Average\n",
    "#### lookback = 6 years (for cook county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical models, features are only difference\n",
    "linear_poisson_weighted_avg = sklearn.linear_model.PoissonRegressor()\n",
    "linear_poisson = sklearn.linear_model.PoissonRegressor()\n",
    "\n",
    "# Params selected via grid search on validation. Need to re-do grid search for chicago\n",
    "hist_poisson =   HistGradientBoostingRegressor(loss=\"poisson\", max_iter=10000, max_depth=3, max_leaf_nodes=2,\n",
    "                                               l2_regularization=1, min_samples_leaf=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_weight_avg = models.scikit_model(multiindexed_gdf, x_BSF_death_only,\n",
    "                                               y_BS_death_only, x_test_BSF_death_only,\n",
    "                                               linear_poisson_weighted_avg,\n",
    "                                               first_test_timestep, last_test_timestep,\n",
    "                                               bpr_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_weight_avg[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_weight_avg[0]) + \\\n",
    "                          np.array(bpr_over_time_weight_avg[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Zeroes model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values_2021 = multiindexed_gdf[multiindexed_gdf['year'] == 2021]['deaths'].values\n",
    "actual_values_2022 = multiindexed_gdf[multiindexed_gdf['year'] == 2022]['deaths'].values\n",
    "\n",
    "# Calculate the model predictions \n",
    "bpr_samples_2021 = np.mean(bpr_over_time_weight_avg[0])\n",
    "bpr_samples_2022 = np.mean(bpr_over_time_weight_avg[1])\n",
    "\n",
    "# Calculate RMSE for model\n",
    "rmse_2021 = np.sqrt(np.mean((bpr_samples_2021 - actual_values_2021)**2))\n",
    "rmse_2022 = np.sqrt(np.mean((bpr_samples_2022 - actual_values_2022)**2))\n",
    "\n",
    "joint_rmse = np.mean([rmse_2021, rmse_2022])\n",
    "\n",
    "print(f\"Weighted Historical Average RMSE for 2021: {rmse_2021:.2f}\")\n",
    "print(f\"Weighted Historical Average RMSE for 2022: {rmse_2022:.2f}\")\n",
    "print(f\"Joint RMSE for 2021 and 2022: {joint_rmse:.2f}\")\n",
    "print(\" \")\n",
    "\n",
    "mae_2021_samples = np.mean(np.abs(bpr_samples_2021 - actual_values_2021))\n",
    "mae_2022_samples = np.mean(np.abs(bpr_samples_2022 - actual_values_2022))\n",
    "\n",
    "# Take the average MAE for each year\n",
    "mae_2021 = np.mean(mae_2021_samples)\n",
    "mae_2022 = np.mean(mae_2022_samples)\n",
    "\n",
    "# Calculate the joint MAE (mean of individual MAE values from both years)\n",
    "joint_mae = np.mean([mae_2021, mae_2022])\n",
    "\n",
    "print(f\"Weighted Historical Average  MAE for 2021: {mae_2021:.2f}\")\n",
    "print(f\"Weighted Historical Average  MAE for 2022: {mae_2022:.2f}\")\n",
    "print(f\"Joint MAE for 2021 and 2022: {joint_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear (Poisson GLM baseline)\n",
    "#### lookback years = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_linear = models.scikit_model(multiindexed_gdf, x_BSF,\n",
    "                                               y_BS, x_test_BSF,\n",
    "                                               linear_poisson,\n",
    "                                               first_test_timestep, last_test_timestep,\n",
    "                                               bpr_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_linear[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_linear[0]) + \\\n",
    "                          np.array(bpr_over_time_linear[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Poisson GLM model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values_2021 = multiindexed_gdf[multiindexed_gdf['year'] == 2021]['deaths'].values\n",
    "actual_values_2022 = multiindexed_gdf[multiindexed_gdf['year'] == 2022]['deaths'].values\n",
    "\n",
    "# Calculate the model predictions \n",
    "bpr_samples_2021 = np.mean(bpr_over_time_linear[0])\n",
    "bpr_samples_2022 = np.mean(bpr_over_time_linear[1])\n",
    "\n",
    "# Calculate RMSE for model\n",
    "rmse_2021 = np.sqrt(np.mean((bpr_samples_2021 - actual_values_2021)**2))\n",
    "rmse_2022 = np.sqrt(np.mean((bpr_samples_2022 - actual_values_2022)**2))\n",
    "\n",
    "joint_rmse = np.mean([rmse_2021, rmse_2022])\n",
    "\n",
    "print(f\"Linear (Poisson GLM baseline) for 2021: {rmse_2021:.2f}\")\n",
    "print(f\"Linear (Poisson GLM baseline) RMSE for 2022: {rmse_2022:.2f}\")\n",
    "print(f\"Joint RMSE for 2021 and 2022: {joint_rmse:.2f}\")\n",
    "print(\" \")\n",
    "\n",
    "mae_2021_samples = np.mean(np.abs(bpr_samples_2021 - actual_values_2021))\n",
    "mae_2022_samples = np.mean(np.abs(bpr_samples_2022 - actual_values_2022))\n",
    "\n",
    "# Take the average MAE for each year\n",
    "mae_2021 = np.mean(mae_2021_samples)\n",
    "mae_2022 = np.mean(mae_2022_samples)\n",
    "\n",
    "# Calculate the joint MAE (mean of individual MAE values from both years)\n",
    "joint_mae = np.mean([mae_2021, mae_2022])\n",
    "\n",
    "print(f\"Linear (Poisson GLM baseline)  MAE for 2021: {mae_2021:.2f}\")\n",
    "print(f\"Linear (Poisson GLM baseline)  MAE for 2022: {mae_2022:.2f}\")\n",
    "print(f\"Joint MAE for 2021 and 2022: {joint_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees (Poisson)\n",
    "#### lookback years = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_tree = models.scikit_model(multiindexed_gdf, x_BSF,\n",
    "                                               y_BS, x_test_BSF,\n",
    "                                               hist_poisson,\n",
    "                                               first_test_timestep, last_test_timestep,\n",
    "                                               bpr_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_tree[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_tree[0]) + \\\n",
    "                          np.array(bpr_over_time_tree[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Gradient Boosted Trees (Poisson) (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values_2021 = multiindexed_gdf[multiindexed_gdf['year'] == 2021]['deaths'].values\n",
    "actual_values_2022 = multiindexed_gdf[multiindexed_gdf['year'] == 2022]['deaths'].values\n",
    "\n",
    "# Calculate the model predictions \n",
    "bpr_samples_2021 = np.mean(bpr_over_time_tree[0])\n",
    "bpr_samples_2022 = np.mean(bpr_over_time_tree[1])\n",
    "\n",
    "# Calculate RMSE for model\n",
    "rmse_2021 = np.sqrt(np.mean((bpr_samples_2021 - actual_values_2021)**2))\n",
    "rmse_2022 = np.sqrt(np.mean((bpr_samples_2022 - actual_values_2022)**2))\n",
    "\n",
    "joint_rmse = np.mean([rmse_2021, rmse_2022])\n",
    "\n",
    "print(f\"Gradient Boosted Trees (Poisson) RMSE for 2021: {rmse_2021:.2f}\")\n",
    "print(f\"Gradient Boosted Trees (Poisson) RMSE for 2022: {rmse_2022:.2f}\")\n",
    "print(f\"Joint RMSE for 2021 and 2022: {joint_rmse:.2f}\")\n",
    "print(\" \")\n",
    "\n",
    "mae_2021_samples = np.mean(np.abs(bpr_samples_2021 - actual_values_2021))\n",
    "mae_2022_samples = np.mean(np.abs(bpr_samples_2022 - actual_values_2022))\n",
    "\n",
    "# Take the average MAE for each year\n",
    "mae_2021 = np.mean(mae_2021_samples)\n",
    "mae_2022 = np.mean(mae_2022_samples)\n",
    "\n",
    "# Calculate the joint MAE (mean of individual MAE values from both years)\n",
    "joint_mae = np.mean([mae_2021, mae_2022])\n",
    "\n",
    "print(f\"Gradient Boosted Trees (Poisson)  MAE for 2021: {mae_2021:.2f}\")\n",
    "print(f\"Gradient Boosted Trees (Poisson)  MAE for 2022: {mae_2022:.2f}\")\n",
    "print(f\"Joint MAE for 2021 and 2022: {joint_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASTNet\n",
    "#### 3 lookback years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import CASTNet \n",
    "import sys\n",
    "my_data ='/Users/jyontika/Desktop/opioid-overdose-models/CASTNet/'\n",
    "CASTNet_path = os.path.join(my_data, 'hughes-CASTNet')\n",
    "sys.path.append(CASTNet_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hughes_castnet_main as CASTNet\n",
    "CASTNet.results['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = results['preds']\n",
    "prediction_matrix = np.array(all_predictions)\n",
    "prediction_matrix = np.maximum(prediction_matrix, 0) #turn all negative values to 0\n",
    "\n",
    "# Call the castnet_model function to calculate BPR for CASTNet predictions\n",
    "bpr_results_castnet = models.castnet_model(prediction_matrix, true_values, num_locations=1328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_results_castnet[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_results_castnet[0]) + \\\n",
    "                          np.array(bpr_results_castnet[1]))/2\n",
    "                        \n",
    "print(f\"\"\"CASTNet model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
