{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/jyontika/Desktop/Python/github_hughes/opioid-overdose-models/cook-county/cook-county-svi-data/'\n",
    "svi_2016_dir = os.path.join(data_dir,'cook-county-svi-2016.csv')\n",
    "svi_2018_dir = os.path.join(data_dir,'cook-county-svi-2018.csv')\n",
    "svi_2020_dir = os.path.join(data_dir,'cook-county-svi-2020.csv')\n",
    "\n",
    "svi_2016 = pd.read_csv(svi_2016_dir)\n",
    "svi_2018 = pd.read_csv(svi_2018_dir)\n",
    "svi_2020 = pd.read_csv(svi_2020_dir)\n",
    "\n",
    "%store -r gdf_annual\n",
    "%store -r gdf_semi\n",
    "%store -r gdf_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_annual = gdf_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in SVI to gdf_annual data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf_annual \n",
    "#initalize new columns with NAs\n",
    "\n",
    "gdf_annual = gdf_annual.assign(\n",
    "    RPL_THEME1 = float('nan'),\n",
    "    RPL_THEME2 = float('nan'),\n",
    "    RPL_THEME3 = float('nan'),\n",
    "    RPL_THEME4 = float('nan'),\n",
    "    RPL_THEMES = float('nan'))\n",
    "\n",
    "##should i match svi years with kyle, or change because i have different years?\n",
    "##2015, 2016 = svi_2016\n",
    "##2017, 2018 = svi_2018\n",
    "##2019, 2020, 2021, 2022 = svi_2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in svi_2016 to gdf_annual\n",
    "svi_2016['FIPS'] = svi_2016['FIPS'].astype(str)\n",
    "gdf_annual['GEOID'] = gdf_annual['GEOID'].str.strip()\n",
    "years_to_update = list(range(2015, 2017))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2015 <= year <= 2016\n",
    "for index, row in gdf_annual[gdf_annual['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2016[svi_2016['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_annual.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in svi_2018 to gdf_annual\n",
    "svi_2018['FIPS'] = svi_2018['FIPS'].astype(str)\n",
    "gdf_annual['GEOID'] = gdf_annual['GEOID'].str.strip()\n",
    "years_to_update = list(range(2017, 2019))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2017 <= year <= 2018\n",
    "for index, row in gdf_annual[gdf_annual['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2018[svi_2018['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_annual.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in svi_2020 to gdf_annual\n",
    "svi_2020['FIPS'] = svi_2020['FIPS'].astype(str)\n",
    "gdf_annual['GEOID'] = gdf_annual['GEOID'].str.strip()\n",
    "years_to_update = list(range(2019, 2023))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2019 <= year <= 2022\n",
    "for index, row in gdf_annual[gdf_annual['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2020[svi_2020['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_annual.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_annual.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping census tracts with zero population (lake)\n",
    "geoid_to_drop = ['17031990000', '17031381700', '17031980000', '17031980100']\n",
    "gdf_annual = gdf_annual[~gdf_annual['GEOID'].isin(geoid_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique GEOIDs with NA values: 44\n",
      "Unique GEOIDs with NA values:\n",
      "['17031320101' '17031320102' '17031330101' '17031330102' '17031330103'\n",
      " '17031380600' '17031460800' '17031490200' '17031612200' '17031630600'\n",
      " '17031803613' '17031803614' '17031803615' '17031803616' '17031804203'\n",
      " '17031804204' '17031804312' '17031804313' '17031804314' '17031804315'\n",
      " '17031804316' '17031804512' '17031804513' '17031804514' '17031806005'\n",
      " '17031806006' '17031809401' '17031809402' '17031820203' '17031820204'\n",
      " '17031824124' '17031824125' '17031824126' '17031824127' '17031824128'\n",
      " '17031824129' '17031824508' '17031824509' '17031828507' '17031828508'\n",
      " '17031829903' '17031829904' '17031844600' '17031844700']\n"
     ]
    }
   ],
   "source": [
    "# check for NA vals in each row and sum the number of NA values\n",
    "na_counts = gdf_annual.isna().sum(axis=1)\n",
    "\n",
    "# filter rows with NA values\n",
    "rows_with_na = gdf_annual[na_counts > 0]\n",
    "\n",
    "geoid_values_with_na = rows_with_na['GEOID'].unique()\n",
    "\n",
    "# Print the count and the unique list of GEOIDs with NA values\n",
    "print(f\"Number of unique GEOIDs with NA values: {len(geoid_values_with_na)}\")\n",
    "print(\"Unique GEOIDs with NA values:\")\n",
    "print(geoid_values_with_na)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate NAs for GEOIDs that are only missing *some* rows\n",
    "\n",
    "columns_to_fill = ['RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4', 'RPL_THEMES']\n",
    "\n",
    "for geoid_value in geoid_values_with_na:\n",
    "    rows_for_geoid = gdf_annual[gdf_annual['GEOID'] == geoid_value]\n",
    "    rows_with_values = rows_for_geoid.dropna(subset=columns_to_fill, how='any')\n",
    "    \n",
    "    if not rows_with_values.empty:\n",
    "        values_to_fill = rows_with_values.iloc[0][columns_to_fill].to_dict()\n",
    "    \n",
    "        gdf_annual.loc[gdf_annual['GEOID'] == geoid_value, columns_to_fill] = gdf_annual.loc[\n",
    "            gdf_annual['GEOID'] == geoid_value, columns_to_fill\n",
    "        ].fillna(values_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to match kyle\n",
    "\n",
    "gdf_annual.rename(columns={\n",
    "    'RPL_THEME1': 'theme_1_pc',\n",
    "    'RPL_THEME2': 'theme_2_pc',\n",
    "    'RPL_THEME3': 'theme_3_pc',\n",
    "    'RPL_THEME4': 'theme_4_pc',\n",
    "    'RPL_THEMES': 'svi_pctile'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOIDs with NAs:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#three GEOIDs have NAs \n",
    "# ['17031381700' '17031980000' '17031980100']\n",
    "\n",
    "gdf_annual = gdf_annual.replace(-999.0000, np.nan)\n",
    "\n",
    "geoids_with_nas = gdf_annual[gdf_annual.isna().any(axis=1)]['GEOID'].unique()\n",
    "print(\"GEOIDs with NAs:\")\n",
    "print(geoids_with_nas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in SVI to gdf_quarter data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf_quarter\n",
    "#initalize new columns with NAs\n",
    "\n",
    "gdf_quarter = gdf_quarter.assign(\n",
    "    RPL_THEME1 = float('nan'),\n",
    "    RPL_THEME2 = float('nan'),\n",
    "    RPL_THEME3 = float('nan'),\n",
    "    RPL_THEME4 = float('nan'),\n",
    "    RPL_THEMES = float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in svi_2016 to gdf_quarter\n",
    "svi_2016['FIPS'] = svi_2016['FIPS'].astype(str)\n",
    "gdf_quarter['GEOID'] = gdf_quarter['GEOID'].str.strip()\n",
    "years_to_update = list(range(2015, 2017))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2015 <= year <= 2016\n",
    "for index, row in gdf_quarter[gdf_quarter['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2016[svi_2016['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_quarter.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in svi_2018 to gdf_quarter\n",
    "svi_2018['FIPS'] = svi_2018['FIPS'].astype(str)\n",
    "gdf_quarter['GEOID'] = gdf_quarter['GEOID'].str.strip()\n",
    "years_to_update = list(range(2017, 2019))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2017 <= year <= 2018\n",
    "for index, row in gdf_quarter[gdf_quarter['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2018[svi_2018['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_quarter.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in svi_2020 to gdf_quarter\n",
    "svi_2020['FIPS'] = svi_2020['FIPS'].astype(str)\n",
    "gdf_quarter['GEOID'] = gdf_quarter['GEOID'].str.strip()\n",
    "years_to_update = list(range(2019, 2023))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2019 <= year <= 2022\n",
    "for index, row in gdf_quarter[gdf_quarter['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2020[svi_2020['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_quarter.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_quarter.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping census tracts with zero population (lake)\n",
    "gdf_quarter = gdf_quarter[~gdf_quarter['GEOID'].isin(geoid_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate NAs for GEOIDs that are only missing *some* rows\n",
    "na_counts = gdf_quarter.isna().sum(axis=1)\n",
    "rows_with_na = gdf_quarter[na_counts > 0]\n",
    "geoid_values_with_na = rows_with_na['GEOID'].unique()\n",
    "\n",
    "columns_to_fill = ['RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4', 'RPL_THEMES']\n",
    "\n",
    "for geoid_value in geoid_values_with_na:\n",
    "    rows_for_geoid = gdf_quarter[gdf_quarter['GEOID'] == geoid_value]\n",
    "    rows_with_values = rows_for_geoid.dropna(subset=columns_to_fill, how='any')\n",
    "    \n",
    "    if not rows_with_values.empty:\n",
    "        values_to_fill = rows_with_values.iloc[0][columns_to_fill].to_dict()\n",
    "    \n",
    "        gdf_quarter.loc[gdf_quarter['GEOID'] == geoid_value, columns_to_fill] = gdf_quarter.loc[\n",
    "            gdf_quarter['GEOID'] == geoid_value, columns_to_fill\n",
    "        ].fillna(values_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to match kyle\n",
    "\n",
    "gdf_quarter.rename(columns={\n",
    "    'RPL_THEME1': 'theme_1_pc',\n",
    "    'RPL_THEME2': 'theme_2_pc',\n",
    "    'RPL_THEME3': 'theme_3_pc',\n",
    "    'RPL_THEME4': 'theme_4_pc',\n",
    "    'RPL_THEMES': 'svi_pctile'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOIDs with NAs:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#three GEOIDs have NAs \n",
    "# ['17031381700' '17031980000' '17031980100']\n",
    "\n",
    "gdf_quarter = gdf_quarter.replace(-999.0000, np.nan)\n",
    "geoids_with_nas = gdf_quarter[gdf_quarter.isna().any(axis=1)]['GEOID'].unique()\n",
    "print(\"GEOIDs with NAs:\")\n",
    "print(geoids_with_nas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in SVI to gdf_semi data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf_semi\n",
    "#initalize new columns with NAs\n",
    "\n",
    "gdf_semi = gdf_semi.assign(\n",
    "    RPL_THEME1 = float('nan'),\n",
    "    RPL_THEME2 = float('nan'),\n",
    "    RPL_THEME3 = float('nan'),\n",
    "    RPL_THEME4 = float('nan'),\n",
    "    RPL_THEMES = float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m gdf_semi[gdf_semi[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(years_to_update)]\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      8\u001b[0m     geoid_value \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mGEOID\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m     matching_row \u001b[39m=\u001b[39m svi_2016[svi_2016[\u001b[39m'\u001b[39;49m\u001b[39mFIPS\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m geoid_value]\n\u001b[1;32m     11\u001b[0m     \u001b[39m# If a matching row is found, update the corresponding columns in gdf_annual\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m matching_row\u001b[39m.\u001b[39mempty:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6093\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   6095\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 6096\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6098\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    292\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/array_ops.py:82\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m     83\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#add in svi_2016 to gdf_semi\n",
    "svi_2016['FIPS'] = svi_2016['FIPS'].astype(str)\n",
    "gdf_semi['GEOID'] = gdf_semi['GEOID'].str.strip()\n",
    "years_to_update = list(range(2015, 2017))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2015 <= year <= 2016\n",
    "for index, row in gdf_semi[gdf_semi['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2016[svi_2016['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_semi.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in svi_2018 to gdf_semi\n",
    "svi_2018['FIPS'] = svi_2018['FIPS'].astype(str)\n",
    "gdf_semi['GEOID'] = gdf_semi['GEOID'].str.strip()\n",
    "years_to_update = list(range(2017, 2019))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2017 <= year <= 2018\n",
    "for index, row in gdf_semi[gdf_semi['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2018[svi_2018['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_semi.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in svi_2020 to gdf_semi\n",
    "svi_2020['FIPS'] = svi_2020['FIPS'].astype(str)\n",
    "gdf_semi['GEOID'] = gdf_semi['GEOID'].str.strip()\n",
    "years_to_update = list(range(2019, 2023))\n",
    "\n",
    "# Iterate over each row in gdf_annual where 2019 <= year <= 2022\n",
    "for index, row in gdf_semi[gdf_semi['year'].isin(years_to_update)].iterrows():\n",
    "    geoid_value = row['GEOID']\n",
    "    matching_row = svi_2020[svi_2020['FIPS'] == geoid_value]\n",
    "    \n",
    "    # If a matching row is found, update the corresponding columns in gdf_annual\n",
    "    if not matching_row.empty:\n",
    "        gdf_semi.loc[index, 'RPL_THEME1'] = matching_row['RPL_THEME1'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME2'] = matching_row['RPL_THEME2'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME3'] = matching_row['RPL_THEME3'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEME4'] = matching_row['RPL_THEME4'].values[0]\n",
    "        gdf_semi.loc[index, 'RPL_THEMES'] = matching_row['RPL_THEMES'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping census tracts with zero population (lake)\n",
    "gdf_semi = gdf_semi[~gdf_semi['GEOID'].isin(geoid_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate NAs for GEOIDs that are only missing *some* rows\n",
    "na_counts = gdf_semi.isna().sum(axis=1)\n",
    "rows_with_na = gdf_semi[na_counts > 0]\n",
    "geoid_values_with_na = rows_with_na['GEOID'].unique()\n",
    "\n",
    "columns_to_fill = ['RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4', 'RPL_THEMES']\n",
    "\n",
    "for geoid_value in geoid_values_with_na:\n",
    "    rows_for_geoid = gdf_semi[gdf_semi['GEOID'] == geoid_value]\n",
    "    rows_with_values = rows_for_geoid.dropna(subset=columns_to_fill, how='any')\n",
    "    \n",
    "    if not rows_with_values.empty:\n",
    "        values_to_fill = rows_with_values.iloc[0][columns_to_fill].to_dict()\n",
    "    \n",
    "        gdf_semi.loc[gdf_semi['GEOID'] == geoid_value, columns_to_fill] = gdf_semi.loc[\n",
    "            gdf_semi['GEOID'] == geoid_value, columns_to_fill\n",
    "        ].fillna(values_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to match kyle\n",
    "\n",
    "gdf_semi.rename(columns={\n",
    "    'RPL_THEME1': 'theme_1_pc',\n",
    "    'RPL_THEME2': 'theme_2_pc',\n",
    "    'RPL_THEME3': 'theme_3_pc',\n",
    "    'RPL_THEME4': 'theme_4_pc',\n",
    "    'RPL_THEMES': 'svi_pctile'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOIDs with NAs:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#three GEOIDs have NAs \n",
    "# ['17031381700' '17031980000' '17031980100']\n",
    "\n",
    "gdf_semi = gdf_semi.replace(-999.0000, np.nan)\n",
    "geoids_with_nas = gdf_semi[gdf_semi.isna().any(axis=1)]['GEOID'].unique()\n",
    "print(\"GEOIDs with NAs:\")\n",
    "print(geoids_with_nas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking NAs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NAs in each column:\n",
      "            gdf_annual  gdf_semi  gdf_quarter\n",
      "GEOID              0.0       0.0          0.0\n",
      "year               0.0       0.0          0.0\n",
      "deaths             0.0       0.0          0.0\n",
      "STATEFP            0.0       0.0          0.0\n",
      "COUNTYFP           0.0       0.0          0.0\n",
      "TRACTCE            0.0       0.0          0.0\n",
      "NAME               0.0       0.0          0.0\n",
      "NAMELSAD           0.0       0.0          0.0\n",
      "MTFCC              0.0       0.0          0.0\n",
      "FUNCSTAT           0.0       0.0          0.0\n",
      "ALAND              0.0       0.0          0.0\n",
      "AWATER             0.0       0.0          0.0\n",
      "lat                0.0       0.0          0.0\n",
      "lon                0.0       0.0          0.0\n",
      "geometry           0.0       0.0          0.0\n",
      "timestep           0.0       0.0          0.0\n",
      "theme_1_pc         0.0       0.0          0.0\n",
      "theme_2_pc         0.0       0.0          0.0\n",
      "theme_3_pc         0.0       0.0          0.0\n",
      "theme_4_pc         0.0       0.0          0.0\n",
      "svi_pctile         0.0       0.0          0.0\n",
      "semiannual         NaN       0.0          NaN\n",
      "season             NaN       0.0          NaN\n",
      "quarter            NaN       NaN          0.0\n",
      "\n",
      "Total number of NAs:\n",
      "gdf_annual: 0\n",
      "gdf_semi: 0\n",
      "gdf_quarter: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NAs in each DataFrame\n",
    "na_counts_annual = gdf_annual.isna().sum()\n",
    "na_counts_semi = gdf_semi.isna().sum()\n",
    "na_counts_quarter = gdf_quarter.isna().sum()\n",
    "\n",
    "# Concatenate the na_counts Series horizontally\n",
    "na_counts_combined = pd.concat([na_counts_annual, na_counts_semi, na_counts_quarter], axis=1)\n",
    "na_counts_combined.columns = ['gdf_annual', 'gdf_semi', 'gdf_quarter']\n",
    "\n",
    "# Total number of NAs in each DataFrame\n",
    "total_na_count_annual = gdf_annual.isna().sum().sum()\n",
    "total_na_count_semi = gdf_semi.isna().sum().sum()\n",
    "total_na_count_quarter = gdf_quarter.isna().sum().sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of NAs in each column:\")\n",
    "print(na_counts_combined)\n",
    "\n",
    "print(\"\\nTotal number of NAs:\")\n",
    "print(\"gdf_annual:\", total_na_count_annual)\n",
    "print(\"gdf_semi:\", total_na_count_semi)\n",
    "print(\"gdf_quarter:\", total_na_count_quarter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_annual = gdf_annual.rename(columns={'GEOID': 'geoid'})\n",
    "gdf_quarter = gdf_quarter.rename(columns={'GEOID': 'geoid'})\n",
    "gdf_semi = gdf_semi.rename(columns={'GEOID': 'geoid'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_annual_with_svi = gdf_annual \n",
    "gdf_quarter_with_svi = gdf_quarter\n",
    "gdf_semi_with_svi = gdf_semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'gdf_annual_with_svi' (GeoDataFrame)\n",
      "Stored 'gdf_quarter_with_svi' (DataFrame)\n",
      "Stored 'gdf_semi_with_svi' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store gdf_annual_with_svi\n",
    "%store gdf_quarter_with_svi\n",
    "%store gdf_semi_with_svi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdf_annual_with_svi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gdf_annual_with_svi\u001b[39m.\u001b[39mplot(\u001b[39m'\u001b[39m\u001b[39mdeaths\u001b[39m\u001b[39m'\u001b[39m, vmax\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdf_annual_with_svi' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
