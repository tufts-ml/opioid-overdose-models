{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m quarter_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, \u001b[39m'\u001b[39m\u001b[39mclean_quarter_tract\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m semi_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, \u001b[39m'\u001b[39m\u001b[39mclean_semi_tract\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m gdf_annual \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39;49mread_file(annual_path)\n\u001b[1;32m      8\u001b[0m gdf_quarter \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(quarter_path)\n\u001b[1;32m      9\u001b[0m gdf_semi \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(semi_path)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/io/file.py:281\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         path_or_bytes \u001b[39m=\u001b[39m filename\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_file_fiona(\n\u001b[1;32m    282\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[39m=\u001b[39;49mbbox, mask\u001b[39m=\u001b[39;49mmask, rows\u001b[39m=\u001b[39;49mrows, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown engine \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/io/file.py:379\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m    376\u001b[0m         [record[\u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m f_filt], columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    377\u001b[0m     )\n\u001b[1;32m    378\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     df \u001b[39m=\u001b[39m GeoDataFrame\u001b[39m.\u001b[39;49mfrom_features(\n\u001b[1;32m    380\u001b[0m         f_filt, crs\u001b[39m=\u001b[39;49mcrs, columns\u001b[39m=\u001b[39;49mcolumns \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39mgeometry\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    381\u001b[0m     )\n\u001b[1;32m    382\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m datetime_fields:\n\u001b[1;32m    383\u001b[0m     as_dt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[k], errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/geodataframe.py:638\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features_lst:\n\u001b[1;32m    636\u001b[0m     \u001b[39m# load geometry\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(feature, \u001b[39m\"\u001b[39m\u001b[39m__geo_interface__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 638\u001b[0m         feature \u001b[39m=\u001b[39m feature\u001b[39m.\u001b[39;49m__geo_interface__\n\u001b[1;32m    639\u001b[0m     row \u001b[39m=\u001b[39m {\n\u001b[1;32m    640\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m: shape(feature[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mif\u001b[39;00m feature[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    641\u001b[0m     }\n\u001b[1;32m    642\u001b[0m     \u001b[39m# load properties\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fiona/model.py:367\u001b[0m, in \u001b[0;36mFeature.__geo_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__geo_interface__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m ObjectEncoder()\u001b[39m.\u001b[39;49mdefault(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fiona/model.py:395\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    393\u001b[0m         o_dict[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault(o\u001b[39m.\u001b[39mgeometry)\n\u001b[1;32m    394\u001b[0m     \u001b[39mif\u001b[39;00m o\u001b[39m.\u001b[39mproperties \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m         o_dict[\u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefault(o\u001b[39m.\u001b[39;49mproperties)\n\u001b[1;32m    396\u001b[0m     \u001b[39mreturn\u001b[39;00m o_dict\n\u001b[1;32m    397\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mbytes\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fiona/model.py:388\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, (Geometry, Properties)):\n\u001b[0;32m--> 388\u001b[0m         \u001b[39mreturn\u001b[39;00m {k: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m o\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n\u001b[1;32m    389\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, Feature):\n\u001b[1;32m    390\u001b[0m         o_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(o)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fiona/model.py:388\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, (Geometry, Properties)):\n\u001b[0;32m--> 388\u001b[0m         \u001b[39mreturn\u001b[39;00m {k: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m o\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n\u001b[1;32m    389\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, Feature):\n\u001b[1;32m    390\u001b[0m         o_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(o)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/_collections_abc.py:852\u001b[0m, in \u001b[0;36mItemsView.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    851\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping:\n\u001b[0;32m--> 852\u001b[0m         \u001b[39myield\u001b[39;00m (key, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fiona/model.py:139\u001b[0m, in \u001b[0;36mObject.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[1;32m    138\u001b[0m     props \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_props()\n\u001b[0;32m--> 139\u001b[0m     props\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m props[item]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/jyontika/Desktop/Python/GitHub/opioid-overdose-models/jyontika-MA-data/data/'\n",
    "\n",
    "annual_path = os.path.join(data_dir, 'clean_annual_tract')\n",
    "quarter_path = os.path.join(data_dir, 'clean_quarter_tract')\n",
    "semi_path = os.path.join(data_dir, 'clean_semi_tract')\n",
    "\n",
    "gdf_annual = gpd.read_file(annual_path)\n",
    "gdf_quarter = gpd.read_file(quarter_path)\n",
    "gdf_semi = gpd.read_file(semi_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity Rate Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  Total Deaths Sparsity Rate\n",
      "0   2000         355.0       81.173%\n",
      "1   2001         445.0       77.531%\n",
      "2   2002         476.0       76.605%\n",
      "3   2003         596.0       71.975%\n",
      "4   2004         469.0       76.358%\n",
      "5   2005         547.0       74.259%\n",
      "6   2006         613.0       70.247%\n",
      "7   2007         599.0       71.358%\n",
      "8   2008         597.0       70.988%\n",
      "9   2009         595.0       71.975%\n",
      "10  2010         524.0       73.951%\n",
      "11  2011         621.0       70.123%\n",
      "12  2012         703.0       67.346%\n",
      "13  2013         897.0       61.667%\n",
      "14  2014        1247.0       52.346%\n",
      "15  2015        1575.0       46.605%\n",
      "16  2016        1896.0       39.383%\n",
      "17  2017        1711.0       42.963%\n",
      "18  2018        1895.0       40.432%\n",
      "19  2019        1862.0       40.185%\n",
      "20  2020        1953.0       39.815%\n",
      "21  2021        2064.0       39.383%\n"
     ]
    }
   ],
   "source": [
    "annual_deaths = gdf_annual.groupby('year')['deaths'].sum().reset_index()\n",
    "\n",
    "# Calculate sparsity rate\n",
    "zero_deaths_count = gdf_annual[gdf_annual['deaths'] == 0].groupby('year').size().reset_index(name='Zero Deaths Count')\n",
    "total_tracts_count = gdf_annual.groupby('year').size().reset_index(name='Total Tracts Count')\n",
    "sparsity_df_annual = pd.merge(zero_deaths_count, total_tracts_count, on='year')\n",
    "sparsity_df_annual['Sparsity Rate'] = (sparsity_df_annual['Zero Deaths Count'] / sparsity_df_annual['Total Tracts Count']) * 100\n",
    "sparsity_df_annual['Sparsity Rate'] = sparsity_df_annual['Sparsity Rate'].round(3).astype(str) + '%'\n",
    "\n",
    "# Merge sparsity rate with annual_deaths table\n",
    "annual_deaths = pd.merge(annual_deaths, sparsity_df_annual[['year', 'Sparsity Rate']], on='year')\n",
    "\n",
    "# Rename the 'deaths' column\n",
    "annual_deaths.rename(columns={'deaths': 'Total Deaths'}, inplace=True)\n",
    "\n",
    "# Exclude 2023 from the table\n",
    "annual_deaths = annual_deaths[annual_deaths['year'] != 2023]\n",
    "\n",
    "# Print the resulting table\n",
    "print(annual_deaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_semi['semiannual'] = pd.NA\n",
    "\n",
    "# Update 'semiannual' column based on 'season' values\n",
    "gdf_semi.loc[gdf_semi['season'] == 'jan-jun', 'semiannual'] = 1\n",
    "gdf_semi.loc[gdf_semi['season'] == 'jul-dec', 'semiannual'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year: 2000, Semiannual: 1, Total Deaths: 172.0, Sparsity Rate: 90.062%\n",
      "Year: 2000, Semiannual: 2, Total Deaths: 183.0, Sparsity Rate: 89.63%\n",
      "\n",
      "Year: 2001, Semiannual: 1, Total Deaths: 224.0, Sparsity Rate: 87.654%\n",
      "Year: 2001, Semiannual: 2, Total Deaths: 221.0, Sparsity Rate: 88.086%\n",
      "\n",
      "Year: 2002, Semiannual: 1, Total Deaths: 245.0, Sparsity Rate: 86.605%\n",
      "Year: 2002, Semiannual: 2, Total Deaths: 231.0, Sparsity Rate: 87.469%\n",
      "\n",
      "Year: 2003, Semiannual: 1, Total Deaths: 314.0, Sparsity Rate: 83.333%\n",
      "Year: 2003, Semiannual: 2, Total Deaths: 282.0, Sparsity Rate: 84.63%\n",
      "\n",
      "Year: 2004, Semiannual: 1, Total Deaths: 218.0, Sparsity Rate: 87.84%\n",
      "Year: 2004, Semiannual: 2, Total Deaths: 251.0, Sparsity Rate: 86.173%\n",
      "\n",
      "Year: 2005, Semiannual: 1, Total Deaths: 273.0, Sparsity Rate: 85.494%\n",
      "Year: 2005, Semiannual: 2, Total Deaths: 274.0, Sparsity Rate: 85.741%\n",
      "\n",
      "Year: 2006, Semiannual: 1, Total Deaths: 288.0, Sparsity Rate: 84.444%\n",
      "Year: 2006, Semiannual: 2, Total Deaths: 325.0, Sparsity Rate: 82.778%\n",
      "\n",
      "Year: 2007, Semiannual: 1, Total Deaths: 331.0, Sparsity Rate: 82.84%\n",
      "Year: 2007, Semiannual: 2, Total Deaths: 268.0, Sparsity Rate: 85.309%\n",
      "\n",
      "Year: 2008, Semiannual: 1, Total Deaths: 305.0, Sparsity Rate: 83.642%\n",
      "Year: 2008, Semiannual: 2, Total Deaths: 292.0, Sparsity Rate: 83.889%\n",
      "\n",
      "Year: 2009, Semiannual: 1, Total Deaths: 286.0, Sparsity Rate: 84.568%\n",
      "Year: 2009, Semiannual: 2, Total Deaths: 309.0, Sparsity Rate: 83.333%\n",
      "\n",
      "Year: 2010, Semiannual: 1, Total Deaths: 263.0, Sparsity Rate: 85.123%\n",
      "Year: 2010, Semiannual: 2, Total Deaths: 261.0, Sparsity Rate: 85.741%\n",
      "\n",
      "Year: 2011, Semiannual: 1, Total Deaths: 286.0, Sparsity Rate: 84.383%\n",
      "Year: 2011, Semiannual: 2, Total Deaths: 335.0, Sparsity Rate: 82.099%\n",
      "\n",
      "Year: 2012, Semiannual: 1, Total Deaths: 343.0, Sparsity Rate: 82.037%\n",
      "Year: 2012, Semiannual: 2, Total Deaths: 360.0, Sparsity Rate: 80.617%\n",
      "\n",
      "Year: 2013, Semiannual: 1, Total Deaths: 417.0, Sparsity Rate: 78.889%\n",
      "Year: 2013, Semiannual: 2, Total Deaths: 480.0, Sparsity Rate: 76.235%\n",
      "\n",
      "Year: 2014, Semiannual: 1, Total Deaths: 599.0, Sparsity Rate: 71.914%\n",
      "Year: 2014, Semiannual: 2, Total Deaths: 648.0, Sparsity Rate: 70.309%\n",
      "\n",
      "Year: 2015, Semiannual: 1, Total Deaths: 803.0, Sparsity Rate: 64.63%\n",
      "Year: 2015, Semiannual: 2, Total Deaths: 772.0, Sparsity Rate: 65.556%\n",
      "\n",
      "Year: 2016, Semiannual: 1, Total Deaths: 913.0, Sparsity Rate: 61.296%\n",
      "Year: 2016, Semiannual: 2, Total Deaths: 983.0, Sparsity Rate: 57.963%\n",
      "\n",
      "Year: 2017, Semiannual: 1, Total Deaths: 800.0, Sparsity Rate: 64.691%\n",
      "Year: 2017, Semiannual: 2, Total Deaths: 911.0, Sparsity Rate: 60.432%\n",
      "\n",
      "Year: 2018, Semiannual: 1, Total Deaths: 986.0, Sparsity Rate: 59.691%\n",
      "Year: 2018, Semiannual: 2, Total Deaths: 909.0, Sparsity Rate: 61.605%\n",
      "\n",
      "Year: 2019, Semiannual: 1, Total Deaths: 908.0, Sparsity Rate: 60.247%\n",
      "Year: 2019, Semiannual: 2, Total Deaths: 954.0, Sparsity Rate: 59.691%\n",
      "\n",
      "Year: 2020, Semiannual: 1, Total Deaths: 1006.0, Sparsity Rate: 58.272%\n",
      "Year: 2020, Semiannual: 2, Total Deaths: 947.0, Sparsity Rate: 61.111%\n",
      "\n",
      "Year: 2021, Semiannual: 1, Total Deaths: 1027.0, Sparsity Rate: 58.333%\n",
      "Year: 2021, Semiannual: 2, Total Deaths: 1037.0, Sparsity Rate: 58.519%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#semi-annual\n",
    "semiannual_deaths = gdf_semi.groupby(['year', 'semiannual'])['deaths'].sum().reset_index()\n",
    "\n",
    "# Calculate sparsity rate\n",
    "zero_deaths_count = gdf_semi[gdf_semi['deaths'] == 0].groupby(['year', 'semiannual']).size().reset_index(name='Zero Deaths Count')\n",
    "total_tracts_count = gdf_semi.groupby(['year', 'semiannual']).size().reset_index(name='Total Tracts Count')\n",
    "sparsity_df_semi = pd.merge(zero_deaths_count, total_tracts_count, on=['year', 'semiannual'])\n",
    "sparsity_df_semi['Sparsity Rate'] = (sparsity_df_semi['Zero Deaths Count'] / sparsity_df_semi['Total Tracts Count']) * 100\n",
    "sparsity_df_semi['Sparsity Rate'] = sparsity_df_semi['Sparsity Rate'].round(3).astype(str) + '%'\n",
    "\n",
    "# Merge sparsity rate with semiannual_deaths table\n",
    "semiannual_deaths = pd.merge(semiannual_deaths, sparsity_df_semi[['year', 'semiannual', 'Sparsity Rate']], on=['year', 'semiannual'])\n",
    "\n",
    "semiannual_deaths.rename(columns={'deaths': 'Total Deaths'}, inplace=True)\n",
    "\n",
    "#format\n",
    "formatted_table = ''\n",
    "current_year = None\n",
    "for _, row in semiannual_deaths.iterrows():\n",
    "    year = row['year']\n",
    "    semiannual = row['semiannual']\n",
    "    total_deaths = row['Total Deaths']\n",
    "    sparsity_rate = row['Sparsity Rate']\n",
    "    \n",
    "    if year != current_year:\n",
    "        formatted_table += '\\n'  # Add an extra space between years\n",
    "        current_year = year\n",
    "    \n",
    "    formatted_table += f\"Year: {year}, Semiannual: {semiannual}, Total Deaths: {total_deaths}, Sparsity Rate: {sparsity_rate}\\n\"\n",
    "\n",
    "# Print the resulting table\n",
    "print(formatted_table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number Tracts with 5+ Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Census Tracts with\n",
      "  5+ Deaths in Given Year\n",
      "\n",
      "    Year     # of Tracts\n",
      "0   2000               0\n",
      "1   2001               1\n",
      "2   2002               0\n",
      "3   2003               0\n",
      "4   2004               1\n",
      "5   2005               3\n",
      "6   2006               0\n",
      "7   2007               0\n",
      "8   2008               0\n",
      "9   2009               0\n",
      "10  2010               3\n",
      "11  2011               3\n",
      "12  2012               3\n",
      "13  2013               4\n",
      "14  2014              15\n",
      "15  2015              31\n",
      "16  2016              44\n",
      "17  2017              38\n",
      "18  2018              51\n",
      "19  2019              40\n",
      "20  2020              59\n",
      "21  2021              66\n"
     ]
    }
   ],
   "source": [
    "#number of census tracts with 5+ deaths in a year\n",
    "result = gdf_annual.groupby('year').apply(lambda x: (x['deaths'] >= 5).sum()).reset_index()\n",
    "\n",
    "result.columns = ['Year', '   # of Tracts']\n",
    "print(\"Number of Census Tracts with\\n  5+ Deaths in Given Year\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Census Tracts with 5+ Deaths in Given Semiannual Period\n",
      "\n",
      "    Year  Semiannual Period  # of Tracts\n",
      "0   2000                  1            0\n",
      "1   2000                  2            0\n",
      "2   2001                  1            0\n",
      "3   2001                  2            0\n",
      "4   2002                  1            0\n",
      "5   2002                  2            0\n",
      "6   2003                  1            0\n",
      "7   2003                  2            0\n",
      "8   2004                  1            0\n",
      "9   2004                  2            1\n",
      "10  2005                  1            0\n",
      "11  2005                  2            1\n",
      "12  2006                  1            0\n",
      "13  2006                  2            0\n",
      "14  2007                  1            0\n",
      "15  2007                  2            0\n",
      "16  2008                  1            0\n",
      "17  2008                  2            0\n",
      "18  2009                  1            0\n",
      "19  2009                  2            0\n",
      "20  2010                  1            1\n",
      "21  2010                  2            0\n",
      "22  2011                  1            0\n",
      "23  2011                  2            0\n",
      "24  2012                  1            0\n",
      "25  2012                  2            0\n",
      "26  2013                  1            0\n",
      "27  2013                  2            0\n",
      "28  2014                  1            1\n",
      "29  2014                  2            1\n",
      "30  2015                  1            2\n",
      "31  2015                  2            2\n",
      "32  2016                  1            3\n",
      "33  2016                  2            2\n",
      "34  2017                  1            2\n",
      "35  2017                  2            5\n",
      "36  2018                  1            5\n",
      "37  2018                  2            5\n",
      "38  2019                  1            1\n",
      "39  2019                  2            4\n",
      "40  2020                  1            8\n",
      "41  2020                  2            6\n",
      "42  2021                  1            5\n",
      "43  2021                  2            8\n"
     ]
    }
   ],
   "source": [
    "#semiannual 5+ tracts \n",
    "result = gdf_semi.groupby(['year', 'semiannual']).apply(lambda x: (x['deaths'] >= 5).sum()).reset_index()\n",
    "result.columns = ['Year', 'Semiannual Period', '# of Tracts']\n",
    "print(\"Number of Census Tracts with 5+ Deaths in Given Semiannual Period\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats Anual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0959104938271604\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#calculate mean from 2014-2021?\n",
    "filtered_df = gdf_annual[(gdf_annual['year'] >= 2014) & (gdf_annual['year'] <= 2021)]\n",
    "mean_deaths = filtered_df['deaths'].mean()\n",
    "median_deaths = filtered_df['deaths'].median()\n",
    "\n",
    "print(mean_deaths)\n",
    "print(median_deaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th Percentile: 0.0\n",
      "75th Percentile: 2.0\n"
     ]
    }
   ],
   "source": [
    "# percentiles\n",
    "percentile_25 = np.percentile(filtered_df['deaths'], 25)\n",
    "percentile_75 = np.percentile(filtered_df['deaths'], 75)\n",
    "\n",
    "print(\"25th Percentile:\", percentile_25)\n",
    "print(\"75th Percentile:\", percentile_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Number of Deaths: 10.0\n",
      "Minimum Number of Deaths: 0.0\n"
     ]
    }
   ],
   "source": [
    "#min and max\n",
    "max_deaths = filtered_df['deaths'].max()\n",
    "min_deaths = filtered_df['deaths'].min()\n",
    "\n",
    "print(\"Maximum Number of Deaths:\", max_deaths)\n",
    "print(\"Minimum Number of Deaths:\", min_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats Semi Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5479552469135802\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#summary stats semi-annual\n",
    "#mean and median\n",
    "gdf_semi_filtered = gdf_semi[gdf_semi['year'].between(2014, 2021)]\n",
    "mean_deaths = gdf_semi_filtered['deaths'].mean()\n",
    "median_deaths = gdf_semi_filtered['deaths'].median()\n",
    "\n",
    "print(mean_deaths)\n",
    "print(median_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th Percentile: 0.0\n",
      "75th Percentile: 1.0\n"
     ]
    }
   ],
   "source": [
    "# percentiles semiannual\n",
    "percentile_25 = np.percentile(gdf_semi_filtered['deaths'], 25)\n",
    "percentile_75 = np.percentile(gdf_semi_filtered['deaths'], 75)\n",
    "\n",
    "print(\"25th Percentile:\", percentile_25)\n",
    "print(\"75th Percentile:\", percentile_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Number of Deaths: 9.0\n",
      "Minimum Number of Deaths: 0.0\n"
     ]
    }
   ],
   "source": [
    "#maximum and min semi-annual\n",
    "max_deaths = gdf_semi_filtered['deaths'].max()\n",
    "min_deaths = gdf_semi_filtered['deaths'].min()\n",
    "\n",
    "print(\"Maximum Number of Deaths:\", max_deaths)\n",
    "print(\"Minimum Number of Deaths:\", min_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats Quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2739776234567901\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#summary stats QUARTERLY\n",
    "#mean and median\n",
    "gdf_quarter_filtered = gdf_quarter[gdf_quarter['year'].between(2014, 2021)]\n",
    "mean_deaths = gdf_quarter_filtered['deaths'].mean()\n",
    "median_deaths = gdf_quarter_filtered['deaths'].median()\n",
    "\n",
    "print(mean_deaths)\n",
    "print(median_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th Percentile: 0.0\n",
      "75th Percentile: 0.0\n"
     ]
    }
   ],
   "source": [
    "# percentiles quarterly\n",
    "percentile_25 = np.percentile(gdf_quarter_filtered['deaths'], 25)\n",
    "percentile_75 = np.percentile(gdf_quarter_filtered['deaths'], 75)\n",
    "\n",
    "print(\"25th Percentile:\", percentile_25)\n",
    "print(\"75th Percentile:\", percentile_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Number of Deaths: 9.0\n",
      "Minimum Number of Deaths: 0.0\n"
     ]
    }
   ],
   "source": [
    "#maximum and min quarterly\n",
    "max_deaths = gdf_quarter_filtered['deaths'].max()\n",
    "min_deaths = gdf_quarter_filtered['deaths'].min()\n",
    "\n",
    "print(\"Maximum Number of Deaths:\", max_deaths)\n",
    "print(\"Minimum Number of Deaths:\", min_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.plot('deaths',vmax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
