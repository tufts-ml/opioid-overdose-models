{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 14:46:30.540121: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# local import\n",
    "from make_datasets import make_data\n",
    "import models\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyontika/Library/Python/3.9/lib/python/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "from shapely import wkt\n",
    "#retrieve cleaned data frames \n",
    "data_dir = '/Users/jyontika/Desktop/opioid-overdose-models/cook-county/cleaning-cook-county/'\n",
    "gdf_annual = pd.read_csv(f'{data_dir}/cook_county_gdf_year.csv')\n",
    "\n",
    "#convert to gpd (was having trouble importing csv as gdf)\n",
    "gdf_annual['geometry'] = gdf_annual['geometry'].apply(wkt.loads)\n",
    "gdf_annual = gpd.GeoDataFrame(gdf_annual, geometry='geometry')\n",
    "gdf_annual.crs = {'init': 'EPSG:4269'}\n",
    "type(gdf_annual)\n",
    "\n",
    "data_gdf = gdf_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_annual['geoid'] = gdf_annual['geoid'].astype(str) #change to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process dataframe into a data frame with a Multiindex on location and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10624, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the important columns\n",
    "timestep_col = 'timestep'\n",
    "geography_col = 'geoid'\n",
    "outcome_col = 'deaths'\n",
    "\n",
    "# These are the columns we could possibly want in the X dataframe\n",
    "x_idx_cols = [geography_col, 'lat', 'lon', timestep_col,\n",
    "              'theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc',\n",
    "              'svi_pctile', 'year',\n",
    "              'neighbor_t', 'deaths']\n",
    "\n",
    "# These are the columns we could want in the Y dataframe\n",
    "y_idx_cols = [geography_col, timestep_col, outcome_col]\n",
    "\n",
    "# These are the features we want\n",
    "features_only = ['deaths']\n",
    "add_spacetime = True\n",
    "add_svi = True\n",
    "if add_spacetime:\n",
    "    features_only += ['lat', 'lon', timestep_col]\n",
    "if add_svi:\n",
    "    features_only += ['theme_1_pc', 'theme_2_pc', 'theme_3_pc', 'theme_4_pc', 'svi_pctile']\n",
    "\n",
    "\n",
    "# #jyontika's parameters\n",
    "validation_year = 2020\n",
    "first_test_year = 2021\n",
    "last_test_year = 2022\n",
    "first_test_timestep = 7\n",
    "last_test_timestep = 8\n",
    "lookback_years= 2 #use 2 lookback years\n",
    "first_train_eval_year = validation_year - lookback_years #2018\n",
    "last_train_eval_year = validation_year -1 #2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multiindex\n",
    "multiindexed_gdf = data_gdf.set_index([geography_col, timestep_col])\n",
    "\n",
    "# re-add the timestep column as a feature because it's useful\n",
    "multiindexed_gdf[timestep_col] = multiindexed_gdf.index.get_level_values(timestep_col)\n",
    "\n",
    "# Track number of locations\n",
    "num_geoids = len(data_gdf[geography_col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1328\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(lookback_years)\n",
    "print(num_geoids)\n",
    "print(len(features_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10624, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiindexed_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BSF, y_BS = make_data(multiindexed_gdf, first_train_eval_year, last_train_eval_year, lookback_years,\n",
    "          features_only, num_geoids)\n",
    "x_test_BSF, y_test_BS = make_data(multiindexed_gdf, first_test_year, last_test_year, lookback_years,\n",
    "          features_only, num_geoids)\n",
    "          \n",
    "# For the weighted historical average model, we only use deaths as features\n",
    "x_BSF_death_only, y_BS_death_only = make_data(multiindexed_gdf, first_train_eval_year, last_train_eval_year, lookback_years,\n",
    "          ['deaths'], num_geoids)\n",
    "x_test_BSF_death_only, y_test_BS_death_only =make_data(multiindexed_gdf, first_test_year, last_test_year, lookback_years,\n",
    "          ['deaths'], num_geoids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1328, 18])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_BSF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1328])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_BS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Zeroes Model\n",
    "### lookback = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_zeroes, actual_over_time_zeroes, predicted_over_time_zeroes = models.all_zeroes_model(multiindexed_gdf,\n",
    "                                        first_test_timestep, last_test_timestep, num_geoids, bpr_uncertainty_samples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 Average: 0.21800659589181517\n",
      "Zeroes model (Mean, 95% CI): 21.7,\n",
      "      (21.1-\n",
      "       22.2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_zeroes[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_zeroes[0]) + \\\n",
    "                          np.array(bpr_over_time_zeroes[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Zeroes model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes_rmse_results, zeroes_mae_results  = evaluation.calculate_metrics(actual_over_time_zeroes, predicted_over_time_zeroes, \n",
    "                                          first_test_timestep, last_test_timestep, num_uncertainty_samples=15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Zeroes Model (Mean, 95% CI): 2.39, (2.35-2.42)\n",
      "MAE for Zeroes Model (Mean, 95% CI): 1.33, (1.32-1.33)\n"
     ]
    }
   ],
   "source": [
    "zeroes_rmse_mean, zeroes_rmse_conf_interval = zeroes_rmse_results\n",
    "zeroes_mae_mean, zeroes_mae_conf_interval = zeroes_mae_results\n",
    "\n",
    "evaluation.print_results(\"RMSE for Zeroes Model\", zeroes_rmse_mean, zeroes_rmse_conf_interval)\n",
    "evaluation.print_results(\"MAE for Zeroes Model\", zeroes_mae_mean, zeroes_mae_conf_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Year\n",
    "#### lookback = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_last_time, actual_over_time_last_time, predicted_over_time_last_time  = models.last_time_model(multiindexed_gdf, first_test_timestep, last_test_timestep, num_geoids,\n",
    "                     1,bpr_uncertainty_samples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 Average: 0.7274553540862435\n",
      "Last Year model (Mean, 95% CI): 73.7,\n",
      "      (71.6-\n",
      "       76.2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_last_time[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_last_time[0]) + \\\n",
    "                          np.array(bpr_over_time_last_time[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Last Year model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time_rmse_results, last_time_mae_results  = evaluation.calculate_metrics(actual_over_time_last_time, predicted_over_time_last_time, \n",
    "                                          first_test_timestep, last_test_timestep, num_uncertainty_samples=15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Last Year Model (Mean, 95% CI): 2.31, (2.18-2.44)\n",
      "MAE for Last Year Model (Mean, 95% CI): 1.51, (1.33-1.69)\n"
     ]
    }
   ],
   "source": [
    "last_time_rmse_mean, last_time_rmse_conf_interval = last_time_rmse_results\n",
    "last_time_mae_mean, last_time_mae_conf_interval = last_time_mae_results\n",
    "\n",
    "evaluation.print_results(\"RMSE for Last Year Model\", last_time_rmse_mean, last_time_rmse_conf_interval)\n",
    "evaluation.print_results(\"MAE for Last Year Model\", last_time_mae_mean, last_time_mae_conf_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Average \n",
    "#### lookback = 6 years for cook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_over_time_avg_time, predicted_over_time_avg_time = models.historical_average_model(multiindexed_gdf, first_test_timestep, last_test_timestep, num_geoids,\n",
    "                     1, 6, bpr_uncertainty_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 Average: 0.8215910930729423\n",
      "Historical Average model (Mean, 95% CI): 81.0,\n",
      "      (79.3-\n",
      "       82.9)\n"
     ]
    }
   ],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_avg_time[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_avg_time[0]) + \\\n",
    "                          np.array(bpr_over_time_avg_time[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Historical Average model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Average model RMSE for 2019: 1.53\n",
      "Historical Average model RMSE for 2020: 1.46\n",
      "Joint RMSE for 2019 and 2020: 1.49\n",
      " \n",
      "Historical Average model MAE for 2021: 1.00\n",
      "Historical Average model MAE for 2020: 0.95\n",
      "Joint MAE for 2021 and 2022: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Calculate the model predictions for the years 2019 and 2020\n",
    "predicted_samples_2021 = predicted_over_time_avg_time[0]\n",
    "predicted_samples_2022 = predicted_over_time_avg_time[1]\n",
    "\n",
    "# Calculate RMSE for the Zeroes model for the year 2019 and 2020\n",
    "rmse_2021 = np.sqrt(np.mean((predicted_samples_2021 - actual_values_2021)**2))\n",
    "rmse_2022 = np.sqrt(np.mean((predicted_samples_2022 - actual_values_2022)**2))\n",
    "\n",
    "joint_rmse = np.mean([rmse_2021, rmse_2022])\n",
    "\n",
    "print(f\"Historical Average model RMSE for 2019: {rmse_2021:.2f}\")\n",
    "print(f\"Historical Average model RMSE for 2020: {rmse_2022:.2f}\")\n",
    "print(f\"Joint RMSE for 2019 and 2020: {joint_rmse:.2f}\")\n",
    "print(\" \")\n",
    "\n",
    "mae_2021_samples = np.mean(np.abs(predicted_samples_2021 - actual_values_2022))\n",
    "mae_2022_samples = np.mean(np.abs(predicted_samples_2022 - actual_values_2022))\n",
    "\n",
    "# Take the average MAE for each year\n",
    "mae_2021 = np.mean(mae_2021_samples)\n",
    "mae_2022 = np.mean(mae_2022_samples)\n",
    "\n",
    "# Calculate the joint MAE (mean of individual MAE values from both years)\n",
    "joint_mae = np.mean([mae_2021, mae_2022])\n",
    "\n",
    "print(f\"Historical Average model MAE for 2021: {mae_2021:.2f}\")\n",
    "print(f\"Historical Average model MAE for 2020: {mae_2022:.2f}\")\n",
    "print(f\"Joint MAE for 2021 and 2022: {joint_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Historical Average\n",
    "#### lookback = 6 years (for cook county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical models, features are only difference\n",
    "linear_poisson_weighted_avg = sklearn.linear_model.PoissonRegressor()\n",
    "linear_poisson = sklearn.linear_model.PoissonRegressor()\n",
    "\n",
    "# Params selected via grid search on validation. Need to re-do grid search for chicago\n",
    "hist_poisson =   HistGradientBoostingRegressor(loss=\"poisson\", max_iter=10000, max_depth=3, max_leaf_nodes=2,\n",
    "                                               l2_regularization=1, min_samples_leaf=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.25225843 1.09200799 1.09440722 ... 0.83131589 0.83222862 1.88634815]\n",
      "[1.64495378 1.43602538 1.88427933 ... 1.09320694 0.95226465 2.15842453]\n"
     ]
    }
   ],
   "source": [
    "bpr_over_time_weight_avg, actual_over_time_weight_avg, predicted_over_time_weight_avg = models.scikit_model(multiindexed_gdf, x_BSF_death_only,\n",
    "                                               y_BS_death_only, x_test_BSF_death_only,\n",
    "                                               linear_poisson_weighted_avg,\n",
    "                                               first_test_timestep, last_test_timestep,\n",
    "                                               bpr_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_weight_avg[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_weight_avg[0]) + \\\n",
    "                          np.array(bpr_over_time_weight_avg[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Weighted Average model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_avg_rmse_results, weight_avg_mae_results  = evaluation.calculate_metrics(actual_over_time_weight_avg, predicted_over_time_weight_avg, \n",
    "                                          first_test_timestep, last_test_timestep, num_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Weighted Average Model (Mean, 95% CI): 10.37, (-6.45-27.19)\n",
      "MAE for Weighted Average Model (Mean, 95% CI): 9.57, (-7.29-26.43)\n"
     ]
    }
   ],
   "source": [
    "weight_avg_rmse_mean, weight_avg_rmse_conf_interval = weight_avg_rmse_results\n",
    "weight_avg_mae_mean, weight_avg_mae_conf_interval = weight_avg_mae_results\n",
    "\n",
    "evaluation.print_results(\"RMSE for Weighted Average Model\", weight_avg_rmse_mean, weight_avg_rmse_conf_interval)\n",
    "evaluation.print_results(\"MAE for Weighted Average Model\", weight_avg_mae_mean, weight_avg_mae_conf_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High prediction at timestep 7, location 17031231500: 336.0135685870546\n",
      "High prediction at timestep 8, location 17031231500: 222.3305946809326\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pandas import IndexSlice as idx\n",
    "from metrics import fast_bpr\n",
    "\n",
    "# B = x_BSF_death_only of data, # S = locations, # F = features\n",
    "B, S, F = x_BSF_death_only.shape\n",
    "\n",
    "# reshape data into 2D for scikit learn models. 1 row = 1 location at 1 time\n",
    "x_long = tf.reshape(x_BSF_death_only, ((B * S), F))\n",
    "y_long = tf.reshape(y_BS_death_only, ((B * S), 1))\n",
    "\n",
    "reg = linear_poisson_weighted_avg.fit(x_long, tf.squeeze(y_long))\n",
    "\n",
    "# sloppy notation here, it's not the same B\n",
    "num_test_times = x_test_BSF_death_only.shape[0]\n",
    "\n",
    "rng = np.random.default_rng(seed=360)\n",
    "num_sampled = S - 250\n",
    "results_over_time = []\n",
    "output_deaths = []\n",
    "\n",
    "high_prediction_threshold = 200  # Adjust this threshold as needed\n",
    "\n",
    "for timestep in range(first_test_timestep, last_test_timestep+1):\n",
    "    evaluation_deaths = multiindexed_gdf.loc[idx[:, timestep], :]\n",
    "    evaluation_deaths = evaluation_deaths.drop(columns=timestep_col).reset_index().set_index('geoid')[\n",
    "        outcome_col]\n",
    "    \n",
    "    prediction = reg.predict(x_test_BSF_death_only[timestep - first_test_timestep])\n",
    "\n",
    "    #trying to figure out where the super high deaths are? why is model getting 200+? \n",
    "    for location, predicted_value in zip(evaluation_deaths.index, prediction):\n",
    "        if predicted_value > high_prediction_threshold:\n",
    "            print(f\"High prediction at timestep {timestep}, location {location}: {predicted_value}\")\n",
    "\n",
    "    #print(prediction)\n",
    "    output_deaths.append(prediction)\n",
    "\n",
    "    results_over_samples = []\n",
    "\n",
    "    for _ in range(50):\n",
    "        sampled_indicies = rng.choice(range(S), size=num_sampled, replace=False)\n",
    "\n",
    "        results_over_samples.append(\n",
    "            fast_bpr(evaluation_deaths[sampled_indicies],\n",
    "                        pd.Series(prediction[sampled_indicies],\n",
    "                                index=evaluation_deaths[sampled_indicies].index)\n",
    "                        )\n",
    "        )\n",
    "\n",
    "    results_over_time.append(results_over_samples)\n",
    "\n",
    "    #weighted historical average predicting 200+, bug somewhere?\n",
    "    #show historical context for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336.0135685870546"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(output_deaths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222.3305946809326"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(output_deaths[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear (Poisson GLM baseline)\n",
    "#### lookback years = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.41099936 1.2945081  1.30874252 ... 0.95782909 0.92025344 2.20476922]\n",
      "[1.86377385 1.71533257 2.2224617  ... 1.26920445 1.06358965 2.54817817]\n"
     ]
    }
   ],
   "source": [
    "bpr_over_time_linear, actual_over_time_linear, predicted_over_time_linear = models.scikit_model(multiindexed_gdf, x_BSF,\n",
    "                                               y_BS, x_test_BSF,\n",
    "                                               linear_poisson,\n",
    "                                               first_test_timestep, last_test_timestep,\n",
    "                                               bpr_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 Average: 0.7658887879570023\n",
      "Poisson GLM model (Mean, 95% CI): 76.1,\n",
      "      (74.5-\n",
      "       78.1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_linear[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_linear[0]) + \\\n",
    "                          np.array(bpr_over_time_linear[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Poisson GLM model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_rmse_results, linear_mae_results  = evaluation.calculate_metrics(actual_over_time_linear, predicted_over_time_linear, \n",
    "                                          first_test_timestep, last_test_timestep, num_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Linear (Poisson GLM) (Mean, 95% CI): 9.44, (-5.51-24.40)\n",
      "MAE for Linear (Poisson GLM) (Mean, 95% CI): 8.65, (-6.34-23.65)\n"
     ]
    }
   ],
   "source": [
    "linear_rmse_mean, linear_rmse_conf_interval = linear_rmse_results\n",
    "linear_mae_mean, linear_mae_conf_interval = linear_mae_results\n",
    "\n",
    "evaluation.print_results(\"RMSE for Linear (Poisson GLM)\", linear_rmse_mean, linear_rmse_conf_interval)\n",
    "evaluation.print_results(\"MAE for Linear (Poisson GLM)\", linear_mae_mean, linear_mae_conf_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees (Poisson)\n",
    "#### lookback years = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.63098092 1.31546526 1.12939356 ... 0.98639537 0.37331472 2.61947066]\n",
      "[2.48069631 1.76387372 1.98798501 ... 1.18050964 0.48404729 2.61947066]\n"
     ]
    }
   ],
   "source": [
    "bpr_over_time_tree, actual_over_time_tree, predicted_over_time_tree = models.scikit_model(multiindexed_gdf, x_BSF,\n",
    "                                               y_BS, x_test_BSF,\n",
    "                                               hist_poisson,\n",
    "                                               first_test_timestep, last_test_timestep,\n",
    "                                               bpr_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 Average: 0.7055868820194819\n",
      "Gradient Boosted Trees (Poisson) (Mean, 95% CI): 68.1,\n",
      "      (66.0-\n",
      "       71.3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_over_time_tree[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_over_time_tree[0]) + \\\n",
    "                          np.array(bpr_over_time_tree[1]))/2\n",
    "                        \n",
    "print(f\"\"\"Gradient Boosted Trees (Poisson) (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_rmse_results, tree_mae_results  = evaluation.calculate_metrics(actual_over_time_tree, predicted_over_time_tree, \n",
    "                                          first_test_timestep, last_test_timestep, num_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Gradient Boosted Trees (Mean, 95% CI): 2.13, (2.07-2.18)\n",
      "MAE for Gradient Boosted Trees (Mean, 95% CI): 1.30, (1.23-1.37)\n"
     ]
    }
   ],
   "source": [
    "tree_rmse_mean, tree_rmse_conf_interval = tree_rmse_results\n",
    "tree_mae_mean, tree_mae_conf_interval = tree_mae_results\n",
    "\n",
    "evaluation.print_results(\"RMSE for Gradient Boosted Trees\", tree_rmse_mean, tree_rmse_conf_interval)\n",
    "evaluation.print_results(\"MAE for Gradient Boosted Trees\", tree_mae_mean, tree_mae_conf_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASTNet\n",
    "#### 3 lookback years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the castnet_model function to calculate BPR for CASTNet predictions\n",
    "bpr_results_castnet, actual_results_castnet, predicted_results_castnet  = models.castnet_model(multiindexed_gdf, first_test_timestep, last_test_timestep, \n",
    "                                            num_geoids, bpr_uncertainty_samples=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 Average: 0.7739815165912338\n",
      "CASTNet model (Mean, 95% CI): 75.2,\n",
      "      (73.2-\n",
      "       76.8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"2021 Average: {np.mean(bpr_results_castnet[0])}\")\n",
    "\n",
    "bpr_samples_both_years = (np.array(bpr_results_castnet[0]) + \\\n",
    "                          np.array(bpr_results_castnet[1]))/2\n",
    "                        \n",
    "print(f\"\"\"CASTNet model (Mean, 95% CI): {np.mean(bpr_samples_both_years)*100:.1f},\n",
    "      ({np.percentile(bpr_samples_both_years,2.5)*100:.1f}-\n",
    "       {np.percentile(bpr_samples_both_years,97.5)*100:.1f})\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m castnet_rmse_results, castnet_mae_results  \u001b[39m=\u001b[39m evaluation\u001b[39m.\u001b[39;49mcalculate_metrics(actual_results_castnet, predicted_results_castnet, \n\u001b[1;32m      2\u001b[0m                                           first_test_timestep, last_test_timestep, num_uncertainty_samples\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/opioid-overdose-models/experiment-runner/evaluation.py:26\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(actual_values, predicted_deaths, first_test_timestep, last_test_timestep, num_uncertainty_samples, confidence_level)\u001b[0m\n\u001b[1;32m     23\u001b[0m year_mae_values \u001b[39m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m sample_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_samples):\n\u001b[0;32m---> 26\u001b[0m     samples \u001b[39m=\u001b[39m year_predicted_deaths[sample_idx]\n\u001b[1;32m     28\u001b[0m     rmse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mmean((samples \u001b[39m-\u001b[39m year_actual_values)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m     29\u001b[0m     year_rmse_values\u001b[39m.\u001b[39mappend(rmse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "castnet_rmse_results, castnet_mae_results  = evaluation.calculate_metrics(actual_results_castnet, predicted_results_castnet, \n",
    "                                          first_test_timestep, last_test_timestep, num_uncertainty_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "castnet_rmse_mean, castnet_rmse_conf_interval = castnet_rmse_results\n",
    "castnet_mae_mean, castnet_mae_conf_interval = castnet_mae_results\n",
    "\n",
    "evaluation.print_results(\"RMSE for CASTNet\", castnet_rmse_mean, castnet_rmse_conf_interval)\n",
    "evaluation.print_results(\"MAE for CASTNet\", castnet_mae_mean, castnet_mae_conf_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
